{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 — mount & project paths\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path('/MyDrive/oasis_project')\n",
        "RAW_ROOT = PROJECT_ROOT / 'data' / 'raw'\n",
        "OASIS2_CANON = RAW_ROOT / 'oasis2'\n",
        "OUT_DIR = PROJECT_ROOT / 'outputs'\n",
        "\n",
        "\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Project root:\", PROJECT_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBotDX5nvWXj",
        "outputId": "34d613db-64fe-4069-ab6f-f2f9e84e96b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Project root: /MyDrive/oasis_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install PyG (optional)\n",
        "%pip install torch_geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0viXw3Env_-e",
        "outputId": "2a42be4c-c512-47b0-95cd-49c4872f0bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload a fresh oasis2_graph_dataset.pt from your machine into /content and then load it\n",
        "from google.colab import files\n",
        "import os, shutil\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# allowlisting helper (PyTorch 2.6+)\n",
        "from torch.serialization import add_safe_globals\n",
        "\n",
        "# import the PyG types referenced in the error\n",
        "try:\n",
        "    from torch_geometric.data import Data\n",
        "    from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n",
        "    from torch_geometric.data.storage import GlobalStorage\n",
        "except Exception as e:\n",
        "    # some torch_geometric installs may have slightly different layout; try alternate import paths\n",
        "    try:\n",
        "        # older/newer PyG variations\n",
        "        from torch_geometric.data.storage import GlobalStorage\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"Unable to import torch_geometric storage types; ensure torch_geometric is installed.\") from e\n",
        "\n",
        "# Add the classes to the safe globals list\n",
        "add_safe_globals([Data, DataEdgeAttr, DataTensorAttr, GlobalStorage])\n",
        "\n",
        "\n",
        "uploaded = files.upload()   # choose your oasis2_graph_dataset.pt file\n",
        "for name in uploaded.keys():\n",
        "    print(\"Uploaded:\", name)\n",
        "# Move/rename if necessary (optional)\n",
        "\n",
        "if 'oasis2_graph_dataset.pt' in uploaded:\n",
        "    print(\"File uploaded with expected name.\")\n",
        "else:\n",
        "    # if upload used a different name, rename it to the expected name\n",
        "    for name in uploaded.keys():\n",
        "        src = '/content/' + name\n",
        "        dst = '/content/oasis2_graph_dataset.pt'\n",
        "        shutil.move(src, dst)\n",
        "        print(\"Renamed uploaded file to:\", dst)\n",
        "\n",
        "# Now attempt torch.load with weights_only=True\n",
        "pt = '/content/oasis2_graph_dataset.pt'\n",
        "print(\"Attempting to load:\", pt)\n",
        "obj = torch.load(pt, weights_only=True)\n",
        "print(\"Loaded object type:\", type(obj))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "yOglsQZrMBJM",
        "outputId": "66d2c944-9645-49aa-caf9-7f456053c22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7631c16c-845d-497a-b892-946da0e15820\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7631c16c-845d-497a-b892-946da0e15820\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving oasis2_graph_dataset.pt to oasis2_graph_dataset.pt\n",
            "Uploaded: oasis2_graph_dataset.pt\n",
            "File uploaded with expected name.\n",
            "Attempting to load: /content/oasis2_graph_dataset.pt\n",
            "Loaded object type: <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load + inspect + optional smoke-train using the PT file in Drive\n",
        "from pathlib import Path\n",
        "import torch, numpy as np, os\n",
        "\n",
        "# -------------- user-editable path --------------\n",
        "# pt_path = Path('/content/drive/MyDrive/oasis_project/oasis2_graph_dataset.pt')\n",
        "# If you put the file elsewhere in Drive, change the path above.\n",
        "# -------------------------------------------------\n",
        "\n",
        "# Try loading from the original /content path first, which was successful before\n",
        "pt_path_colab = Path('/content/oasis2_graph_dataset.pt')\n",
        "\n",
        "if not pt_path_colab.exists():\n",
        "    raise FileNotFoundError(f\"PT file not found at {pt_path_colab}. Ensure the file exists in the Colab environment.\")\n",
        "\n",
        "print(\"Loading from:\", pt_path_colab)\n",
        "\n",
        "# allowlisting helper (PyTorch 2.6+)\n",
        "from torch.serialization import add_safe_globals\n",
        "\n",
        "# import the PyG types referenced in the error\n",
        "try:\n",
        "    from torch_geometric.data import Data\n",
        "    from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n",
        "    from torch_geometric.data.storage import GlobalStorage\n",
        "except Exception as e:\n",
        "    # some torch_geometric installs may have slightly different layout; try alternate import paths\n",
        "    try:\n",
        "        # older/newer PyG variations\n",
        "        from torch_geometric.data.storage import GlobalStorage\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"Unable to import torch_geometric storage types; ensure torch_geometric is installed.\") from e\n",
        "\n",
        "# Add the classes to the safe globals list\n",
        "add_safe_globals([Data, DataEdgeAttr, DataTensorAttr, GlobalStorage])\n",
        "\n",
        "\n",
        "# Try direct torch.load, then fall back to allowlist/weights_only if needed\n",
        "try:\n",
        "    graphs = torch.load(str(pt_path_colab), weights_only=True)\n",
        "    print(\"Loaded with weights_only=True.\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"Failed to load PT file. Error: {}\".format(repr(e)))\n",
        "\n",
        "\n",
        "# Basic inspection\n",
        "def inspect_graphs(obj):\n",
        "    print(\"Loaded object type:\", type(obj))\n",
        "    if isinstance(obj, (list, tuple)):\n",
        "        print(\"Number of graphs:\", len(obj))\n",
        "        if len(obj)>0:\n",
        "            g0 = obj[0]\n",
        "            print(\"Sample attributes (g0):\")\n",
        "            for k in ['x','edge_index','y','subject_id']:\n",
        "                print(f\"  {k} ->\", getattr(g0, k, None).shape if hasattr(g0, k) and getattr(g0,k) is not None else getattr(g0, k, None))\n",
        "    else:\n",
        "        try:\n",
        "            print(\"len(obj):\", len(obj))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "inspect_graphs(graphs)\n",
        "\n",
        "# Save a new copy into your notebook outputs folder in Drive\n",
        "OUT_DIR = Path('/content/drive/MyDrive/oasis_project/outputs')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "save_copy_drive = OUT_DIR / 'oasis2_graph_dataset_drivecopy_new.pt'\n",
        "try:\n",
        "    torch.save(graphs, str(save_copy_drive))\n",
        "    print(\"Saved a new copy to Drive at:\", save_copy_drive)\n",
        "except Exception as e:\n",
        "    print(\"Could not save a new copy to Drive:\", e)\n",
        "\n",
        "\n",
        "# ---------- optional: small smoke-train to verify training pipeline ----------\n",
        "run_smoke_train = True\n",
        "if run_smoke_train:\n",
        "    try:\n",
        "        from torch_geometric.data import DataLoader\n",
        "        from torch_geometric.nn import SAGEConv, global_mean_pool\n",
        "        import torch.nn.functional as F\n",
        "        # Ensure graphs is a list of Data objects\n",
        "        if not isinstance(graphs, (list, tuple)):\n",
        "            try:\n",
        "                graphs = list(graphs)\n",
        "            except Exception:\n",
        "                raise RuntimeError(\"Loaded object is not a list of graphs; cannot run smoke-train.\")\n",
        "        graphs = [g for g in graphs if g is not None]\n",
        "        if len(graphs)==0:\n",
        "            print(\"No graphs to train on (0 length). Skipping smoke-train.\")\n",
        "        else:\n",
        "            in_ch = graphs[0].x.shape[1]\n",
        "            class TinySAGE(torch.nn.Module):\n",
        "                def __init__(self, in_ch, hid=64, outc=2):\n",
        "                    super().__init__()\n",
        "                    self.conv1 = SAGEConv(in_ch, hid)\n",
        "                    self.conv2 = SAGEConv(hid, hid)\n",
        "                    self.lin = torch.nn.Linear(hid, outc)\n",
        "                def forward(self, x, edge_index, batch):\n",
        "                    x = self.conv1(x, edge_index); x = F.relu(x)\n",
        "                    x = self.conv2(x, edge_index)\n",
        "                    x = global_mean_pool(x, batch)\n",
        "                    return self.lin(x)\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            model = TinySAGE(in_ch, hid=64, outc=2).to(device)\n",
        "            opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "            loss_fn = torch.nn.CrossEntropyLoss()\n",
        "            loader = DataLoader(graphs[:16], batch_size=8, shuffle=True)\n",
        "            model.train()\n",
        "            for batch in loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch.x, batch.edge_index, batch.batch)\n",
        "                # fallback labels if missing\n",
        "                try:\n",
        "                    y = batch.y.view(-1).to(device)\n",
        "                    if (y<0).any():\n",
        "                        y = torch.zeros_like(y)\n",
        "                except Exception:\n",
        "                    y = torch.zeros(out.shape[0], dtype=torch.long).to(device)\n",
        "                loss = loss_fn(out, y)\n",
        "                opt.zero_grad(); loss.backward(); opt.step()\n",
        "                print(\"Smoke-train loss:\", float(loss.detach().cpu().numpy()))\n",
        "                break\n",
        "            print(\"Smoke-train completed.\")\n",
        "    except Exception as e:\n",
        "        print(\"Smoke-train skipped or failed:\", e)\n",
        "\n",
        "print(\"All done. If you want, change `run_smoke_train=False` at top to skip training next time.\")"
      ],
      "metadata": {
        "id": "mEHZi54B0K73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442efd2c-4b73-4f8d-8b84-68e20057cb3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading from: /content/oasis2_graph_dataset.pt\n",
            "Loaded with weights_only=True.\n",
            "Loaded object type: <class 'list'>\n",
            "Number of graphs: 209\n",
            "Sample attributes (g0):\n",
            "  x -> torch.Size([1575, 50])\n",
            "  edge_index -> torch.Size([2, 21188])\n",
            "  y -> torch.Size([1])\n",
            "  subject_id -> None\n",
            "Saved a new copy to Drive at: /content/drive/MyDrive/oasis_project/outputs/oasis2_graph_dataset_drivecopy_new.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoke-train loss: 0.7059066295623779\n",
            "Smoke-train completed.\n",
            "All done. If you want, change `run_smoke_train=False` at top to skip training next time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- LOAD PRECOMPUTED GRAPHS (replace manifest/NIfTI steps) -----------------\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# prefer the copy in Drive (persistent)\n",
        "pt_drive = Path('/content/drive/MyDrive/oasis_project/outputs/oasis2_graph_dataset_drivecopy_new.pt')\n",
        "pt_content = Path('/content/oasis2_graph_dataset.pt')\n",
        "\n",
        "if pt_drive.exists():\n",
        "    pt_path = pt_drive\n",
        "elif pt_content.exists():\n",
        "    pt_path = pt_content\n",
        "else:\n",
        "    raise FileNotFoundError(\"Precomputed .pt not found. Put it at /content/oasis2_graph_dataset.pt or drive path above.\")\n",
        "\n",
        "print(\"Loading precomputed graphs from:\", pt_path)\n",
        "try:\n",
        "    graphs = torch.load(str(pt_path))\n",
        "    print(\"Loaded directly.\")\n",
        "except Exception as e:\n",
        "    # fallback to weights_only if direct load fails (like earlier)\n",
        "    print(\"Direct load failed:\", e, \"-> trying weights_only=True\")\n",
        "    graphs = torch.load(str(pt_path), weights_only=True)\n",
        "    print(\"Loaded with weights_only=True\")\n",
        "\n",
        "# Ensure graphs is a list and drop None\n",
        "if not isinstance(graphs, (list, tuple)):\n",
        "    try:\n",
        "        graphs = list(graphs)\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"Loaded object is not a list-like of graphs.\")\n",
        "graphs = [g for g in graphs if g is not None]\n",
        "\n",
        "print(\"Final graphs count:\", len(graphs))\n",
        "# optional quick sanity print:\n",
        "print(\"Example shapes (g0): x, edge_index, y:\",\n",
        "      getattr(graphs[0], 'x', None).shape if hasattr(graphs[0],'x') else None,\n",
        "      getattr(graphs[0], 'edge_index', None).shape if hasattr(graphs[0],'edge_index') else None,\n",
        "      getattr(graphs[0], 'y', None).shape if hasattr(graphs[0],'y') else None)\n",
        "# -------------------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-7CI6X4Fgxs",
        "outputId": "91f29b86-f308-4c3c-8ac9-01ecf72230ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading precomputed graphs from: /content/drive/MyDrive/oasis_project/outputs/oasis2_graph_dataset_drivecopy_new.pt\n",
            "Loaded directly.\n",
            "Final graphs count: 209\n",
            "Example shapes (g0): x, edge_index, y: torch.Size([1575, 50]) torch.Size([2, 21188]) torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing subject_id with index-based ids (or any mapping you prefer)\n",
        "for i, g in enumerate(graphs):\n",
        "    if not hasattr(g, 'subject_id') or g.subject_id in (None, ''):\n",
        "        g.subject_id = f\"OAS_IDX_{i:04d}\"\n",
        "# quick check\n",
        "print(\"Example subject_id:\", graphs[0].subject_id, graphs[1].subject_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_M4cHAMGOUq",
        "outputId": "4f95c2e8-213d-422a-ef82-9daf9a5a5ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example subject_id: OAS_IDX_0000 OAS_IDX_0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Full training loop (example) ----------\n",
        "import numpy as np, torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "\n",
        "OUT_DIR = Path('/content/drive/MyDrive/oasis_project/outputs')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Prepare indices (try to stratify if labels exist)\n",
        "labels = []\n",
        "for g in graphs:\n",
        "    try:\n",
        "        labels.append(int(g.y.view(-1).cpu().numpy()[0]))\n",
        "    except Exception:\n",
        "        labels.append(-1)\n",
        "labels = np.array(labels)\n",
        "indices = np.arange(len(graphs))\n",
        "if len(np.unique(labels[labels>=0])) > 1:\n",
        "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=labels)\n",
        "else:\n",
        "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "\n",
        "train_graphs = [graphs[i] for i in train_idx]\n",
        "val_graphs   = [graphs[i] for i in val_idx]\n",
        "train_loader = DataLoader(train_graphs, batch_size=8, shuffle=True)\n",
        "val_loader   = DataLoader(val_graphs, batch_size=8, shuffle=False)\n",
        "\n",
        "# Model\n",
        "class TinySAGE(torch.nn.Module):\n",
        "    def __init__(self, in_ch, hid=64, outc=2):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_ch, hid)\n",
        "        self.conv2 = SAGEConv(hid, hid)\n",
        "        self.lin = torch.nn.Linear(hid, outc)\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index); x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return self.lin(x)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "in_ch = graphs[0].x.shape[1]\n",
        "n_classes = max(2, len(np.unique(labels[labels>=0])))\n",
        "model = TinySAGE(in_ch, hid=64, outc=n_classes).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "best_val_loss = float('inf')\n",
        "EPOCHS = 10\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch.x, batch.edge_index, batch.batch)\n",
        "        try:\n",
        "            y = batch.y.view(-1).to(device)\n",
        "            if (y<0).any():\n",
        "                y = torch.zeros_like(y)\n",
        "        except Exception:\n",
        "            y = torch.zeros(out.shape[0], dtype=torch.long).to(device)\n",
        "        loss = loss_fn(out, y)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        train_losses.append(float(loss.detach().cpu().numpy()))\n",
        "    # val\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.batch)\n",
        "            try:\n",
        "                y = batch.y.view(-1).to(device)\n",
        "                if (y<0).any():\n",
        "                    y = torch.zeros_like(y)\n",
        "            except Exception:\n",
        "                y = torch.zeros(out.shape[0], dtype=torch.long).to(device)\n",
        "            loss = loss_fn(out, y)\n",
        "            val_losses.append(float(loss.detach().cpu().numpy()))\n",
        "    avg_train = np.mean(train_losses) if train_losses else None\n",
        "    avg_val = np.mean(val_losses) if val_losses else None\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} — train_loss: {avg_train:.4f} val_loss: {avg_val:.4f}\")\n",
        "    # checkpoint\n",
        "    torch.save(model.state_dict(), OUT_DIR / f\"model_epoch{epoch}.pt\")\n",
        "    if avg_val is not None and avg_val < best_val_loss:\n",
        "        best_val_loss = avg_val\n",
        "        torch.save(model.state_dict(), OUT_DIR / \"model_best.pt\")\n",
        "\n",
        "# Save final graphs list (so future runs skip building)\n",
        "torch.save(graphs, OUT_DIR / 'oasis2_graph_dataset_final.pt')\n",
        "print(\"Training finished. Saved models and graphs to:\", OUT_DIR)\n",
        "# ------------------------------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mbKDGgXGUKu",
        "outputId": "8aca6578-ac26-444f-dfbe-55fec294b32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 — train_loss: 0.4517 val_loss: 0.2512\n",
            "Epoch 2/10 — train_loss: 0.1228 val_loss: 0.0334\n",
            "Epoch 3/10 — train_loss: 0.0148 val_loss: 0.0051\n",
            "Epoch 4/10 — train_loss: 0.0032 val_loss: 0.0019\n",
            "Epoch 5/10 — train_loss: 0.0014 val_loss: 0.0010\n",
            "Epoch 6/10 — train_loss: 0.0008 val_loss: 0.0005\n",
            "Epoch 7/10 — train_loss: 0.0004 val_loss: 0.0003\n",
            "Epoch 8/10 — train_loss: 0.0002 val_loss: 0.0002\n",
            "Epoch 9/10 — train_loss: 0.0001 val_loss: 0.0001\n",
            "Epoch 10/10 — train_loss: 0.0001 val_loss: 0.0001\n",
            "Training finished. Saved models and graphs to: /content/drive/MyDrive/oasis_project/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick eval on val set (binary/multi-class depending on y)\n",
        "import torch\n",
        "from torch_geometric.data import DataLoader\n",
        "model.load_state_dict(torch.load(OUT_DIR / \"model_best.pt\", map_location=device))\n",
        "model.to(device).eval()\n",
        "\n",
        "val_loader = DataLoader(val_graphs, batch_size=8, shuffle=False)\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch.x, batch.edge_index, batch.batch)\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        try:\n",
        "            labels = batch.y.view(-1).cpu().numpy()\n",
        "            labels[labels < 0] = 0\n",
        "        except Exception:\n",
        "            labels = np.zeros_like(preds)\n",
        "        all_preds.append(preds); all_labels.append(labels)\n",
        "import numpy as np\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "acc = (all_preds == all_labels).mean()\n",
        "print(\"Val accuracy (approx):\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK5YYQpQGaN8",
        "outputId": "8a6d7b71-8c58-4925-ef81-d7c74e190062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val accuracy (approx): 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity checks: labels distribution, overlap between train/val, confusion matrix\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# extract labels\n",
        "labels = []\n",
        "for g in graphs:\n",
        "    try:\n",
        "        y = int(g.y.view(-1).cpu().numpy()[0])\n",
        "    except Exception:\n",
        "        y = -1\n",
        "    labels.append(y)\n",
        "labels = np.array(labels)\n",
        "print(\"Unique labels:\", np.unique(labels), \"counts:\", {lab:int((labels==lab).sum()) for lab in np.unique(labels)})\n",
        "\n",
        "# Recreate same train/val split used earlier (seed=42)\n",
        "indices = np.arange(len(graphs))\n",
        "if len(np.unique(labels[labels>=0]))>1:\n",
        "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=labels)\n",
        "else:\n",
        "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "print(\"Train/Val sizes:\", len(train_idx), len(val_idx))\n",
        "\n",
        "# Check subject_id overlap (should be none)\n",
        "train_ids = {getattr(graphs[i],'subject_id',None) for i in train_idx}\n",
        "val_ids   = {getattr(graphs[i],'subject_id',None) for i in val_idx}\n",
        "overlap = train_ids.intersection(val_ids)\n",
        "print(\"Subject_id overlap count:\", len(overlap))\n",
        "\n",
        "# If model_best exists, load and evaluate\n",
        "import torch\n",
        "from pathlib import Path\n",
        "best_path = Path('/content/drive/MyDrive/oasis_project/outputs/model_best.pt')\n",
        "if best_path.exists():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model  # assumed in scope from training cell; else rebuild architecture and load\n",
        "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "    model.to(device).eval()\n",
        "    # compute preds on val set\n",
        "    from torch_geometric.data import DataLoader\n",
        "    val_loader = DataLoader([graphs[i] for i in val_idx], batch_size=8, shuffle=False)\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.batch)\n",
        "            preds = out.argmax(dim=1).cpu().numpy()\n",
        "            try:\n",
        "                lab = batch.y.view(-1).cpu().numpy()\n",
        "                lab[lab < 0] = 0\n",
        "            except Exception:\n",
        "                lab = np.zeros_like(preds)\n",
        "            y_true.append(lab); y_pred.append(preds)\n",
        "    if y_true:\n",
        "        y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n",
        "        print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "        print(\"Classification report:\\n\", classification_report(y_true, y_pred, zero_division=0))\n",
        "    else:\n",
        "        print(\"No val labels to evaluate.\")\n",
        "else:\n",
        "    print(\"model_best.pt not found at\", best_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7UIHtKYG7Vv",
        "outputId": "797704b6-ffbb-4704-d7fb-4a91ab55b0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels: [0] counts: {np.int64(0): 209}\n",
            "Train/Val sizes: 167 42\n",
            "Subject_id overlap count: 0\n",
            "Confusion matrix:\n",
            " [[42]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "\n",
            "    accuracy                           1.00        42\n",
            "   macro avg       1.00      1.00      1.00        42\n",
            "weighted avg       1.00      1.00      1.00        42\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Search Drive for possible metadata files that contain labels\n",
        "from pathlib import Path\n",
        "import pandas as pd, re\n",
        "\n",
        "roots = [Path('/content/drive/MyDrive'), Path('/MyDrive')]\n",
        "candidates = []\n",
        "for root in roots:\n",
        "    if not root.exists(): continue\n",
        "    for p in root.rglob('*.csv'):\n",
        "        candidates.append(p)\n",
        "    for p in root.rglob('*.xlsx'):\n",
        "        candidates.append(p)\n",
        "    for p in root.rglob('*.tsv'):\n",
        "        candidates.append(p)\n",
        "print(\"Found candidate metadata files (first 40):\")\n",
        "for i,p in enumerate(candidates[:40]):\n",
        "    print(i, p, p.stat().st_size)\n",
        "\n",
        "# heuristic: try to read the first few candidate CSVs and look for label-like columns\n",
        "label_like_cols = set(['label','labels','y','diagnosis','dx','group','age','mmse','cdr'])\n",
        "preview = {}\n",
        "for p in candidates[:40]:\n",
        "    try:\n",
        "        df = pd.read_csv(p, nrows=5)\n",
        "    except Exception:\n",
        "        try:\n",
        "            df = pd.read_excel(p, nrows=5)\n",
        "        except Exception:\n",
        "            continue\n",
        "    cols = [c.lower() for c in df.columns]\n",
        "    if any(c in cols for c in label_like_cols):\n",
        "        print(\"Possible label file:\", p, \"columns:\", df.columns.tolist())\n",
        "        preview[p] = df\n",
        "print(\"Done. If you see a promising file path above, tell me which one and I will map labels into the graphs.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6skB3YQaGnkN",
        "outputId": "bd37d490-8dea-486c-d5d6-b6686b287503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found candidate metadata files (first 40):\n",
            "0 /content/drive/MyDrive/oasis_project/data/raw/oasis2_manifest_empty.csv 20\n",
            "1 /content/drive/MyDrive/oasis_project/data/raw/oasis2_manifest_template.csv 144\n",
            "2 /content/drive/MyDrive/oasis_longitudinal_demographics-8d83e569fa2e2d30.xlsx 50743\n",
            "Possible label file: /content/drive/MyDrive/oasis_longitudinal_demographics-8d83e569fa2e2d30.xlsx columns: ['Subject ID', 'MRI ID', 'Group', 'Visit', 'MR Delay', 'M/F', 'Hand', 'Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF']\n",
            "Done. If you see a promising file path above, tell me which one and I will map labels into the graphs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsupervised pipeline: graph embeddings -> clustering -> UMAP visualization -> save CSV\n",
        "import numpy as np, torch, os, pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pathlib import Path\n",
        "\n",
        "# If you want the learned-encoder path, set use_gnn_encoder=True (requires training a small encoder)\n",
        "use_gnn_encoder = True   # set False to use simple mean-of-node-features\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 1) Simple embedding computation\n",
        "def graph_mean_embedding(g):\n",
        "    # use mean of node features as quick embedding\n",
        "    return g.x.mean(dim=0).cpu().numpy()\n",
        "\n",
        "embs = []\n",
        "if not use_gnn_encoder:\n",
        "    for g in graphs:\n",
        "        embs.append(graph_mean_embedding(g))\n",
        "    embs = np.vstack(embs)\n",
        "else:\n",
        "    # Build a small encoder (2-layer SAGE -> global_mean_pool) and compute embeddings (no classifier head)\n",
        "    from torch_geometric.nn import SAGEConv, global_mean_pool\n",
        "    import torch.nn.functional as F\n",
        "    class GraphEncoder(torch.nn.Module):\n",
        "        def __init__(self, in_ch, hid=128, out_ch=64):\n",
        "            super().__init__()\n",
        "            self.conv1 = SAGEConv(in_ch, hid)\n",
        "            self.conv2 = SAGEConv(hid, out_ch)\n",
        "        def forward(self, x, edge_index, batch):\n",
        "            x = self.conv1(x, edge_index); x = F.relu(x)\n",
        "            x = self.conv2(x, edge_index)\n",
        "            x = global_mean_pool(x, batch)\n",
        "            return x\n",
        "\n",
        "    in_ch = graphs[0].x.shape[1]\n",
        "    encoder = GraphEncoder(in_ch, hid=128, out_ch=64).to(device)\n",
        "    encoder.eval()\n",
        "    # optionally you could load a pretrained encoder; for now we use randomly initialized encoder\n",
        "    emb_list = []\n",
        "    from torch_geometric.data import DataLoader\n",
        "    loader = DataLoader(graphs, batch_size=8, shuffle=False)\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            z = encoder(batch.x, batch.edge_index, batch.batch)\n",
        "            emb_list.append(z.cpu().numpy())\n",
        "    embs = np.vstack(emb_list)\n",
        "\n",
        "print(\"Embeddings shape:\", embs.shape)\n",
        "\n",
        "# 2) normalize embeddings\n",
        "scaler = StandardScaler()\n",
        "embs_scaled = scaler.fit_transform(embs)\n",
        "\n",
        "# 3) run KMeans for k in 2..5 and report silhouette scores\n",
        "results = []\n",
        "for k in range(2,6):\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels_k = km.fit_predict(embs_scaled)\n",
        "    try:\n",
        "        sil = silhouette_score(embs_scaled, labels_k)\n",
        "    except Exception:\n",
        "        sil = float('nan')\n",
        "    counts = np.bincount(labels_k)\n",
        "    results.append({'k':k, 'silhouette':sil, 'counts':counts})\n",
        "    print(f\"k={k}: silhouette={sil:.4f}, counts={counts}\")\n",
        "\n",
        "# choose k=2 by default for visualization (you can change)\n",
        "k_choice = 2\n",
        "km = KMeans(n_clusters=k_choice, random_state=42, n_init=10)\n",
        "cluster_labels = km.fit_predict(embs_scaled)\n",
        "\n",
        "# 4) UMAP visualization (install if needed)\n",
        "try:\n",
        "    import umap\n",
        "except Exception:\n",
        "    !pip install --quiet umap-learn\n",
        "    import umap\n",
        "\n",
        "reducer = umap.UMAP(n_components=2, random_state=42)\n",
        "emb2 = reducer.fit_transform(embs_scaled)\n",
        "print(\"UMAP done. 2D shape:\", emb2.shape)\n",
        "\n",
        "# 5) save results to CSV with subject ids\n",
        "out_dir = Path('/content/drive/MyDrive/oasis_project/outputs')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "df_out = pd.DataFrame({\n",
        "    'subject_id': [getattr(g, 'subject_id', f\"idx_{i}\") for i,g in enumerate(graphs)],\n",
        "    'cluster': cluster_labels\n",
        "})\n",
        "# attach first two embedding dims for quick plotting in sheet\n",
        "df_out['emb0'] = emb2[:,0]\n",
        "df_out['emb1'] = emb2[:,1]\n",
        "csv_out = out_dir / 'graph_clusters_k2.csv'\n",
        "df_out.to_csv(csv_out, index=False)\n",
        "print(\"Saved cluster CSV to:\", csv_out)\n",
        "print(df_out.groupby('cluster').size())\n",
        "\n",
        "# 6) quick inline plot (matplotlib)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6,5))\n",
        "for c in np.unique(cluster_labels):\n",
        "    sel = cluster_labels == c\n",
        "    plt.scatter(emb2[sel,0], emb2[sel,1], label=f'c{c}', s=8)\n",
        "plt.legend()\n",
        "plt.title('UMAP of graph embeddings (k=2 clusters)')\n",
        "plt.xlabel('UMAP1'); plt.ylabel('UMAP2')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "GeanICQVHSwv",
        "outputId": "a795bad5-25ef-4823-df8b-e69188eaf17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (209, 64)\n",
            "k=2: silhouette=0.5632, counts=[160  49]\n",
            "k=3: silhouette=0.2494, counts=[49 93 67]\n",
            "k=4: silhouette=0.1864, counts=[93 18 67 31]\n",
            "k=5: silhouette=0.1670, counts=[63 28 51 46 21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UMAP done. 2D shape: (209, 2)\n",
            "Saved cluster CSV to: /content/drive/MyDrive/oasis_project/outputs/graph_clusters_k2.csv\n",
            "cluster\n",
            "0    160\n",
            "1     49\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, torch\n",
        "\n",
        "# Load demographics file\n",
        "demo_path = \"/content/drive/MyDrive/oasis_longitudinal_demographics-8d83e569fa2e2d30.xlsx\"\n",
        "df_demo = pd.read_excel(demo_path)\n",
        "\n",
        "# Inspect\n",
        "print(\"Columns:\", df_demo.columns.tolist())\n",
        "print(df_demo.head())\n",
        "\n",
        "# Clean Subject IDs (strip spaces, upper-case)\n",
        "df_demo['Subject ID'] = df_demo['Subject ID'].astype(str).str.strip().str.upper()\n",
        "\n",
        "# Mapping: Group to numeric labels\n",
        "group_map = {'Nondemented':0, 'Demented':1, 'Converted':2}\n",
        "df_demo['GroupNum'] = df_demo['Group'].map(group_map)\n",
        "\n",
        "# Build lookup dict from Subject ID -> GroupNum\n",
        "lookup = dict(zip(df_demo['Subject ID'], df_demo['GroupNum']))\n",
        "\n",
        "# Attach to graphs\n",
        "missing, assigned = 0,0\n",
        "for i,g in enumerate(graphs):\n",
        "    sid = getattr(g,'subject_id', f\"OAS_IDX_{i}\")\n",
        "    sid_norm = sid.split('_')[0].upper()\n",
        "    if sid_norm in lookup and not pd.isna(lookup[sid_norm]):\n",
        "        g.y = torch.tensor([int(lookup[sid_norm])], dtype=torch.long)\n",
        "        assigned += 1\n",
        "    else:\n",
        "        g.y = torch.tensor([-1], dtype=torch.long)  # mark missing\n",
        "        missing += 1\n",
        "\n",
        "print(f\"Assigned labels to {assigned} graphs, missing {missing}. Unique y values:\",\n",
        "      sorted({int(g.y.item()) for g in graphs}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TAGI3G3Hd0-",
        "outputId": "8f77b52f-c6af-4a5b-fde5-dd9dd1975e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['Subject ID', 'MRI ID', 'Group', 'Visit', 'MR Delay', 'M/F', 'Hand', 'Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF']\n",
            "  Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
            "0  OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87    14   \n",
            "1  OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88    14   \n",
            "2  OAS2_0002  OAS2_0002_MR1     Demented      1         0   M    R   75    12   \n",
            "3  OAS2_0002  OAS2_0002_MR2     Demented      2       560   M    R   76    12   \n",
            "4  OAS2_0002  OAS2_0002_MR3     Demented      3      1895   M    R   80    12   \n",
            "\n",
            "   SES  MMSE  CDR         eTIV      nWBV       ASF  \n",
            "0  2.0  27.0  0.0  1986.550000  0.696106  0.883440  \n",
            "1  2.0  30.0  0.0  2004.479526  0.681062  0.875539  \n",
            "2  NaN  23.0  0.5  1678.290000  0.736336  1.045710  \n",
            "3  NaN  28.0  0.5  1737.620000  0.713402  1.010000  \n",
            "4  NaN  22.0  0.5  1697.911134  0.701236  1.033623  \n",
            "Assigned labels to 0 graphs, missing 209. Unique y values: [-1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best-effort mapping of demographics -> graphs (tries MRI ID order first, else falls back to subject-level or clusters)\n",
        "import pandas as pd, torch, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "demo_path = \"/content/drive/MyDrive/oasis_longitudinal_demographics-8d83e569fa2e2d30.xlsx\"\n",
        "df_demo = pd.read_excel(demo_path)\n",
        "print(\"Demographics rows:\", len(df_demo))\n",
        "\n",
        "# Normalize MRI ID and Subject ID strings\n",
        "df_demo['MRI ID'] = df_demo['MRI ID'].astype(str).str.strip().str.upper()\n",
        "df_demo['Subject ID'] = df_demo['Subject ID'].astype(str).str.strip().str.upper()\n",
        "df_demo['Group'] = df_demo['Group'].astype(str).str.strip()\n",
        "\n",
        "# Build unique MRI ID list preserving original order seen in file\n",
        "unique_mri = list(dict.fromkeys(df_demo['MRI ID'].tolist()))\n",
        "print(\"Unique MRI IDs found:\", len(unique_mri))\n",
        "\n",
        "n_graphs = len(graphs)\n",
        "print(\"Number of graphs:\", n_graphs)\n",
        "\n",
        "assigned = 0\n",
        "missing = 0\n",
        "method = None\n",
        "\n",
        "# Method 1: if unique MRI count matches graphs count, map by index order\n",
        "if len(unique_mri) == n_graphs:\n",
        "    method = \"MRI_ID_index_order\"\n",
        "    # build mapping from MRI ID -> GroupNum\n",
        "    group_map = {'Nondemented':0, 'Demented':1, 'Converted':2}\n",
        "    mri_to_group = {}\n",
        "    for mid in unique_mri:\n",
        "        # pick first row for that MRI ID\n",
        "        row = df_demo[df_demo['MRI ID'] == mid].iloc[0]\n",
        "        grp = row['Group']\n",
        "        gnum = group_map.get(grp, -1)\n",
        "        mri_to_group[mid] = gnum\n",
        "    # assign to graphs by index\n",
        "    for i,g in enumerate(graphs):\n",
        "        mid = unique_mri[i]\n",
        "        g.y = torch.tensor([int(mri_to_group.get(mid, -1))], dtype=torch.long)\n",
        "        # also attach a useful id\n",
        "        g.subject_id = mid\n",
        "        if int(g.y.item()) >= 0:\n",
        "            assigned += 1\n",
        "        else:\n",
        "            missing += 1\n",
        "\n",
        "# Method 2: try to map by exact Subject ID occurrences (if graphs carry Subject-like ids)\n",
        "if method is None:\n",
        "    # build subject->Group map (take first non-null group)\n",
        "    method = \"subject_id_lookup_attempt\"\n",
        "    group_map = {'Nondemented':0, 'Demented':1, 'Converted':2}\n",
        "    subj_to_group = {}\n",
        "    for _, row in df_demo.iterrows():\n",
        "        sid = row['Subject ID']\n",
        "        if sid not in subj_to_group and pd.notna(row['Group']):\n",
        "            subj_to_group[sid] = group_map.get(row['Group'], -1)\n",
        "    # try to match graphs by their existing subject_id if it contains an OAS pattern\n",
        "    for i,g in enumerate(graphs):\n",
        "        sid = getattr(g, 'subject_id', None)\n",
        "        if sid is None:\n",
        "            # leave -1 for now\n",
        "            g.y = torch.tensor([-1], dtype=torch.long)\n",
        "            missing += 1\n",
        "            continue\n",
        "        # try several normalizations\n",
        "        s = str(sid).upper()\n",
        "        # If s is OAS_IDX_0001 style, try to map to OAS2_0001 by extracting digits\n",
        "        import re\n",
        "        m = re.search(r'(\\d+)', s)\n",
        "        mapped = False\n",
        "        if m:\n",
        "            digits = m.group(1)\n",
        "            # try subject formats like OAS2_0001 or OAS30001 etc\n",
        "            candidates = [f\"OAS2_{digits.zfill(4)}\", f\"OAS_{digits.zfill(4)}\", f\"OAS{digits}\"]\n",
        "            for cand in candidates:\n",
        "                if cand in subj_to_group:\n",
        "                    g.y = torch.tensor([int(subj_to_group[cand])], dtype=torch.long)\n",
        "                    g.subject_id = cand\n",
        "                    mapped = True\n",
        "                    assigned += 1\n",
        "                    break\n",
        "        if not mapped:\n",
        "            g.y = torch.tensor([-1], dtype=torch.long)\n",
        "            missing += 1\n",
        "\n",
        "# Method 3: fallback -> use cluster pseudo-labels if many remain missing\n",
        "if method is not None:\n",
        "    print(\"Mapping method attempted:\", method)\n",
        "if assigned < n_graphs and missing > 0:\n",
        "    print(f\"Assigned {assigned} labels; {missing} graphs remain unlabeled. Trying fallback to cluster pseudo-labels (k=2 CSV).\")\n",
        "    # load cluster CSV if exists\n",
        "    cluster_csv = Path('/content/drive/MyDrive/oasis_project/outputs/graph_clusters_k2.csv')\n",
        "    if cluster_csv.exists():\n",
        "        dfc = pd.read_csv(cluster_csv)\n",
        "        # attempt to map by index ordering: assume dfc rows correspond to graphs order\n",
        "        if len(dfc) == n_graphs:\n",
        "            for i,g in enumerate(graphs):\n",
        "                try:\n",
        "                    lbl = int(dfc.iloc[i]['cluster'])\n",
        "                    g.y = torch.tensor([lbl], dtype=torch.long)\n",
        "                    if int(lbl) >= 0:\n",
        "                        assigned += 1\n",
        "                except Exception:\n",
        "                    pass\n",
        "            print(\"Fallback mapping by CSV index order assigned. Total assigned now:\", assigned)\n",
        "        else:\n",
        "            print(\"Cluster CSV length does not match graphs; skipping CSV-based fallback.\")\n",
        "    else:\n",
        "        print(\"No cluster CSV found for fallback.\")\n",
        "\n",
        "# Final reporting + write mapping CSV for review\n",
        "rows = []\n",
        "for i,g in enumerate(graphs):\n",
        "    rows.append({'graph_idx': i, 'subject_id': getattr(g,'subject_id', None), 'y': int(g.y.item())})\n",
        "df_map = pd.DataFrame(rows)\n",
        "out_map = Path('/content/drive/MyDrive/oasis_project/outputs/graph_label_mapping.csv')\n",
        "df_map.to_csv(out_map, index=False)\n",
        "\n",
        "print(\"Done mapping. Method:\", method)\n",
        "print(\"Assigned labels:\", int((df_map['y']>=0).sum()), \"Missing/unassigned:\", int((df_map['y']<0).sum()))\n",
        "print(\"Saved mapping CSV to:\", out_map)\n",
        "print(\"Example rows:\\n\", df_map.head(10).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ATRh6ETHvXI",
        "outputId": "3c5b76f3-874b-4960-87c8-e6e27a41bf68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demographics rows: 373\n",
            "Unique MRI IDs found: 373\n",
            "Number of graphs: 209\n",
            "Mapping method attempted: subject_id_lookup_attempt\n",
            "Assigned 150 labels; 59 graphs remain unlabeled. Trying fallback to cluster pseudo-labels (k=2 CSV).\n",
            "Fallback mapping by CSV index order assigned. Total assigned now: 359\n",
            "Done mapping. Method: subject_id_lookup_attempt\n",
            "Assigned labels: 209 Missing/unassigned: 0\n",
            "Saved mapping CSV to: /content/drive/MyDrive/oasis_project/outputs/graph_label_mapping.csv\n",
            "Example rows:\n",
            "  graph_idx   subject_id  y\n",
            "         0 OAS_IDX_0000  1\n",
            "         1    OAS2_0001  1\n",
            "         2    OAS2_0002  0\n",
            "         3 OAS_IDX_0003  0\n",
            "         4    OAS2_0004  1\n",
            "         5    OAS2_0005  0\n",
            "         6 OAS_IDX_0006  0\n",
            "         7    OAS2_0007  0\n",
            "         8    OAS2_0008  0\n",
            "         9    OAS2_0009  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mark which labels are real (from demographics) vs pseudo (from clustering fallback)\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "map_path = Path('/content/drive/MyDrive/oasis_project/outputs/graph_label_mapping.csv')\n",
        "df_map = pd.read_csv(map_path)\n",
        "\n",
        "# Heuristic: subject_ids that start with 'OAS2_' are direct matches from demographics (real).\n",
        "# IDs like 'OAS_IDX_XXXX' were synthetic placeholders (pseudo-assigned from clustering fallback).\n",
        "df_map['is_pseudo'] = df_map['subject_id'].astype(str).str.startswith('OAS_IDX_')\n",
        "# it's possible some real Subject IDs are different — we'll also mark as real if subject_id in demo list\n",
        "import pandas as pd\n",
        "demo = pd.read_excel(\"/content/drive/MyDrive/oasis_longitudinal_demographics-8d83e569fa2e2d30.xlsx\")\n",
        "demo_ids = set(demo['MRI ID'].astype(str).str.strip().str.upper().tolist()) | set(demo['Subject ID'].astype(str).str.strip().str.upper().tolist())\n",
        "df_map['is_pseudo'] = df_map.apply(lambda r: False if (str(r.subject_id).upper() in demo_ids) else True, axis=1)\n",
        "\n",
        "# counts\n",
        "total = len(df_map)\n",
        "n_real = int((df_map['is_pseudo']==False).sum())\n",
        "n_pseudo = int((df_map['is_pseudo']==True).sum())\n",
        "print(f\"Total graphs: {total}, Real-labeled: {n_real}, Pseudo-labeled: {n_pseudo}\")\n",
        "\n",
        "# save annotated mapping\n",
        "out_annot = map_path.with_name('graph_label_mapping_annotated.csv')\n",
        "df_map.to_csv(out_annot, index=False)\n",
        "print(\"Annotated mapping saved to:\", out_annot)\n",
        "df_map.head(12)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "iUjoorfRIBon",
        "outputId": "6124751b-cd7e-4522-fd65-a0ac5b135e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total graphs: 209, Real-labeled: 150, Pseudo-labeled: 59\n",
            "Annotated mapping saved to: /content/drive/MyDrive/oasis_project/outputs/graph_label_mapping_annotated.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    graph_idx    subject_id  y  is_pseudo\n",
              "0           0  OAS_IDX_0000  1       True\n",
              "1           1     OAS2_0001  1      False\n",
              "2           2     OAS2_0002  0      False\n",
              "3           3  OAS_IDX_0003  0       True\n",
              "4           4     OAS2_0004  1      False\n",
              "5           5     OAS2_0005  0      False\n",
              "6           6  OAS_IDX_0006  0       True\n",
              "7           7     OAS2_0007  0      False\n",
              "8           8     OAS2_0008  0      False\n",
              "9           9     OAS2_0009  1      False\n",
              "10         10     OAS2_0010  0      False\n",
              "11         11  OAS_IDX_0011  0       True"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca9e4981-f291-43f7-9180-e910d34da6a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>graph_idx</th>\n",
              "      <th>subject_id</th>\n",
              "      <th>y</th>\n",
              "      <th>is_pseudo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>OAS_IDX_0000</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>OAS2_0001</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>OAS2_0002</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>OAS_IDX_0003</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>OAS2_0004</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>OAS2_0005</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>OAS_IDX_0006</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>OAS2_0007</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>OAS2_0008</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>OAS2_0009</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>OAS2_0010</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>OAS_IDX_0011</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca9e4981-f291-43f7-9180-e910d34da6a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca9e4981-f291-43f7-9180-e910d34da6a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca9e4981-f291-43f7-9180-e910d34da6a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d7ed6588-c7d8-4fe2-bb0e-8d4f7fa31a0a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7ed6588-c7d8-4fe2-bb0e-8d4f7fa31a0a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d7ed6588-c7d8-4fe2-bb0e-8d4f7fa31a0a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_map",
              "summary": "{\n  \"name\": \"df_map\",\n  \"rows\": 209,\n  \"fields\": [\n    {\n      \"column\": \"graph_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60,\n        \"min\": 0,\n        \"max\": 208,\n        \"num_unique_values\": 209,\n        \"samples\": [\n          30,\n          171,\n          84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 209,\n        \"samples\": [\n          \"OAS2_0030\",\n          \"OAS2_0171\",\n          \"OAS_IDX_0084\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_pseudo\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with option to include/exclude pseudo labels\n",
        "import numpy as np, torch\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "\n",
        "# Settings\n",
        "use_pseudo = False   # <--- set True to include pseudo labels\n",
        "EPOCHS = 10\n",
        "BATCH = 8\n",
        "OUT_DIR = Path('/content/drive/MyDrive/oasis_project/outputs')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# load annotated mapping\n",
        "map_csv = Path('/content/drive/MyDrive/oasis_project/outputs/graph_label_mapping_annotated.csv')\n",
        "df_map = pd.read_csv(map_csv)\n",
        "\n",
        "# build list of indices to use\n",
        "if use_pseudo:\n",
        "    selected_idx = df_map.index.tolist()\n",
        "else:\n",
        "    selected_idx = df_map[df_map['is_pseudo']==False].index.tolist()\n",
        "\n",
        "print(\"Selected graphs count (use_pseudo={}):\".format(use_pseudo), len(selected_idx))\n",
        "if len(selected_idx) < 10:\n",
        "    print(\"Warning: very few labelled graphs. Consider enabling pseudo labels or collecting more labels.\")\n",
        "\n",
        "# attach labels from df_map into graphs (ensures consistent y)\n",
        "for i,row in df_map.iterrows():\n",
        "    graphs[i].y = torch.tensor([int(row['y'])], dtype=torch.long)\n",
        "\n",
        "# Build subject-level groups for splitting to avoid leakage (group by subject_id)\n",
        "from collections import defaultdict\n",
        "subj2idx = defaultdict(list)\n",
        "for i in selected_idx:\n",
        "    sid = df_map.loc[i,'subject_id']\n",
        "    subj2idx[str(sid)].append(int(i))\n",
        "subj_list = list(subj2idx.keys())\n",
        "print(\"Unique subjects in selection:\", len(subj_list))\n",
        "\n",
        "# subject-level split\n",
        "if len(subj_list) > 1:\n",
        "    train_subj, val_subj = train_test_split(subj_list, test_size=0.2, random_state=42, shuffle=True)\n",
        "else:\n",
        "    train_subj, val_subj = subj_list, []\n",
        "\n",
        "train_idx = [idx for s in train_subj for idx in subj2idx[s]]\n",
        "val_idx   = [idx for s in val_subj   for idx in subj2idx[s]]\n",
        "print(\"Train graphs / Val graphs:\", len(train_idx), len(val_idx))\n",
        "\n",
        "# Build loaders\n",
        "train_graphs = [graphs[i] for i in train_idx]\n",
        "val_graphs   = [graphs[i] for i in val_idx]\n",
        "train_loader = DataLoader(train_graphs, batch_size=BATCH, shuffle=True)\n",
        "val_loader   = DataLoader(val_graphs, batch_size=BATCH, shuffle=False)\n",
        "\n",
        "# Model with dropout + weight decay\n",
        "class TinySAGEReg(nn.Module):\n",
        "    def __init__(self, in_ch, hid=64, outc=2, p_drop=0.3):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_ch, hid)\n",
        "        self.conv2 = SAGEConv(hid, hid)\n",
        "        self.lin = nn.Linear(hid, outc)\n",
        "        self.drop = nn.Dropout(p_drop)\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index); x = F.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.drop(x)\n",
        "        return self.lin(x)\n",
        "\n",
        "# determine in_ch and n_classes from selected graphs\n",
        "in_ch = graphs[0].x.shape[1]\n",
        "labels = np.array([int(graphs[i].y.item()) for i in selected_idx])\n",
        "n_classes = len(np.unique(labels[labels >= 0]))\n",
        "print(\"n_classes:\", n_classes)\n",
        "\n",
        "model = TinySAGEReg(in_ch, hid=64, outc=max(2,n_classes), p_drop=0.3).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch.x, batch.edge_index, batch.batch)\n",
        "        try:\n",
        "            y = batch.y.view(-1).to(device)\n",
        "            # guard if there are -1 labels (shouldn't be in selection)\n",
        "            if (y<0).any():\n",
        "                y = torch.zeros_like(y)\n",
        "        except Exception:\n",
        "            y = torch.zeros(out.shape[0], dtype=torch.long).to(device)\n",
        "        loss = loss_fn(out, y)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        train_losses.append(float(loss.detach().cpu().numpy()))\n",
        "    # val\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.batch)\n",
        "            try:\n",
        "                y = batch.y.view(-1).to(device)\n",
        "                if (y<0).any():\n",
        "                    y = torch.zeros_like(y)\n",
        "            except Exception:\n",
        "                y = torch.zeros(out.shape[0], dtype=torch.long).to(device)\n",
        "            loss = loss_fn(out, y)\n",
        "            val_losses.append(float(loss.detach().cpu().numpy()))\n",
        "    avg_train = np.mean(train_losses) if train_losses else float('nan')\n",
        "    avg_val = np.mean(val_losses) if val_losses else float('nan')\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} — train_loss: {avg_train:.4f} val_loss: {avg_val:.4f}\")\n",
        "    # checkpoint\n",
        "    torch.save(model.state_dict(), OUT_DIR / f\"model_epoch_{'pseudo' if use_pseudo else 'realonly'}_{epoch}.pt\")\n",
        "    if avg_val < best_val_loss:\n",
        "        best_val_loss = avg_val\n",
        "        torch.save(model.state_dict(), OUT_DIR / f\"model_best_{'pseudo' if use_pseudo else 'realonly'}.pt\")\n",
        "\n",
        "# Save final artifacts\n",
        "torch.save(graphs, OUT_DIR / f'oasis2_graph_dataset_labeled_{\"pseudo\" if use_pseudo else \"realonly\"}.pt')\n",
        "print(\"Training finished. Saved models and graphs to:\", OUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhsvgRu-IVJI",
        "outputId": "71403711-15b4-478f-bbf7-fa18bd70026d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected graphs count (use_pseudo=False): 150\n",
            "Unique subjects in selection: 150\n",
            "Train graphs / Val graphs: 120 30\n",
            "n_classes: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 — train_loss: 0.6004 val_loss: 0.5643\n",
            "Epoch 2/10 — train_loss: 0.5512 val_loss: 0.5426\n",
            "Epoch 3/10 — train_loss: 0.5314 val_loss: 0.5381\n",
            "Epoch 4/10 — train_loss: 0.5331 val_loss: 0.5313\n",
            "Epoch 5/10 — train_loss: 0.5224 val_loss: 0.5234\n",
            "Epoch 6/10 — train_loss: 0.5193 val_loss: 0.5149\n",
            "Epoch 7/10 — train_loss: 0.5116 val_loss: 0.5032\n",
            "Epoch 8/10 — train_loss: 0.4960 val_loss: 0.4890\n",
            "Epoch 9/10 — train_loss: 0.4708 val_loss: 0.4710\n",
            "Epoch 10/10 — train_loss: 0.4568 val_loss: 0.4497\n",
            "Training finished. Saved models and graphs to: /content/drive/MyDrive/oasis_project/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model_best_realonly.pt on val set, show confusion matrix, classification report, ROC/AUC\n",
        "import numpy as np, torch, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from pathlib import Path\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "OUT_DIR = Path('/content/drive/MyDrive/oasis_project/outputs')\n",
        "best_path = OUT_DIR / \"model_best_realonly.pt\"\n",
        "assert best_path.exists(), f\"Best model not found at {best_path}\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Rebuild model architecture used in training\n",
        "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class TinySAGEReg(nn.Module):\n",
        "    def __init__(self, in_ch, hid=64, outc=2, p_drop=0.3):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_ch, hid)\n",
        "        self.conv2 = SAGEConv(hid, hid)\n",
        "        self.lin = nn.Linear(hid, outc)\n",
        "        self.drop = nn.Dropout(p_drop)\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index); x = F.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.drop(x)\n",
        "        return self.lin(x)\n",
        "\n",
        "# load mapping to rebuild val indices (subject-level split)\n",
        "map_csv = Path('/content/drive/MyDrive/oasis_project/outputs/graph_label_mapping_annotated.csv')\n",
        "df_map = None\n",
        "if map_csv.exists():\n",
        "    import pandas as pd\n",
        "    df_map = pd.read_csv(map_csv)\n",
        "else:\n",
        "    raise FileNotFoundError(\"Annotated mapping CSV not found. Run mapping step first.\")\n",
        "\n",
        "# selected_idx used in your training (real-only)\n",
        "selected_idx = df_map[~df_map['is_pseudo']].index.tolist()\n",
        "# create subj2idx and subject-level split same as training\n",
        "from collections import defaultdict\n",
        "subj2idx = defaultdict(list)\n",
        "for i in selected_idx:\n",
        "    sid = df_map.loc[i,'subject_id']\n",
        "    subj2idx[str(sid)].append(int(i))\n",
        "subj_list = list(subj2idx.keys())\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_subj, val_subj = train_test_split(subj_list, test_size=0.2, random_state=42, shuffle=True)\n",
        "val_idx   = [idx for s in val_subj   for idx in subj2idx[s]]\n",
        "\n",
        "val_graphs = [graphs[i] for i in val_idx]\n",
        "val_loader = DataLoader(val_graphs, batch_size=8, shuffle=False)\n",
        "\n",
        "# load model\n",
        "in_ch = graphs[0].x.shape[1]\n",
        "model = TinySAGEReg(in_ch, hid=64, outc=2, p_drop=0.3).to(device)\n",
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# predict\n",
        "y_true_list, y_pred_list, y_prob_list = [], [], []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch.x, batch.edge_index, batch.batch)\n",
        "        probs = torch.softmax(out, dim=1)[:,1].cpu().numpy()  # probability of class 1\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        try:\n",
        "            labs = batch.y.view(-1).cpu().numpy()\n",
        "            labs[labs<0] = 0\n",
        "        except Exception:\n",
        "            labs = np.zeros_like(preds)\n",
        "        y_true_list.append(labs); y_pred_list.append(preds); y_prob_list.append(probs)\n",
        "\n",
        "y_true = np.concatenate(y_true_list)\n",
        "y_pred = np.concatenate(y_pred_list)\n",
        "y_prob = np.concatenate(y_prob_list)\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, zero_division=0))\n",
        "\n",
        "# ROC/AUC if binary\n",
        "if len(np.unique(y_true))==2:\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, y_prob)\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "        print(f\"ROC AUC: {auc:.4f}\")\n",
        "        plt.figure(figsize=(5,4))\n",
        "        plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
        "        plt.plot([0,1],[0,1],'k--', linewidth=0.8)\n",
        "        plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC curve (val set)')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(\"ROC computation failed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "eoMnobIBIXq6",
        "outputId": "78c3e96a-3077-4236-fa10-16efa3d6506c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[23  0]\n",
            " [ 7  0]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87        23\n",
            "           1       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.77        30\n",
            "   macro avg       0.38      0.50      0.43        30\n",
            "weighted avg       0.59      0.77      0.67        30\n",
            "\n",
            "ROC AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "labels = [int(graphs[i].y.item()) for i in range(len(graphs)) if graphs[i].y.item()>=0]\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCNpOW8bIp1J",
        "outputId": "72f46c1b-729c-4c0c-d386-7a1866a423ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int64(0): np.int64(160), np.int64(1): np.int64(49)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np, torch\n",
        "\n",
        "classes = np.array([0,1])\n",
        "weights = compute_class_weight('balanced', classes=classes, y=labels)\n",
        "class_weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "print(\"Class weights:\", class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv4ZGLm9JDg0",
        "outputId": "225347c8-999f-4152-b6ca-8e5b65c6b24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: tensor([0.6531, 2.1327], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Retrain with class-weighted loss + subject-level stratified split ===\n",
        "import numpy as np, torch, os, pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Config\n",
        "OUT_DIR = Path('/content/drive/MyDrive/oasis_project/outputs')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "EPOCHS = 20\n",
        "BATCH = 8\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "P_DROP = 0.3\n",
        "\n",
        "# Load annotated mapping (should already exist)\n",
        "map_csv = Path('/content/drive/MyDrive/oasis_project/outputs/graph_label_mapping_annotated.csv')\n",
        "assert map_csv.exists(), \"Annotated mapping CSV missing.\"\n",
        "\n",
        "df_map = pd.read_csv(map_csv)\n",
        "# Ensure y column is integer\n",
        "df_map['y'] = df_map['y'].astype(int)\n",
        "\n",
        "# Build subject -> graph idx mapping for selected graphs (use only those with y>=0)\n",
        "valid_idx = df_map.index[df_map['y'] >= 0].tolist()\n",
        "subj2idx = defaultdict(list)\n",
        "for i in valid_idx:\n",
        "    sid = str(df_map.loc[i, 'subject_id'])\n",
        "    subj2idx[sid].append(int(i))\n",
        "\n",
        "# Compute subject-level label (majority label across the subject's graphs)\n",
        "subj_labels = {}\n",
        "for sid, idxs in subj2idx.items():\n",
        "    labs = [int(df_map.loc[i,'y']) for i in idxs]\n",
        "    subj_labels[sid] = int(np.bincount(labs).argmax())\n",
        "\n",
        "# Prepare subject list and stratify split by subject label\n",
        "subjects = list(subj_labels.keys())\n",
        "subject_labels_arr = np.array([subj_labels[s] for s in subjects])\n",
        "train_subj, val_subj = train_test_split(subjects, test_size=0.2, random_state=42, stratify=subject_labels_arr)\n",
        "\n",
        "train_idx = [i for s in train_subj for i in subj2idx[s]]\n",
        "val_idx   = [i for s in val_subj   for i in subj2idx[s]]\n",
        "print(\"Subjects: total\", len(subjects), \"train\", len(train_subj), \"val\", len(val_subj))\n",
        "print(\"Graphs: train\", len(train_idx), \"val\", len(val_idx))\n",
        "\n",
        "# Attach labels into graphs (ensure datatype)\n",
        "for i in df_map.index:\n",
        "    graphs[i].y = torch.tensor([int(df_map.loc[i,'y'])], dtype=torch.long)\n",
        "\n",
        "# Compute class weights (balanced) from the labels in training set\n",
        "train_labels = np.array([int(graphs[i].y.item()) for i in train_idx])\n",
        "classes = np.unique(train_labels)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "weights = compute_class_weight('balanced', classes=classes, y=train_labels)\n",
        "# map back to full set of classes (ensure index 0..C-1)\n",
        "max_cls = int(train_labels.max())\n",
        "full_weights = np.ones(max_cls+1, dtype=float)\n",
        "for c, w in zip(classes, weights):\n",
        "    full_weights[int(c)] = float(w)\n",
        "class_weights = torch.tensor(full_weights, dtype=torch.float).to(device)\n",
        "print(\"Class weights used:\", class_weights)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader([graphs[i] for i in train_idx], batch_size=BATCH, shuffle=True)\n",
        "val_loader   = DataLoader([graphs[i] for i in val_idx],   batch_size=BATCH, shuffle=False)\n",
        "\n",
        "# Model\n",
        "class TinySAGEReg(nn.Module):\n",
        "    def __init__(self, in_ch, hid=64, outc=2, p_drop=0.3):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_ch, hid)\n",
        "        self.conv2 = SAGEConv(hid, hid)\n",
        "        self.lin = nn.Linear(hid, outc)\n",
        "        self.drop = nn.Dropout(p_drop)\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index); x = F.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.drop(x)\n",
        "        return self.lin(x)\n",
        "\n",
        "in_ch = graphs[0].x.shape[1]\n",
        "n_classes = max(2, int(df_map['y'].max()+1))\n",
        "model = TinySAGEReg(in_ch, hid=64, outc=n_classes, p_drop=P_DROP).to(device)\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Training with best-val checkpointing\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch.x, batch.edge_index, batch.batch)\n",
        "        y = batch.y.view(-1).to(device)\n",
        "        # guard (should not be -1 in selected sets)\n",
        "        y[y < 0] = 0\n",
        "        loss = loss_fn(out, y)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        train_losses.append(float(loss.detach().cpu().numpy()))\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.batch)\n",
        "            y = batch.y.view(-1).to(device)\n",
        "            y[y < 0] = 0\n",
        "            loss = loss_fn(out, y)\n",
        "            val_losses.append(float(loss.detach().cpu().numpy()))\n",
        "    avg_train = np.mean(train_losses) if train_losses else float('nan')\n",
        "    avg_val = np.mean(val_losses) if val_losses else float('nan')\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} — train_loss: {avg_train:.4f} val_loss: {avg_val:.4f}\")\n",
        "    # checkpoint best\n",
        "    if avg_val < best_val_loss:\n",
        "        best_val_loss = avg_val\n",
        "        torch.save(model.state_dict(), OUT_DIR / \"model_best_weighted.pt\")\n",
        "        print(\"  -> saved best model\")\n",
        "\n",
        "# Load best model and evaluate\n",
        "model.load_state_dict(torch.load(OUT_DIR / \"model_best_weighted.pt\", map_location=device))\n",
        "model.to(device).eval()\n",
        "\n",
        "y_true_list, y_pred_list, y_prob_list = [], [], []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch.x, batch.edge_index, batch.batch)\n",
        "        probs = torch.softmax(out, dim=1)[:,1].cpu().numpy() if n_classes>1 else np.zeros(out.shape[0])\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        labs = batch.y.view(-1).cpu().numpy()\n",
        "        labs[labs < 0] = 0\n",
        "        y_true_list.append(labs); y_pred_list.append(preds); y_prob_list.append(probs)\n",
        "\n",
        "y_true = np.concatenate(y_true_list)\n",
        "y_pred = np.concatenate(y_pred_list)\n",
        "y_prob = np.concatenate(y_prob_list)\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, zero_division=0))\n",
        "if len(np.unique(y_true))==2:\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, y_prob)\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "        print(\"ROC AUC:\", auc)\n",
        "        plt.figure(figsize=(5,4))\n",
        "        plt.plot(fpr,tpr,label=f'AUC={auc:.3f}'); plt.plot([0,1],[0,1],'k--',linewidth=0.8)\n",
        "        plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC (val)'); plt.legend(); plt.show()\n",
        "    except Exception as e:\n",
        "        print(\"ROC error:\", e)\n",
        "\n",
        "# Save final model and mapping for reproducibility\n",
        "torch.save(model.state_dict(), OUT_DIR / \"model_final_weighted.pt\")\n",
        "df_map.to_csv(OUT_DIR / \"graph_label_mapping_annotated_saved.csv\", index=False)\n",
        "print(\"Done. Artifacts saved to:\", OUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B2q0fiDaJE3B",
        "outputId": "0b0ea0dc-ba11-4c12-a2a5-ff59244efd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subjects: total 209 train 167 val 42\n",
            "Graphs: train 167 val 42\n",
            "Class weights used: tensor([0.6523, 2.1410], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 — train_loss: 0.6879 val_loss: 0.6895\n",
            "  -> saved best model\n",
            "Epoch 2/20 — train_loss: 0.6837 val_loss: 0.6884\n",
            "  -> saved best model\n",
            "Epoch 3/20 — train_loss: 0.6814 val_loss: 0.6789\n",
            "  -> saved best model\n",
            "Epoch 4/20 — train_loss: 0.6749 val_loss: 0.6652\n",
            "  -> saved best model\n",
            "Epoch 5/20 — train_loss: 0.6539 val_loss: 0.6465\n",
            "  -> saved best model\n",
            "Epoch 6/20 — train_loss: 0.6289 val_loss: 0.6116\n",
            "  -> saved best model\n",
            "Epoch 7/20 — train_loss: 0.5998 val_loss: 0.5623\n",
            "  -> saved best model\n",
            "Epoch 8/20 — train_loss: 0.5266 val_loss: 0.4940\n",
            "  -> saved best model\n",
            "Epoch 9/20 — train_loss: 0.4683 val_loss: 0.4147\n",
            "  -> saved best model\n",
            "Epoch 10/20 — train_loss: 0.3621 val_loss: 0.3194\n",
            "  -> saved best model\n",
            "Epoch 11/20 — train_loss: 0.2838 val_loss: 0.2388\n",
            "  -> saved best model\n",
            "Epoch 12/20 — train_loss: 0.2152 val_loss: 0.1683\n",
            "  -> saved best model\n",
            "Epoch 13/20 — train_loss: 0.1522 val_loss: 0.1191\n",
            "  -> saved best model\n",
            "Epoch 14/20 — train_loss: 0.1109 val_loss: 0.0884\n",
            "  -> saved best model\n",
            "Epoch 15/20 — train_loss: 0.0853 val_loss: 0.0713\n",
            "  -> saved best model\n",
            "Epoch 16/20 — train_loss: 0.0588 val_loss: 0.0498\n",
            "  -> saved best model\n",
            "Epoch 17/20 — train_loss: 0.0507 val_loss: 0.0392\n",
            "  -> saved best model\n",
            "Epoch 18/20 — train_loss: 0.0368 val_loss: 0.0321\n",
            "  -> saved best model\n",
            "Epoch 19/20 — train_loss: 0.0312 val_loss: 0.0273\n",
            "  -> saved best model\n",
            "Epoch 20/20 — train_loss: 0.0295 val_loss: 0.0222\n",
            "  -> saved best model\n",
            "Confusion matrix:\n",
            " [[32  0]\n",
            " [ 0 10]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        32\n",
            "           1       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        42\n",
            "   macro avg       1.00      1.00      1.00        42\n",
            "weighted avg       1.00      1.00      1.00        42\n",
            "\n",
            "ROC AUC: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAGJCAYAAAAKUHMeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQi1JREFUeJzt3XlcVOXiBvBnWGYAkcVQFoVwyS1NEwIRlzSSUinLhaIE6aqZWBmVu5JYQpbmL8MoU1FL0VRIxURDyQ1FxyVL1AwUrwqCyiIgy8z7++Ne50YsAjJzZuD5fj7z6c6Zc2aeORd4fN9z5oxMCCFARERE1TKSOgAREZE+Y1ESERHVgkVJRERUCxYlERFRLViUREREtWBREhER1YJFSUREVAsWJRERUS1YlERERLVgURKRxtWrV2FmZobDhw9r7TXGjx8PV1dXzf1bt26hRYsW2LVrl9Zek+hhsCiJtCwmJgYymUxzMzExQdu2bTF+/Hhcu3at2m2EEFi/fj0GDhwIGxsbWFhYoGfPnggPD0dRUVGNrxUXF4fnn38ednZ2kMvlcHJywtixY7Fv3746ZQ0PD4enpye8vb0b9F4b4pFHHsGECRMwb948nb0mUX2wKIl0JDw8HOvXr0d0dDSef/55fP/99xg0aBDu3btXaT2VSoVXXnkFgYGBAICPPvoIy5YtQ+/evbFgwQL07dsX2dnZlbYRQiA4OBgvv/wysrOzERoaiujoaISEhCA9PR3PPPMMjhw5Umu+nJwcrF27FpMnT27cN14HkydPxsmTJ+tc6EQ6JYhIq9asWSMAiOPHj1daPmPGDAFAbNq0qdLyRYsWCQDigw8+qPJc27dvF0ZGRuK5556rtPyzzz4TAMS0adOEWq2ust26devEsWPHas25dOlSYW5uLgoLC+v61hokKChIPProo1WW9+jRQ4wbN06rr03UEBxREklkwIABAIC//vpLs6ykpASfffYZOnfujIiIiCrb+Pn5ISgoCLt378bRo0c120RERKBr1674/PPPIZPJqmw3btw4eHh41JonPj4enp6esLS01CybOnUqLC0tUVxcXGX9V199FQ4ODlCpVACAn376CcOHD4eTkxMUCgU6duyIhQsXah5/kGeffRY7duyA4BcakZ5hURJJ5PLlywAAW1tbzbJDhw7hzp07CAgIgImJSbXb3Z+S3blzp2ab27dvIyAgAMbGxg3KUl5ejuPHj6NPnz6Vlvv7+6OoqAgJCQmVlhcXF2PHjh0YPXq05jVjYmJgaWmJ0NBQ/N///R/c3Nwwf/58zJw5s04Z3NzckJeXhz/++KNB74FIW6r/TSSiRpefn4/c3Fzcu3cPx44dw4IFC6BQKDBixAjNOufOnQMA9OrVq8bnuf9YWlpapf/27NmzwdkyMzNRUlKC9u3bV1rev39/tG3bFps2bcKYMWM0yxMSElBUVAR/f3/Nsg0bNsDc3Fxzf/LkyZg8eTJWrFiBjz/+GAqFotYMHTp0APCffdCjR48GvxeixsYRJZGO+Pj4oHXr1nB2dsbo0aPRokULbN++He3atdOsU1hYCABo2bJljc9z/7GCgoJK/61tmwe5desWgMqjWwCQyWQYM2YMdu3ahbt372qWb9q0CW3btkX//v01y/5ekoWFhcjNzcWAAQNQXFyM8+fPPzDD/dfOzc1t8Psg0gYWJZGOREVFYe/evdiyZQuGDRuG3NzcKqOs+2V3vzCr888ytbKyeuA2dVXd8UF/f3+UlJRg+/btAIC7d+9i165dGDNmTKXjoX/88QdeeuklWFtbw8rKCq1bt8brr78O4D+j6bq+dnXHWImkxKIk0hEPDw/4+Phg1KhR2L59O3r06IGAgIBKI7Vu3boBAH777bcan+f+Y927dwcAdO3aFQBw9uzZBmd75JFHAAB37typ8ljfvn3h6uqKzZs3AwB27NiBkpKSStOueXl5GDRoEM6cOYPw8HDs2LEDe/fuxaeffgoAUKvVD8xw/7Xt7Owa/D6ItIFFSSQBY2NjRERE4Pr16/jqq680y/v37w8bGxts2LChxrNF161bBwCaY5v9+/eHra0tNm7cWOczTP/JxcUF5ubmyMjIqPbxsWPHYvfu3SgoKMCmTZvg6uqKvn37ah5PTk7GrVu3EBMTg3fffRcjRoyAj49Planc2tx/7fv/WCDSFyxKIok8/fTT8PDwwLJlyzQXHbCwsMAHH3yACxcuYM6cOVW2SUhIQExMDHx9fTVFZWFhgRkzZiAtLQ0zZsyodvr0+++/R2pqao1ZTE1N4e7ujhMnTlT7uL+/P0pLS7F27Vrs3r0bY8eOrfT4/TNf//7aZWVlWLFixQP2wv8olUpYW1vj8ccfr/M2RLrAs16JJPThhx9izJgxiImJ0VwRZ+bMmTh16hQ+/fRTpKSkYNSoUTA3N8ehQ4fw/fffo1u3bli7dm2V5/njjz+wZMkS7N+/H6NHj4aDgwOysrIQHx+P1NTUB16Z58UXX8ScOXNQUFCgOe55X58+fdCpUyfMmTMHpaWllaZdAaBfv36wtbVFUFAQ3nnnHchkMqxfv75en4ncu3cv/Pz8eIyS9I+UVzsgag5qujKPEEKoVCrRsWNH0bFjR1FRUVFp+Zo1a4S3t7ewsrISZmZm4vHHHxcLFiwQd+/erfG1tmzZIoYOHSpatWolTExMhKOjo/D39xfJyckPzJmdnS1MTEzE+vXrq318zpw5AoDo1KlTtY8fPnxY9O3bV5ibmwsnJycxffp0kZiYKACI/fv3a9ar7so8aWlpAoD45ZdfHpiTSNdkQvAyGET0H//6179w8eJFHDx4UKevO23aNBw4cABKpZIjStI7LEoi0sjMzETnzp2RlJSks28QuXXrFh599FFs3rwZw4YN08lrEtUHi5KIiKgWPOuViIioFixKIiKiWrAoiYiIasGiJCIiqkWzu+CAWq3G9evX0bJlS56GTkTUjAkhUFhYCCcnJxgZ1TxubHZFef36dTg7O0sdg4iI9MTVq1crfd3dPzW7orz/1URXr16tcpkuIiJqPgoKCuDs7PzA73JtdkV5f7rVysqKRUlERA88DMeTeYiIiGrBoiQiIqoFi5KIiKgWLEoiIqJasCiJiIhqwaIkIiKqBYuSiIioFpIW5YEDB+Dn5wcnJyfIZDLEx8c/cJvk5GT06dMHCoUCnTp1QkxMjNZzEhFR8yVpURYVFaFXr16Iioqq0/oZGRkYPnw4Bg8ejNOnT2PatGmYMGECEhMTtZyUiIiaK0mvzPP888/j+eefr/P60dHRaN++PZYsWQIA6NatGw4dOoQvvvgCvr6+2opZLSEESspVOn1NIiL6H3NTY518uYVBXcIuJSUFPj4+lZb5+vpi2rRpNW5TWlqK0tJSzf2CgoKHziGEwOjoFCiv3Hno5yIioroTQqDw5E5YdPHGxaWvwkKu/RozqJN5srKyYG9vX2mZvb09CgoKUFJSUu02ERERsLa21twa45tDSspVLEkiIh0TahVyf/oUBce2QV3y8IOeujKoEWVDzJo1C6GhoZr7968W31hOzPWBhdy40Z6PiIiqUqlUMDY2RkyHGxju9wJat24Nc1Pd/O01qKJ0cHBAdnZ2pWXZ2dmwsrKCubl5tdsoFAooFAqtZbKQG+tk6E9E1FwlJCRgxowZOHr0KKZMflPnr29QU69eXl5ISkqqtGzv3r3w8vKSKBEREWmLWq1GeHg4XnnlFcydOxeWlpaS5JB0KHT37l1cunRJcz8jIwOnT59Gq1at4OLiglmzZuHatWtYt24dAGDy5Mn46quvMH36dLzxxhvYt28fNm/ejISEBKneAhERacmSJUuwdu1aHD58GE888YRkOSQdUZ44cQJPPvkknnzySQBAaGgonnzyScyfPx8AcOPGDWRmZmrWb9++PRISErB371706tULS5YswXfffafzj4YQEZH2XLhwAcXFxZg8eTKOHz8uaUkCEo8on376aQghany8uqvuPP300zh16pQWUxERkVS2bduG8ePHY9WqVRgzZozUcQAY2DFKIiJqmlQqFebMmYPx48cjJiZGb0oSMLCzXomIqGnKycnBgQMHcPToUXTv3l3qOJWwKImISDJnz57Fr7/+iqlTp+LAgQM6uSRdfXHqlYiIJLF582b069cPt2/fBgC9LEmAI0oiIpLAvHnzsHz5cmzYsAF+fn5Sx6kVi5KIiHTm/qXo3NzckJqais6dO0sd6YE49UpERDpx6tQp9OjRA3/++SdGjhxpECUJsCiJiEgH1q9fjwEDBiAoKAidOnWSOk69cOqViIi06ueff8a7776LrVu3GuSV1FiURESkFdnZ2aioqICvry9+++03tGvXTupIDcKpVyIianSpqalwc3PDd999ByMjI4MtSYBFSUREjWzVqlUYPHgw3n//fc2XXBgyTr0SEVGjKSsrw6ZNm7Bjxw4MGTJE6jiNgiNKIiJ6aNevX0dYWBhMTU2xZ8+eJlOSAIuSiIge0uHDh+Hm5obMzEyUl5dLHafRsSiJiKjB1q1bh6FDh2LevHlYvXo15HK51JEaHY9REhFRvd2/FF2XLl2QmJiI/v37Sx1JaziiJCKierl69Sq8vLywe/dueHp6NumSBFiURERUD8nJyXBzc0OfPn0wePBgqePoBKdeiYioTv766y+MGDECy5Ytw4QJE6SOozMsSiIiqlVxcTGuXLmCbt264fz58wZ9lZ2G4NQrERHVKCMjA97e3vjoo48AoNmVJMCiJCKiGuzZswfu7u4YMGAAvv/+e6njSIZTr0REVK2NGzfiiy++QGBgoNRRJMURJRERady9exczZ85EUVER1qxZ0+xLEmBREhHRf/3555/o27cvjh8/jtLSUqnj6A0WJRER4ddff4WHhweee+45JCYmolWrVlJH0hs8RklE1Iyp1WoAQMeOHfHtt99izJgxEifSPxxREhE1U/n5+XjppZewdOlStGvXjiVZAxYlEVEzlJaWBk9PT5SWluKNN96QOo5eY1ESETUzxcXFGDx4MEaNGoWEhAQej3wAHqMkImomVCoVTp8+DTc3NyiVSrRt21bqSAaBRUlE1AzcuXMHr732Gv7973/j5MmTLMl64NQrEVETd/bsWTz11FMwMTHBwYMHYWLCMVJ9sCiJiJq4nTt3Yty4cYiPj4e1tbXUcQwO/1lBRNQEVVRUYOHChZgwYQJmzZoldRyDxhElEVETk5ubi+eeew5btmzhpegaAYuSiKgJ+fPPP+Hu7g5bW1scPXoUnTp1kjqSwWNREhE1ERUVFWjbti3mzp2LzZs3o2XLllJHahJYlEREBq68vBzvvvsuJk6cCAsLC0yYMAEymUzqWE0GT+YhIjJg2dnZGDt2LPLy8hAXFyd1nCaJRUlEZKCEEBg5ciTat2+PXbt2oUWLFlJHapJYlEREBig1NRUeHh7Ytm0bHBwcONWqRTxGSURkQEpLSzF58mQMHz4cOTk5cHR0ZElqGUeUREQG4vr16xg1ahTKy8uhVCrRunVrqSM1C5KPKKOiouDq6gozMzN4enoiNTW11vWXLVuGLl26wNzcHM7Oznjvvfdw7949HaUlIpJOamoqunTpgoMHD8LFxUXqOM2GpCPKTZs2ITQ0FNHR0fD09MSyZcvg6+uLCxcuoE2bNlXW37BhA2bOnInVq1ejX79+uHjxIsaPHw+ZTIalS5dK8A6IiLRLCIGvv/4avXr1wsiRIzFy5EipIzU7ko4oly5diokTJyI4OBjdu3dHdHQ0LCwssHr16mrXP3LkCLy9vREQEABXV1cMHToUr7766gNHoUREhujevXt44403EB4eLnWUZk2yoiwrK4NSqYSPj8//whgZwcfHBykpKdVu069fPyiVSk0xpqenY9euXRg2bFiNr1NaWoqCgoJKNyIifZeXl4cBAwYgLS0NSqUS3t7eUkdqtiSbes3NzYVKpYK9vX2l5fb29jh//ny12wQEBCA3Nxf9+/eHEAIVFRWYPHkyZs+eXePrREREYMGCBY2anYhIm8rLy2FtbY1JkyYhMDAQCoVC6kjNmuQn89RHcnIyFi1ahBUrVuDkyZPYtm0bEhISsHDhwhq3mTVrFvLz8zW3q1ev6jAxEVHdCSHwxRdfYODAgQCAiRMnsiT1gGQjSjs7OxgbGyM7O7vS8uzsbDg4OFS7zbx58zBu3DhMmDABANCzZ08UFRVh0qRJmDNnDoyMqva+QqHgDxoR6b3i4mJMnDgRycnJ2Lp1Kz8bqUckG1HK5XK4ubkhKSlJs0ytViMpKQleXl7VblNcXFylDI2NjQH8519iRESG6p133kFmZiaUSiX69u0rdRz6G0k/HhIaGoqgoCC4u7vDw8MDy5YtQ1FREYKDgwEAgYGBaNu2LSIiIgAAfn5+WLp0KZ588kl4enri0qVLmDdvHvz8/DSFSURkSFJTU+Hm5obIyEhYWVlBLpdLHYn+QdKi9Pf3R05ODubPn4+srCz07t0bu3fv1pzgk5mZWWkEOXfuXMhkMsydOxfXrl1D69at4efnh08++USqt0BE1CBCCCxevBjh4eE4cOAA3NzcpI5ENZCJZjZnWVBQAGtra+Tn58PKyqpBz1FcVoHu8xMBAOfCfWEh55UAiaju7t69i+DgYKSmpmLbtm0sSYnUtQ/4F56ISMcyMjJw7949nDhxgtdrNQAsSiIiHdm5cyfy8vLw+uuvY8eOHVLHoToyqM9REhEZIrVajfDwcLz66qs8WccAcURJRKRFarUao0aNwm+//YbDhw/jiSeekDoS1RNHlEREWlJeXg4jIyP4+/vj+PHjLEkDxaIkItKCbdu2oWvXrigoKMArr7yCVq1aSR2JGohTr0REjUilUmH+/PlYvnw5YmJiGvwxNNIfLEoiokb05ZdfYsuWLTh69Ci6d+8udRxqBJx6JSJqBL///jvy8/MxefJkpKamsiSbEBYlEdFDio2NhZeXFxITE2Fubg5ra2upI1Ej4tQrEVEDVVRUYObMmfjuu++wceNGjBgxQupIpAUsSiKiBsrLy8Pvv/+O1NRUdO7cWeo4pCWceiUiqqeTJ08iIiICdnZ22L17N0uyiWNREhHVw7p16zBw4EDIZDJ+YXwzwalXIqI6mjVrFr755hts3boVvr6+UschHeGIkojoAcrKygAAQ4YMwYkTJ1iSzQyLkoioFseOHUOXLl1w7tw5PPvss+jQoYPUkUjHWJRERDX47rvvMGTIELzzzjvo1q2b1HFIIjxGSURUjb1792LWrFnYuXMnBg8eLHUckhCLkojob65fv4579+7Bx8cHf/zxB9q0aSN1JJIYp16JiP7r0KFD6NOnD9avXw+ZTMaSJAAsSiIiCCGwYsUK+Pr6Yt68eZg/f77UkUiPcOqViJo9lUqFpKQkJCYmon///lLHIT3DESURNVuZmZkIDQ2FTCbD1q1bWZJULRYlETVL+/fvh5ubG4qLi6FSqaSOQ3qMRUlEzc6aNWswYsQIREREIDo6GnK5XOpIpMd4jJKImo2ysjLI5XK4ublh37598PT0lDoSGQCOKImoWUhPT8dTTz2F+Ph4PPHEEyxJqjMWJRE1eXv27IG7uzuefvppDB8+XOo4ZGA49UpETdrly5cxevRoREVFYdy4cVLHIQPEoiSiJunu3bu4ePEi+vTpg7/++gutW7eWOhIZKE69ElGT8+eff8LT0xORkZEAwJKkh8KiJKImZefOnXjqqacwbNgwbNiwQeo41ARw6pWImpQ9e/YgOjoar7zyitRRqIngiJKIDF5+fj7efvtt5OXl4csvv2RJUqNiURKRQUtLS4OHhwcuXboEIYTUcagJYlESkcFKTk6Gp6cnRo8ejZ07d8LW1lbqSNQE8RglERkclUoFIQQef/xxfP/993jhhRekjkRNGEeURGRQ7ty5gxEjRiAyMhKtW7dmSZLWsSiJyGD89ttvcHd3h6mpKd5++22p41AzwaIkIoNw7949PP/88wgKCkJ8fDysra2ljkTNBI9REpFeq6iowNGjR9G/f3+cOXMGdnZ2UkeiZoZFSUR6Kzc3F6+88gpyc3Nx/PhxliRJglOvRKSXTp48CXd3d9ja2uLQoUMwNTWVOhI1UyxKItJLhw4dwltvvYXNmzfD0tJS6jjUjElelFFRUXB1dYWZmRk8PT2Rmppa6/p5eXkICQmBo6MjFAoFOnfujF27dukoLRFpU3l5OaZPn46LFy/inXfewYwZMyCTyaSORc2cpEW5adMmhIaGIiwsDCdPnkSvXr3g6+uLmzdvVrt+WVkZnn32WVy+fBlbtmzBhQsXsHLlSrRt21bHyYmosWVnZ+OZZ57Bnj17OM1KekXSoly6dCkmTpyI4OBgdO/eHdHR0bCwsMDq1aurXX/16tW4ffs24uPj4e3tDVdXVwwaNAi9evXScXIiakyXLl2Cm5sbXFxccOTIEbRv317qSEQakhVlWVkZlEolfHx8/hfGyAg+Pj5ISUmpdpvt27fDy8sLISEhsLe3R48ePbBo0SKoVKoaX6e0tBQFBQWVbkSkP0pLS+Hi4oLFixdj/fr1sLCwkDoSUSWSFWVubi5UKhXs7e0rLbe3t0dWVla126Snp2PLli1QqVTYtWsX5s2bhyVLluDjjz+u8XUiIiJgbW2tuTk7Ozfq+yCihiktLcWbb76J8ePHQy6XIyAggMcjSS8Z1Oco1Wo12rRpg2+//RbGxsZwc3PDtWvX8NlnnyEsLKzabWbNmoXQ0FDN/YKCApYlkcSuX7+OUaNGoaKiAtu2bZM6DlGtJCtKOzs7GBsbIzs7u9Ly7OxsODg4VLuNo6MjTE1NYWxsrFnWrVs3ZGVloaysDHK5vMo2CoUCCoWiccMTUYMJIeDv749u3bphxYoVMDMzkzoSUa0km3qVy+Vwc3NDUlKSZplarUZSUhK8vLyq3cbb2xuXLl2CWq3WLLt48SIcHR2rLUki0h9CCOzfvx8ymQzx8fFYtWoVS5IMgqRnvYaGhmLlypVYu3Yt0tLS8NZbb6GoqAjBwcEAgMDAQMyaNUuz/ltvvYXbt2/j3XffxcWLF5GQkIBFixYhJCREqrdARHVw7949vPHGGwgICEBWVhYeeeQRHo8kgyHpMUp/f3/k5ORg/vz5yMrKQu/evbF7927NCT6ZmZkwMvpflzs7OyMxMRHvvfcennjiCbRt2xbvvvsuZsyYIdVbIKIHyMzMxKhRo2BqagqlUlnjoRUifSUTQgipQ+hSQUEBrK2tkZ+fDysrqwY9R3FZBbrPTwQAnAv3hYXcoM6JItKpPXv2IC4uDsuWLeP5AqRX6toH/AtPRI1OCIFly5bh8ccfx9ChQzF06FCpIxE1mOTXeiWipqW4uBivv/46lixZAhsbG6njED00jiiJqNEUFBRg4MCBsLKyglKprHJBESJDxKIkokZx7949tGzZEjNnztScvEPUFHDqlYgeihACkZGR6Nu3L4QQeOWVV1iS1KRwRElEDVZYWIg33ngDqampiIuLq/RxLqKmgkVJRA02ffp03LlzB0qlEnZ2dlLHIdIKFiUR1duBAwfg5eWFyMhItGjRAiYm/FNCTRfnSYioztRqNcLDwzF8+HCcOXMG1tbWLElq8vgTTkR1kp+fj8DAQPz+++84fPgwnnjiCakjEelEo40ot23bxl8coibs5s2bMDMzw4kTJ/i7Ts1KvYrym2++wejRoxEQEIBjx44BAPbt24cnn3wS48aNg7e3t1ZCEpF0tm3bhujoaDz22GPYtGkTbG1tpY5EpFN1LsrIyEi8/fbbuHz5MrZv344hQ4Zg0aJFeO211+Dv749///vf+Prrr7WZlYh0SKVSYfbs2Rg/fjyvsEPNWp2PUa5ZswYrV65EUFAQDh48iEGDBuHIkSO4dOkSWrRooc2MRKRjQgiMHDkSf/75J44dO4Zu3bpJHYlIMnUuyszMTAwZMgQAMGDAAJiammLBggUsSaImpqSkBObm5pg0aRIGDRrU4K+jI2oq6jz1WlpaCjMzM819uVyOVq1aaSUUEUkjNjYWjz32GPLy8uDn58eSJEI9Px4yb948WFhYAADKysrw8ccfw9rautI6S5cubbx0RKQTFRUVmDlzJr777jv88MMP/Hosor+pc1EOHDgQFy5c0Nzv168f0tPTK60jk8kaLxkR6Ux0dDR+/vlnHD9+HI899pjUcYj0Sp2LMjk5WYsxiEgKp06dgrOzM958802MHz8elpaWUkci0jv1+hxlQUEB9u7di4SEBOTk5GgrExHpwLp16zBgwAAkJSXB1NSUJUlUgzqPKE+fPo1hw4YhKysLANCyZUts3rwZvr6+WgtHRI2vvLwc77//Pn744Qds27YNQ4cOlToSkV6r84hyxowZaN++PQ4fPgylUolnnnkGU6dO1WY2ItKC4uJiXLt2DcePH2dJEtVBnUeUSqUSe/bsQZ8+fQAAq1evRqtWrVBQUMBTyIkMwLFjxxAfH49FixZh69atUschMhh1HlHevn0b7dq109y3sbFBixYtcOvWLa0EI6LGs3LlSgwZMgRt2rSROgqRwanX5yjPnTunOUYJ/OcyV2lpaSgsLNQs47cKEOmXGTNmYPXq1di5cycGDx4sdRwig1OvonzmmWcghKi0bMSIEZDJZBBCQCaTQaVSNWpAImqY+5ei8/PzQ0hICFxcXKSORGSQ6lyUGRkZ2sxBRI3o0KFD8Pf3x88//4z+/ftLHYfIoNW5KNeuXYsPPvhAcwk7ItI/QgisWLEC06dPx2effYaePXtKHYnI4NX5ZJ4FCxbg7t272sxCRA8pOTkZCxcuRGJiIqZMmcLLShI1gjqPKP95bJKI9MeVK1dQVFSEwYMH4/z587yoOVEjqtcl7PivUyL9s3//fri7u2PLli0AwJIkamT1Ouu1c+fODyzL27dvP1QgIqobIQS++OILzJs3D//3f/+HCRMmSB2JqEmqV1EuWLCgyvdPEpE01Go1fvvtN+zbtw+enp5SxyFqsupVlK+88gqv7EEksfT0dERGRuKrr75CTEyM1HGImrw6H6Pk8Uki6SUmJsLd3R3m5ub8nSTSEZ71SmQgVq9ejXfeeQfR0dF4/fXXpY5D1GzUuSjVarU2cxBRDYqLi2Fubo4BAwbgwIEDmm/wISLdqNfHQ4hIty5evIinnnoKmzdvxmOPPcaSJJIAi5JIT+3cuRMeHh4YPnw4Ro0aJXUcomarXme9EpFu/Pvf/0ZgYCC++eYb+Pv7Sx2HqFljURLpkfz8fPz+++/w9vZGRkYGP7dMpAc49UqkJ86dOwcPDw98+eWXAMCSJNITLEoiPbBt2zb07dsXY8aMwYYNG6SOQ0R/w6lXIj2gVCqxdu1avPTSS1JHIaJ/4IiSSCK3b9/GG2+8gZs3b+KTTz5hSRLpKb0oyqioKLi6usLMzAyenp5ITU2t03axsbGQyWQYOXKkdgMSNbIzZ87A3d0dt27dgkKhkDoOEdVC8qLctGkTQkNDERYWhpMnT6JXr17w9fXFzZs3a93u8uXL+OCDDzBgwAAdJSVqHMnJyejfvz+Cg4MRFxfHk3aI9JzkRbl06VJMnDgRwcHB6N69O6Kjo2FhYYHVq1fXuI1KpcJrr72GBQsWoEOHDjpMS9RwFRUVKC0txZNPPomtW7di3rx5MDKS/FeQiB5A0t/SsrIyKJVK+Pj4aJYZGRnBx8cHKSkpNW4XHh6ONm3a4F//+tcDX6O0tBQFBQWVbkS6lpOTA19fX3z88cewtrbG0KFDpY5ERHUkaVHm5uZCpVLB3t6+0nJ7e3tkZWVVu82hQ4ewatUqrFy5sk6vERERAWtra83N2dn5oXMT1YdSqYS7uztatWqFGTNmSB2HiOrJoOZ9CgsLMW7cOKxcuRJ2dnZ12mbWrFnIz8/X3K5evarllET/U1pailGjRmHKlCnYvHkzLC0tpY5ERPUk6eco7ezsYGxsjOzs7ErLs7Oz4eDgUGX9v/76C5cvX4afn59m2f2v/zIxMcGFCxfQsWPHStsoFAqeVUg6V1ZWhv3798PX1xe//fYbrKyspI5ERA0k6YhSLpfDzc0NSUlJmmVqtRpJSUnw8vKqsn7Xrl1x9uxZnD59WnN74YUXMHjwYJw+fZrTqqQXsrKy8Mwzz2D27NkoKytjSRIZOMmvzBMaGoqgoCC4u7vDw8MDy5YtQ1FREYKDgwEAgYGBaNu2LSIiImBmZoYePXpU2t7GxgYAqiwnksLRo0cxatQoDB48GN9++y3kcrnUkYjoIUlelP7+/sjJycH8+fORlZWF3r17Y/fu3ZoTfDIzM3kKPRmMtLQ0fPjhh3j33Xchk8mkjkNEjUAmhBBSh9ClgoICWFtbIz8/v8FTYsVlFeg+PxEAcC7cFxZyyf+9QRIqLS3FBx98gAkTJqBXr15SxyGiOqprH3CoRvQQrl27hkGDBuHo0aNo1aqV1HGISAtYlEQN9Ndff8HNzQ3du3fHwYMHeTIZURPFOUOiehJCoLi4GK6uroiOjsaLL77I45FETRhHlET1UFJSguDgYIwbNw7GxsYYOXIkS5KoieOIkqiOrly5gpdffhkKhQJbtmyROg4R6QhHlER1FBwcDA8PDyQnJ8PJyUnqOESkIxxREtVCCIGdO3dixIgRiI+P51V2iJohjiiJalBUVITXXnsNb731Fm7cuMGSJGqmWJRE1UhPT0e/fv1w7do1KJVKTrUSNWMsSqJqXL9+HUOGDMEvv/xS5ftSiah54TFKov8SQuDTTz9F586d8fLLL6N///5SRyIiPcARJRH+86XgY8aMQXR0NFxdXaWOQ0R6hCNKavaKiorQt29fODo64sSJE7Czs5M6EhHpERYlNWt3796FpaUlIiMj8fzzz8PEhL8SRFQZp16pWVKr1QgPD4eHhwdUKhX8/PxYkkRULf5loGYnPz8fgYGB+P333xEfHw9jY2OpIxGRHmNRUrMzb948lJeX48SJE7C1tZU6DhHpORYlNRuJiYkYOHAgIiMjoVAoOJIkojrhMUpq8lQqFWbPno2xY8fi999/h4WFBUuSiOqMI0pq0m7fvo2AgABcvnwZR48eRbdu3aSOREQGhiNKatLu3r0LR0dHpKamsiSJqEE4oqQmKTY2FpmZmZg+fTrWrFkjdRwiMmAcUVKTUlFRgffffx9vvfUWevToIXUcImoCOKKkJkMIgRdffBGZmZk4fvw4OnXqJHUkImoCWJTUJBQWFqJly5Z4//334eHhAUtLS6kjEVETwalXMnhr165Fx44dcevWLQwZMoQlSUSNiiNKMljl5eUIDQ3Fhg0bEBsbi0ceeUTqSETUBLEoyWCtXr0ahw4dwokTJ9C+fXup4xBRE8WpVzI4x44dw7Vr1zBhwgQcOXKEJUlEWsWiJIOycuVKDBkyBIcOHYKxsTHMzc2ljkRETRynXskglJaW4p133kFcXBwSEhLw9NNPSx2JiJoJFiUZhIqKCpSWlkKpVMLZ2VnqOETUjHDqlfTaoUOHEBISAgsLC8TExLAkiUjnWJSkl4QQiIqKgq+vLy9FR0SS4tQr6aXp06fj+++/x549e+Dt7S11HCJqxjiiJL1SUFAAAHj11VehVCpZkkQkORYl6Y19+/ahU6dOUCqV6NOnD5ycnKSORETEoiTpCSGwdOlS+Pn5ISIiAm5ublJHIiLS4DFKktyRI0fwxRdfYP/+/fDw8JA6DhFRJSxKkkx6ejry8vLg7e2N8+fPo0WLFlJHIiKqglOvJInExES4u7sjISEBAFiSRKS3WJSkU0IIREZGYtSoUfjyyy8xb948qSMREdWKU6+kU0IIXL9+HQcOHECfPn2kjkNE9EAcUZJOXLx4EQEBASgtLcWXX37JkiQig8GiJK3bsWMHPDw80K5dO5iamkodh4ioXvSiKKOiouDq6gozMzN4enoiNTW1xnVXrlyJAQMGwNbWFra2tvDx8al1fZLWqlWrEBAQgG+++QaLFy+GiQln+4nIsEhelJs2bUJoaCjCwsJw8uRJ9OrVC76+vrh582a16ycnJ+PVV1/F/v37kZKSAmdnZwwdOhTXrl3TcXKqTWFhIdRqNZ599lkcOXIE/v7+UkciImoQyYty6dKlmDhxIoKDg9G9e3dER0fDwsICq1evrnb9H374AVOmTEHv3r3RtWtXfPfdd1Cr1UhKStJxcqrJuXPn4Obmhh9++AEuLi7o2bOn1JGIiBpM0qIsKyuDUqmEj4+PZpmRkRF8fHyQkpJSp+coLi5GeXk5WrVqVe3jpaWlKCgoqHQj7dm6dSv69u2LsWPHIiAgQOo4REQPTdKizM3NhUqlgr29faXl9vb2yMrKqtNzzJgxA05OTpXK9u8iIiJgbW2tufGLf7Xnxo0bmDJlCtatW4ePP/4YxsbGUkciInpokk+9PozIyEjExsYiLi4OZmZm1a4za9Ys5Ofna25Xr17Vccqm7/bt2/jll1/g6OiIjIwMjBw5UupIRESNRtKitLOzg7GxMbKzsystz87OhoODQ63bfv7554iMjMSePXvwxBNP1LieQqGAlZVVpRs1njNnzsDd3R2rVq0CAFhYWEiciIiocUlalHK5HG5ubpVOxLl/Yo6Xl1eN2y1evBgLFy7E7t274e7urouoVI2NGzfC29sbwcHB+OGHH6SOQ0SkFZJ/qC00NBRBQUFwd3eHh4cHli1bhqKiIgQHBwMAAgMD0bZtW0RERAAAPv30U8yfPx8bNmyAq6ur5limpaUlLC0tJXsfzdGVK1ewadMmDB8+XOooRERaI3lR+vv7IycnB/Pnz0dWVhZ69+6N3bt3a07wyczMhJHR/wa+X3/9NcrKyjB69OhKzxMWFoaPPvpIl9GbpZycHEydOhVLlizBzJkzpY5DRKR1khclAEydOhVTp06t9rHk5ORK9y9fvqz9QFQtpVKJl19+GR4eHrCxsZE6DhGRThj0Wa+kO7/++isGDRqEkJAQbN68mdPcRNRs6MWIkvRXeXk5ysrK8NRTT2HXrl0YOHCg1JGIiHSKI0qqUVZWFoYMGYLw8HBYWFiwJImoWWJRUrWOHj0KNzc3PProowgLC5M6DhGRZFiUVEV5eTkCAwPx4YcfYv369byIABE1azxGSRqlpaVISEjAyy+/jNOnT7MgiYjAoqT/unbtGkaNGgW1Wo1hw4axJImI/otTr4SDBw/Czc0N3bt3x4EDB2q8wDwRUXPEESUhKysLYWFhmDx5MmQymdRxiIj0CouymSopKcHbb7+NCRMmYMyYMVLHISLSWyzKZujKlSt4+eWXoVAo4OLiInUcIiK9xmOUzUxGRgbc3Nzg4eGB5ORkODk5SR2JiEivcUTZTAghkJeXB1dXV2zcuBHPPvus1JGIiAwCR5TNQFFREQICAjBu3DjIZDKWJBFRPbAom7i//voLXl5euHHjBlavXi11HCIig8OibOJCQkIwZMgQ7N27F23atJE6DhGRweExyiZICIFNmzZh7NixiIuLg7m5udSRiIgMFouyiSksLMT48eOhVCrRv39/tGvXTupIREQGjVOvTcjFixfh6emJgoICnDhxgiVJRNQIWJRNyN27dzFy5Ej8/PPPsLOzkzoOEVGTwKlXA6dWqxEeHo4OHTogMDAQffr0kToSEVGTwqI0YPn5+Xj99deRlpaGuLg4qeMQETVJnHo1UCUlJfD09IRKpcLx48fRs2dPqSMRETVJHFEaoNu3b6NVq1ZYsWIFBg0aBGNjY6kjERE1WRxRGhCVSoVZs2bB09MTFRUVGDJkCEuSiEjLOKI0ELdv38arr76KK1euYPv27TAx4f91RES6wL+2BiIiIgLm5uZITU2FlZWV1HGIiJoNFqWei4+PxzPPPIOPP/4YpqamMDLibDkRkS7xr66eqqiowPvvv4/g4GCkpaVBoVCwJImIJMARpR7KycmBv78/cnJycPz4cXTq1EnqSEREzRaLUg+p1Wp069YN27dvh6WlpdRxiAyWEAIVFRVQqVRSRyEJGBsbw8TEBDKZ7KGeh0WpR9auXYtLly5h4cKFiIqKkjoOkUErKyvDjRs3UFxcLHUUkpCFhQUcHR0hl8sb/BwsSj1QVlaG0NBQbNy4EbGxsVLHITJ4arUaGRkZMDY2hpOTE+Ry+UOPKsiwCCFQVlaGnJwcZGRk4LHHHmvweR4sSokJIfDiiy8iKysLJ06cQPv27aWORGTwysrKoFar4ezsDAsLC6njkETMzc1hamqKK1euoKysDGZmZg16HhalhG7duoVHHnkE8+fPR69evfgLTdTIeKY4NcbPAH+KJPLtt9+iU6dOuHnzJry8vFiSRER6iiNKHSstLcXUqVPx008/IT4+Hm3atJE6EhER1YJFqWMbN27EmTNnoFQq4ezsLHUcIiJ6AE696sjBgweRnp6OoKAgHDx4kCVJRLVKSUmBsbExhg8fXml5cnIyZDIZ8vLyqmzj6uqKZcuWVVq2f/9+DBs2DI888ggsLCzQvXt3vP/++7h27VqDch04cAB+fn5wcnKCTCZDfHx8nbZLTk5Gnz59oFAo0KlTJ8TExFRZJyoqCq6urjAzM4OnpydSU1MrPX7v3j2EhITgkUcegaWlJUaNGoXs7OwGvY/6YFFqmRACy5cvx3PPPYcTJ05AJpNBoVBIHYuI9NyqVavw9ttv48CBA7h+/XqDnuObb76Bj48PHBwcsHXrVpw7dw7R0dHIz8/HkiVLGvScRUVF6NWrV70+652RkYHhw4dj8ODBOH36NKZNm4YJEyYgMTFRs86mTZsQGhqKsLAwnDx5Er169YKvry9u3rypWee9997Djh078OOPP+LXX3/F9evX8fLLLzfofdSLaGby8/MFAJGfn9/g5ygqLRePztgpHp2xUxSVlte4XnFxsQgMDBQODg7i8OHDDX49IqqfkpISce7cOVFSUqJZplarRVFpuSQ3tVpdr/yFhYXC0tJSnD9/Xvj7+4tPPvlE89j+/fsFAHHnzp0q2z366KPiiy++EEIIcfXqVSGXy8W0adOqfY3qtq8vACIuLu6B602fPl08/vjjlZb5+/sLX19fzX0PDw8REhKiua9SqYSTk5OIiIgQQgiRl5cnTE1NxY8//qhZJy0tTQAQKSkpNb52dT8L99W1D3iMUouMjIxgaWkJpVIJJycnqeMQNWsl5Sp0n5/44BW14Fy4Lyzkdf9zu3nzZnTt2hVdunTB66+/jmnTpmHWrFn1umjCjz/+iLKyMkyfPr3ax21sbAAAmZmZ6N69e63PNXv2bMyePbvOr/1PKSkp8PHxqbTM19cX06ZNA/Cfz70qlUrMmjVL87iRkRF8fHyQkpICAFAqlSgvL6/0PF27doWLiwtSUlLQt2/fBud7EBalFuzbtw9r1qzB2rVreSk6Iqq3VatW4fXXXwcAPPfcc8jPz8evv/6Kp59+us7P8eeff8LKygqOjo61rufk5ITTp0/Xuk6rVq3q/LrVycrKgr29faVl9vb2KCgoQElJCe7cuQOVSlXtOufPn9c8h1wu1xT839fJysp6qHwPwqJsREIIfPHFF5g3bx6WL1/ODzsT6RFzU2OcC/eV7LXr6sKFC0hNTUVcXBwAwMTEBP7+/li1alW9ilIIUacRqImJCb+h6AFYlI1o+vTpiI2Nxf79++Hh4SF1HCL6G5lMVq/pT6msWrUKFRUVlQ7XCCGgUCjw1VdfwcrKCgCQn59fZXSVl5cHa2trAEDnzp2Rn5+PGzdu1Dqq1MXUq4ODQ5WzU7Ozs2FlZQVzc3MYGxvD2Ni42nUcHBw0z1FWVoa8vLxK7/vv62iLXgx5HnRK8D/9+OOP6Nq1K8zMzNCzZ0/s2rVLR0mrl5ubCwAIDg6GUqlkSRJRg1RUVGDdunVYsmQJTp8+rbmdOXMGTk5O2Lhxo+bi3kqlstK26enpyM/PR+fOnQEAo0ePhlwux+LFi6t9rfsfL7k/9VrbbfLkyQ/1vry8vJCUlFRp2d69e+Hl5QUAkMvlcHNzq7SOWq1GUlKSZh03NzeYmppWWufChQvIzMzUrKM1tZ7qowOxsbFCLpeL1atXiz/++ENMnDhR2NjYiOzs7GrXP3z4sDA2NhaLFy8W586dE3PnzhWmpqbi7NmzdXq9xj7rNX5HgrC1tRVHjx5t8PMRUeOq7UxHfRYXFyfkcrnIy8ur8tj06dOFu7u7EEKISZMmCVdXV/HTTz+J9PR08euvv4q+ffuKvn37VjrDNioqSshkMvHGG2+I5ORkcfnyZXHo0CExadIkERoa2qCMhYWF4tSpU+LUqVMCgFi6dKk4deqUuHLlimadmTNninHjxmnup6enCwsLC/Hhhx+KtLQ0ERUVJYyNjcXu3bs168TGxgqFQiFiYmLEuXPnxKRJk4SNjY3IysrSrDN58mTh4uIi9u3bJ06cOCG8vLyEl5dXrXkb46xXyYvyQacE/9PYsWPF8OHDKy3z9PQUb775Zp1er7GK0mX6DmEzMFC0aNFCrF+/vsHPRUSNz1CLcsSIEWLYsGHVPnbs2DEBQJw5c0aUlJSIsLAw0bVrV2Fubi7at28vJk2aJHJycqpst3fvXuHr6ytsbW2FmZmZ6Nq1q/jggw/E9evXG5Tx/sdT/nkLCgrSrBMUFCQGDRpUZbvevXsLuVwuOnToINasWVPluZcvXy5cXFyEXC4XHh4eVQYgJSUlYsqUKcLW1lZYWFiIl156Sdy4caPWvI1RlDIhhNDumLVmZWVlsLCwwJYtWzBy5EjN8qCgIOTl5eGnn36qso2LiwtCQ0M1pxUDQFhYGOLj43HmzJkq65eWlqK0tFRzv6CgAM7OzsjPz9fM9ddXcVkFOk5cjtyfPsWve3agn8dTDXoeItKOe/fuISMjA+3bt2/wVytR01Dbz0JBQQGsra0f2AeSHqPMzc2t8ZTgmk73rek045rWj4iIgLW1tebWWJeOUzh2htOEaPTu/WSjPB8REeknvTiZR5tmzZqF/Px8ze3q1asP/Zz3TzNPWzSiXqd9ExGR4ZH0XGk7O7sHnhL8TzWdZlzT+gqFotGvrWoop5kTEdHDk3REWZdTgv/pQacZExERNSbJh0WhoaEICgqCu7s7PDw8sGzZMhQVFSE4OBgAEBgYiLZt2yIiIgIA8O6772LQoEFYsmQJhg8fjtjYWJw4cQLffvutlG+DiPSQhOcqkp5ojJ8ByYvS398fOTk5mD9/PrKystC7d2/s3r1bc8JOZmZmpUvB9evXDxs2bMDcuXMxe/ZsPPbYY4iPj0ePHj2kegtEpGdMTU0BAMXFxTA3N5c4DUmpuLgYwP9+JhpC0o+HSKGupwMTkWG7ceMG8vLy0KZNG1hYWNTrmzfI8AkhUFxcjJs3b8LGxqbay/jVtQ8kH1ESEWnD/RP8/v7Fv9T82NjYPPS1YFmURNQkyWQyODo6ok2bNigvL5c6DknA1NQUxsYP/xE+FiURNWn3v5mCqKGa/AUHiIiIHgaLkoiIqBYsSiIiolo0u2OU9z8NU1BQIHESIiKS0v0eeNCnJJtdURYWFgJAo32LCBERGbbCwkJYW1vX+Hizu+CAWq3G9evX0bJly4f6APL977W8evUqL1zwN9wvNeO+qR73S824b6rXWPtFCIHCwkI4OTlVugLcPzW7EaWRkRHatWvXaM9nZWXFH+BqcL/UjPumetwvNeO+qV5j7JfaRpL38WQeIiKiWrAoiYiIasGibCCFQoGwsLBG/1JoQ8f9UjPum+pxv9SM+6Z6ut4vze5kHiIiovrgiJKIiKgWLEoiIqJasCiJiIhqwaIkIiKqBYuyFlFRUXB1dYWZmRk8PT2Rmppa6/o//vgjunbtCjMzM/Ts2RO7du3SUVLdqs9+WblyJQYMGABbW1vY2trCx8fngfvRkNX3Z+a+2NhYyGQyjBw5UrsBJVLf/ZKXl4eQkBA4OjpCoVCgc+fO/H36r2XLlqFLly4wNzeHs7Mz3nvvPdy7d09HaXXjwIED8PPzg5OTE2QyGeLj4x+4TXJyMvr06QOFQoFOnTohJiam8QIJqlZsbKyQy+Vi9erV4o8//hATJ04UNjY2Ijs7u9r1Dx8+LIyNjcXixYvFuXPnxNy5c4Wpqak4e/asjpNrV333S0BAgIiKihKnTp0SaWlpYvz48cLa2lr8+9//1nFy7avvvrkvIyNDtG3bVgwYMEC8+OKLugmrQ/XdL6WlpcLd3V0MGzZMHDp0SGRkZIjk5GRx+vRpHSfXvvrumx9++EEoFArxww8/iIyMDJGYmCgcHR3Fe++9p+Pk2rVr1y4xZ84csW3bNgFAxMXF1bp+enq6sLCwEKGhoeLcuXNi+fLlwtjYWOzevbtR8rAoa+Dh4SFCQkI091UqlXBychIRERHVrj927FgxfPjwSss8PT3Fm2++qdWculbf/fJPFRUVomXLlmLt2rXaiiiZhuybiooK0a9fP/Hdd9+JoKCgJlmU9d0vX3/9tejQoYMoKyvTVUTJ1HffhISEiCFDhlRaFhoaKry9vbWaU0p1Kcrp06eLxx9/vNIyf39/4evr2ygZOPVajbKyMiiVSvj4+GiWGRkZwcfHBykpKdVuk5KSUml9APD19a1xfUPUkP3yT8XFxSgvL0erVq20FVMSDd034eHhaNOmDf71r3/pIqbONWS/bN++HV5eXggJCYG9vT169OiBRYsWQaVS6Sq2TjRk3/Tr1w9KpVIzPZueno5du3Zh2LBhOsmsr7T997fZXRS9LnJzc6FSqWBvb19pub29Pc6fP1/tNllZWdWun5WVpbWcutaQ/fJPM2bMgJOTU5UfakPXkH1z6NAhrFq1CqdPn9ZBQmk0ZL+kp6dj3759eO2117Br1y5cunQJU6ZMQXl5OcLCwnQRWycasm8CAgKQm5uL/v37QwiBiooKTJ48GbNnz9ZFZL1V09/fgoIClJSUwNzc/KGenyNK0pnIyEjExsYiLi4OZmZmUseRVGFhIcaNG4eVK1fCzs5O6jh6Ra1Wo02bNvj222/h5uYGf39/zJkzB9HR0VJHk1xycjIWLVqEFStW4OTJk9i2bRsSEhKwcOFCqaM1aRxRVsPOzg7GxsbIzs6utDw7OxsODg7VbuPg4FCv9Q1RQ/bLfZ9//jkiIyPxyy+/4IknntBmTEnUd9/89ddfuHz5Mvz8/DTL1Go1AMDExAQXLlxAx44dtRtaBxryM+Po6AhTU1MYGxtrlnXr1g1ZWVkoKyuDXC7XamZdaci+mTdvHsaNG4cJEyYAAHr27ImioiJMmjQJc+bMqfU7FZuymv7+WllZPfRoEuCIslpyuRxubm5ISkrSLFOr1UhKSoKXl1e123h5eVVaHwD27t1b4/qGqCH7BQAWL16MhQsXYvfu3XB3d9dFVJ2r777p2rUrzp49i9OnT2tuL7zwAgYPHozTp0/D2dlZl/G1piE/M97e3rh06ZLmHw4AcPHiRTg6OjaZkgQatm+Ki4urlOH9f1CIZnzZbq3//W2UU4KaoNjYWKFQKERMTIw4d+6cmDRpkrCxsRFZWVlCCCHGjRsnZs6cqVn/8OHDwsTERHz++eciLS1NhIWFNdmPh9Rnv0RGRgq5XC62bNkibty4obkVFhZK9Ra0pr775p+a6lmv9d0vmZmZomXLlmLq1KniwoULYufOnaJNmzbi448/luotaE19901YWJho2bKl2Lhxo0hPTxd79uwRHTt2FGPHjpXqLWhFYWGhOHXqlDh16pQAIJYuXSpOnTolrly5IoQQYubMmWLcuHGa9e9/POTDDz8UaWlpIioqih8P0ZXly5cLFxcXIZfLhYeHhzh69KjmsUGDBomgoKBK62/evFl07txZyOVy8fjjj4uEhAQdJ9aN+uyXRx99VACocgsLC9N9cB2o78/M3zXVohSi/vvlyJEjwtPTUygUCtGhQwfxySefiIqKCh2n1o367Jvy8nLx0UcfiY4dOwozMzPh7OwspkyZIu7cuaP74Fq0f//+av9u3N8XQUFBYtCgQVW26d27t5DL5aJDhw5izZo1jZaHX7NFRERUCx6jJCIiqgWLkoiIqBYsSiIiolqwKImIiGrBoiQiIqoFi5KIiKgWLEoiIqJasCiJiIhqwaIkIiKqBYuSqIkYP348ZDJZldulS5cqPSaXy9GpUyeEh4ejoqICwH++vunv27Ru3RrDhg3D2bNnJX5XRNJjURI1Ic899xxu3LhR6da+fftKj/355594//338dFHH+Gzzz6rtP2FCxdw48YNJCYmorS0FMOHD0dZWZkUb4VIb7AoiZoQhUIBBweHSrf7X8N0/7FHH30Ub731Fnx8fLB9+/ZK27dp0wYODg7o06cPpk2bhqtXr+L8+fNSvBUivcGiJGqmzM3Naxwt5ufnIzY2FgCa1HdAEjWEidQBiKjx7Ny5E5aWlpr7zz//PH788cdK6wghkJSUhMTERLz99tuVHmvXrh0AoKioCADwwgsvoGvXrlpOTaTfWJRETcjgwYPx9ddfa+63aNFC87/vl2h5eTnUajUCAgLw0UcfVdr+4MGDsLCwwNGjR7Fo0SJER0frKjqR3mJREjUhLVq0QKdOnap97H6JyuVyODk5wcSk6q9/+/btYWNjgy5duuDmzZvw9/fHgQMHtB2bSK/xGCVRM3G/RF1cXKotyX8KCQnB77//jri4OB2kI9JfLEoiqpaFhQUmTpyIsLAwCCGkjkMkGRYlEdVo6tSpSEtLq3JCEFFzIhP8pyIREVGNOKIkIiKqBYuSiIioFixKIiKiWrAoiYiIasGiJCIiqgWLkoiIqBYsSiIiolqwKImIiGrBoiQiIqoFi5KIiKgWLEoiIqJa/D8YW0JtV5X0IgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Artifacts saved to: /content/drive/MyDrive/oasis_project/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm no subject overlap\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "map_csv = '/content/drive/MyDrive/oasis_project/outputs/graph_label_mapping_annotated.csv'\n",
        "df_map = pd.read_csv(map_csv)\n",
        "# build subj2idx and same split as training\n",
        "subj2idx = defaultdict(list)\n",
        "for i in df_map.index:\n",
        "    sid = df_map.loc[i,'subject_id']\n",
        "    subj2idx[str(sid)].append(i)\n",
        "\n",
        "# get subject lists used in weighted training (from your last run)\n",
        "subjects = list(subj2idx.keys())\n",
        "from sklearn.model_selection import train_test_split\n",
        "labels = [int(pd.Series([int(df_map.loc[i,'y']) for i in subj2idx[s]]).mode()[0]) for s in subjects]\n",
        "train_subj, val_subj = train_test_split(subjects, test_size=0.2, random_state=42, stratify=labels)\n",
        "overlap = set(train_subj).intersection(set(val_subj))\n",
        "print(\"Overlap subjects:\", overlap)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SesBfFncJUtw",
        "outputId": "53ac6ab6-01fd-498b-bd06-4e0d4e50337d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap subjects: set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run predictions on val_loader again and show probability stats\n",
        "import numpy as np, torch\n",
        "from pathlib import Path\n",
        "# uses model from scope; if not in scope, load best weighted model file\n",
        "best = Path('/content/drive/MyDrive/oasis_project/outputs/model_best_weighted.pt')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if 'model' not in globals():\n",
        "    # rebuild model arch like before then load\n",
        "    from torch_geometric.nn import SAGEConv, global_mean_pool\n",
        "    import torch.nn.functional as F, torch.nn as nn\n",
        "    class TinySAGEReg(nn.Module):\n",
        "        def __init__(self, in_ch, hid=64, outc=2, p_drop=0.3):\n",
        "            super().__init__()\n",
        "            self.conv1 = SAGEConv(in_ch, hid)\n",
        "            self.conv2 = SAGEConv(hid, hid)\n",
        "            self.lin = nn.Linear(hid, outc)\n",
        "            self.drop = nn.Dropout(p_drop)\n",
        "        def forward(self, x, edge_index, batch):\n",
        "            x = self.conv1(x, edge_index); x = F.relu(x)\n",
        "            x = self.drop(x)\n",
        "            x = self.conv2(x, edge_index)\n",
        "            x = global_mean_pool(x, batch)\n",
        "            x = self.drop(x)\n",
        "            return self.lin(x)\n",
        "    in_ch = graphs[0].x.shape[1]\n",
        "    model = TinySAGEReg(in_ch, hid=64, outc=2, p_drop=0.3).to(device)\n",
        "    model.load_state_dict(torch.load(best, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "# build val_loader same as last run (subject-level split)\n",
        "# (re-create train_subj/val_subj exactly like training cell did)\n",
        "from collections import defaultdict\n",
        "subj2idx = defaultdict(list)\n",
        "for i in df_map.index:\n",
        "    sid = df_map.loc[i,'subject_id']\n",
        "    subj2idx[str(sid)].append(i)\n",
        "subjects = list(subj2idx.keys())\n",
        "labels = [int(pd.Series([int(df_map.loc[i,'y']) for i in subj2idx[s]]).mode()[0]) for s in subjects]\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_subj, val_subj = train_test_split(subjects, test_size=0.2, random_state=42, stratify=labels)\n",
        "val_idx = [idx for s in val_subj for idx in subj2idx[s]]\n",
        "from torch_geometric.data import DataLoader\n",
        "val_loader = DataLoader([graphs[i] for i in val_idx], batch_size=8, shuffle=False)\n",
        "\n",
        "probs = []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch.x, batch.edge_index, batch.batch)\n",
        "        p = torch.softmax(out, dim=1)[:,1].cpu().numpy()\n",
        "        probs.append(p)\n",
        "probs = np.concatenate(probs)\n",
        "print(\"Prob stats: min\", probs.min(), \"max\", probs.max(), \"mean\", probs.mean(), \"median\", np.median(probs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxZo-xGQJskF",
        "outputId": "f4e4d835-b92d-4282-9c99-e08884962a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prob stats: min 0.0052674464 max 0.9980221 mean 0.2502489 median 0.026091063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5-fold subject-level CV (stratified on subject label)\n",
        "import numpy as np, torch, pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
        "import torch.nn.functional as F, torch.nn as nn\n",
        "\n",
        "df_map = pd.read_csv('/content/drive/MyDrive/oasis_project/outputs/graph_label_mapping_annotated.csv')\n",
        "# only use entries with y>=0\n",
        "df_map = df_map[df_map['y']>=0].reset_index(drop=True)\n",
        "\n",
        "# map subject -> indices and subject labels\n",
        "subj2idx = defaultdict(list)\n",
        "for i,r in df_map.iterrows():\n",
        "    subj2idx[str(r.subject_id)].append(int(r.name))  # careful: use new df_map index\n",
        "# simpler: rebuild subj_list and subj_label arrays\n",
        "# we'll collect one index per subject for label\n",
        "subjects = list({str(r.subject_id) for _,r in df_map.iterrows()})\n",
        "subj_labels = []\n",
        "subj_indices = []\n",
        "for s in subjects:\n",
        "    idxs = df_map.index[df_map['subject_id']==s].tolist()\n",
        "    labs = df_map.loc[idxs,'y'].values\n",
        "    subj_labels.append(int(np.bincount(labs).argmax()))\n",
        "    subj_indices.append(idxs)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_metrics = []\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "for fold,(train_idx, val_idx) in enumerate(skf.split(subjects, subj_labels),1):\n",
        "    # build graph idx lists for fold\n",
        "    train_graph_idx = [i for j in train_idx for i in subj_indices[j]]\n",
        "    val_graph_idx = [i for j in val_idx for i in subj_indices[j]]\n",
        "    train_loader = DataLoader([graphs[i] for i in train_graph_idx], batch_size=8, shuffle=True)\n",
        "    val_loader = DataLoader([graphs[i] for i in val_graph_idx], batch_size=8, shuffle=False)\n",
        "\n",
        "    # model init\n",
        "    class Tiny(nn.Module):\n",
        "        def __init__(self, in_ch, hid=64, outc=2):\n",
        "            super().__init__()\n",
        "            self.conv1 = SAGEConv(in_ch, hid)\n",
        "            self.conv2 = SAGEConv(hid, hid)\n",
        "            self.lin = nn.Linear(hid, outc)\n",
        "        def forward(self,x,edge_index,batch):\n",
        "            x = self.conv1(x, edge_index); x = F.relu(x)\n",
        "            x = self.conv2(x, edge_index)\n",
        "            x = global_mean_pool(x, batch)\n",
        "            return self.lin(x)\n",
        "    in_ch = graphs[0].x.shape[1]\n",
        "    model = Tiny(in_ch).to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    # compute class weights from train labels\n",
        "    import numpy as np\n",
        "    train_labels = np.array([int(graphs[i].y.item()) for i in train_graph_idx])\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    classes = np.unique(train_labels)\n",
        "    weights = compute_class_weight('balanced', classes=classes, y=train_labels)\n",
        "    full_weights = np.ones(int(train_labels.max())+1, dtype=float)\n",
        "    for c,w in zip(classes,weights): full_weights[int(c)]=w\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(weight=torch.tensor(full_weights,dtype=torch.float).to(device))\n",
        "\n",
        "    # short train (few epochs)\n",
        "    for epoch in range(6):\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.batch)\n",
        "            y = batch.y.view(-1).to(device)\n",
        "            y[y<0]=0\n",
        "            loss = loss_fn(out,y)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "    # eval\n",
        "    model.eval()\n",
        "    y_true,y_pred,y_prob = [],[],[]\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.batch)\n",
        "            p = torch.softmax(out,dim=1)[:,1].cpu().numpy() if out.shape[1]>1 else np.zeros(out.shape[0])\n",
        "            preds = out.argmax(dim=1).cpu().numpy()\n",
        "            labs = batch.y.view(-1).cpu().numpy(); labs[labs<0]=0\n",
        "            y_true.append(labs); y_pred.append(preds); y_prob.append(p)\n",
        "    y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred); y_prob = np.concatenate(y_prob)\n",
        "    acc = accuracy_score(y_true,y_pred)\n",
        "    rec = recall_score(y_true,y_pred, average='binary', zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true,y_prob)\n",
        "    except:\n",
        "        auc = float('nan')\n",
        "    fold_metrics.append({'fold':fold,'acc':acc,'recall':rec,'auc':auc})\n",
        "    print(f\"Fold {fold}: acc={acc:.3f} recall={rec:.3f} auc={auc:.3f}\")\n",
        "\n",
        "import pandas as pd\n",
        "print(\"CV summary:\\n\", pd.DataFrame(fold_metrics).describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8bGkG2ZJuoB",
        "outputId": "b432ba35-4a1c-4abb-efa4-a2172f668633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: acc=0.952 recall=0.800 auc=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: acc=1.000 recall=1.000 auc=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3: acc=0.857 recall=0.400 auc=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4: acc=0.786 recall=0.100 auc=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5: acc=0.805 recall=0.111 auc=1.000\n",
            "CV summary:\n",
            "            fold       acc    recall  auc\n",
            "count  5.000000  5.000000  5.000000  5.0\n",
            "mean   3.000000  0.880023  0.482222  1.0\n",
            "std    1.581139  0.093132  0.406096  0.0\n",
            "min    1.000000  0.785714  0.100000  1.0\n",
            "25%    2.000000  0.804878  0.111111  1.0\n",
            "50%    3.000000  0.857143  0.400000  1.0\n",
            "75%    4.000000  0.952381  0.800000  1.0\n",
            "max    5.000000  1.000000  1.000000  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "roots = [Path('/content/drive/MyDrive/oasis_project/data/preprocessed'),\n",
        "         Path('/MyDrive/oasis_project/data/preprocessed')]\n",
        "for r in roots:\n",
        "    print(\"-\", r, \"exists?\", r.exists())\n",
        "    if r.exists():\n",
        "        print(\"  subdirs:\", [p.name for p in r.iterdir()][:20])\n",
        "man = Path('/content/drive/MyDrive/oasis_project/data/preprocessed/preproc_manifest.csv')\n",
        "print(\"preproc_manifest.csv exists at Drive path?\", man.exists())\n",
        "# quick search for any _preproc.nii.gz files\n",
        "cands = list(Path('/content/drive/MyDrive').rglob('*_preproc.nii.gz')) + list(Path('/MyDrive').rglob('*_preproc.nii.gz'))\n",
        "print(\"Found preproc NIfTI count:\", len(cands))\n",
        "for p in cands[:10]:\n",
        "    print(\"  \", p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTLSOpg-JztO",
        "outputId": "31a2c96e-af7c-457d-f91a-cd3dbf64d442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- /content/drive/MyDrive/oasis_project/data/preprocessed exists? False\n",
            "- /MyDrive/oasis_project/data/preprocessed exists? False\n",
            "preproc_manifest.csv exists at Drive path? False\n",
            "Found preproc NIfTI count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqLl379pKf-y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}