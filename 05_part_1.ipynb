{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Unmount drive if already mounted and clear the mountpoint\n",
        "if os.path.exists('/content/drive'):\n",
        "    try:\n",
        "        drive.flush_and_unmount()\n",
        "        # It might take a moment for the unmount to complete,\n",
        "        # but often clearing the directory is sufficient.\n",
        "    except ValueError:\n",
        "        # Drive was not mounted, no need to unmount\n",
        "        pass\n",
        "\n",
        "    # Clear the mountpoint directory\n",
        "    if os.path.exists('/content/drive') and os.path.isdir('/content/drive'):\n",
        "        for item in os.listdir('/content/drive'):\n",
        "            item_path = os.path.join('/content/drive', item)\n",
        "            try:\n",
        "                if os.path.isfile(item_path) or os.path.islink(item_path):\n",
        "                    os.unlink(item_path)\n",
        "                elif os.path.isdir(item_path):\n",
        "                    shutil.rmtree(item_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error removing {item_path}: {e}\")\n",
        "\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "print(\"✅ Drive mounted.\")\n",
        "print(\"Drive contents at root:\")\n",
        "for f in os.listdir(\"/content/drive\"):\n",
        "    print(\" -\", f)\n",
        "\n",
        "# verify main project folder exists\n",
        "proj = \"/content/drive/MyDrive/oasis_project\"\n",
        "print(\"\\nProject folder exists?\", os.path.exists(proj))\n",
        "if os.path.exists(proj):\n",
        "    print(\"Contents of oasis_project:\")\n",
        "    for f in os.listdir(proj):\n",
        "        print(\"   \", f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq4LJeuucCAX",
        "outputId": "388cb973-7f2a-4604-ca96-f30a18cb3e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Drive mounted.\n",
            "Drive contents at root:\n",
            " - .shortcut-targets-by-id\n",
            " - MyDrive\n",
            " - .Trash-0\n",
            " - .Encrypted\n",
            "\n",
            "Project folder exists? True\n",
            "Contents of oasis_project:\n",
            "    notebooks\n",
            "    data\n",
            "    outputs\n",
            "    logs\n",
            "    oasis2_graph_dataset.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLUwHqwlc2h2",
        "outputId": "09b7f046-66b8-42dc-9928-a3e4b2d5aefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb41XzJgZtak",
        "outputId": "71b227e7-bf47-4338-ec38-c825d0f6cdd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clinical file exists: True\n",
            "MRI archive exists: True\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os, tarfile, pandas as pd, numpy as np, nibabel as nib, torch\n",
        "from skimage.transform import resize\n",
        "from tqdm import tqdm\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/oasis_project\")\n",
        "RAW_DIR = BASE / \"data\" / \"raw\" / \"oasis1\"\n",
        "PREPROC_DIR = BASE / \"data\" / \"preproc\" / \"oasis1\"\n",
        "GRAPH_DIR = BASE / \"data\" / \"graphs\"\n",
        "for p in [RAW_DIR, PREPROC_DIR, GRAPH_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "CLIN_PATH = Path(\"/content/drive/MyDrive/oasis_project/data/demographics/oasis2_demographics.xlsx\")\n",
        "TAR_PATH  = Path(\"/content/drive/MyDrive/OAS2_RAW_PART2.tar.gz\")\n",
        "\n",
        "print(\"Clinical file exists:\", CLIN_PATH.exists())\n",
        "print(\"MRI archive exists:\", TAR_PATH.exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract only once\n",
        "extracted_flag = RAW_DIR / \".extracted\"\n",
        "if not extracted_flag.exists():\n",
        "    print(\"Extracting .tar.gz ... this may take a few minutes\")\n",
        "    with tarfile.open(TAR_PATH, \"r:gz\") as tar:\n",
        "        tar.extractall(RAW_DIR)\n",
        "    extracted_flag.write_text(\"done\")\n",
        "else:\n",
        "    print(\"Already extracted:\", RAW_DIR)\n",
        "\n",
        "# list nii or img/hdr files\n",
        "nii_files = sorted(list(RAW_DIR.rglob(\"*.nii*\")) + list(RAW_DIR.rglob(\"*.img\")))\n",
        "print(\"Total MRI files:\", len(nii_files))\n",
        "print(\"Sample:\", [f.name for f in nii_files[:5]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwX6iFrKZyCQ",
        "outputId": "f9b02159-3c22-43aa-8944-3de84f5c12be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already extracted: /content/drive/MyDrive/oasis_project/data/raw/oasis1\n",
            "Total MRI files: 304\n",
            "Sample: ['OAS1_0001_MR1_mpr_n4_anon_111_t88_masked_gfc_fseg.img', 'OAS1_0001_MR1_mpr_n4_anon_sbj_111.img', 'OAS1_0001_MR1_mpr_n4_anon_111_t88_gfc.img', 'OAS1_0001_MR1_mpr_n4_anon_111_t88_masked_gfc.img', 'OAS1_0001_MR1_mpr-1_anon.img']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed metadata parsing cell (paste & run)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "CLIN_PATH = Path(\"/content/drive/MyDrive/oasis_cross-sectional-5708aa0a98d82080 (1).xlsx\")\n",
        "\n",
        "meta = pd.read_excel(CLIN_PATH)\n",
        "print(\"Original columns:\", meta.columns.tolist())\n",
        "display(meta.head(5))\n",
        "\n",
        "# Build a mapping original_col -> canonical name\n",
        "rename_map = {}\n",
        "col_lower = [c.lower() for c in meta.columns]\n",
        "\n",
        "def find_original(keys):\n",
        "    for k in keys:\n",
        "        for orig in meta.columns:\n",
        "            if k in orig.lower():\n",
        "                return orig\n",
        "    return None\n",
        "\n",
        "orig_subject = find_original([\"subject\", \"id\", \"subj\"])\n",
        "orig_cdr     = find_original([\"cdr\", \"cdR\", \"diagnosis\", \"label\"])\n",
        "orig_age     = find_original([\"age\"])\n",
        "orig_time    = find_original([\"delay\", \"visit\", \"examdate\", \"time\", \"session\"])\n",
        "\n",
        "if orig_subject: rename_map[orig_subject] = \"subject_id\"\n",
        "if orig_cdr:     rename_map[orig_cdr]     = \"cdr\"\n",
        "if orig_age:     rename_map[orig_age]     = \"age\"\n",
        "if orig_time:    rename_map[orig_time]    = \"timepoint\"\n",
        "\n",
        "print(\"Detected rename mapping (orig -> new):\", rename_map)\n",
        "# apply rename\n",
        "meta = meta.rename(columns=rename_map)\n",
        "\n",
        "# ensure required columns exist or create safe defaults\n",
        "if \"subject_id\" not in meta.columns:\n",
        "    raise KeyError(f\"Could not detect subject id column automatically. Available columns: {list(meta.columns)}\")\n",
        "\n",
        "if \"cdr\" not in meta.columns:\n",
        "    print(\"Warning: CDR column not detected — filling with NaN\")\n",
        "    meta[\"cdr\"] = np.nan\n",
        "\n",
        "if \"timepoint\" not in meta.columns:\n",
        "    # create a default timepoint column filled with NaN (we will convert to 0.0 later)\n",
        "    meta[\"timepoint\"] = np.nan\n",
        "\n",
        "# sanitize subject_id to a compact form that matches filenames:\n",
        "# e.g., convert \"OAS1_0001_MR1\" -> \"OAS1_0001\"\n",
        "def canonical_subject(s):\n",
        "    s = str(s)\n",
        "    # common pattern: keep first two underscore parts if present\n",
        "    parts = s.split('_')\n",
        "    if len(parts) >= 2:\n",
        "        return \"_\".join(parts[:2])\n",
        "    return s\n",
        "\n",
        "meta[\"subject_id\"] = meta[\"subject_id\"].astype(str).map(canonical_subject)\n",
        "\n",
        "# coerce cdr to float where possible\n",
        "meta[\"cdr\"] = pd.to_numeric(meta[\"cdr\"], errors=\"coerce\")\n",
        "\n",
        "# fill missing timepoint with NaN (or 0.0 if you prefer)\n",
        "meta[\"timepoint\"] = pd.to_numeric(meta[\"timepoint\"], errors=\"coerce\")\n",
        "# If you want a numeric default, you can uncomment next line:\n",
        "# meta[\"timepoint\"] = meta[\"timepoint\"].fillna(0.0)\n",
        "\n",
        "print(\"After normalization — columns now:\", meta.columns.tolist())\n",
        "print(\"Unique subjects:\", meta[\"subject_id\"].nunique())\n",
        "display(meta[[\"subject_id\",\"cdr\",\"timepoint\"]].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "wB3QpkFqecq9",
        "outputId": "fd4d71b2-ccb5-4b5b-cb5c-16a9f8db167b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original columns: ['ID', 'M/F', 'Hand', 'Age', 'Educ', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF', 'Delay']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              ID M/F Hand  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  \\\n",
              "0  OAS1_0001_MR1   F    R   74   2.0  3.0  29.0  0.0  1344  0.743  1.306   \n",
              "1  OAS1_0002_MR1   F    R   55   4.0  1.0  29.0  0.0  1147  0.810  1.531   \n",
              "2  OAS1_0003_MR1   F    R   73   4.0  3.0  27.0  0.5  1454  0.708  1.207   \n",
              "3  OAS1_0004_MR1   M    R   28   NaN  NaN   NaN  NaN  1588  0.803  1.105   \n",
              "4  OAS1_0005_MR1   M    R   18   NaN  NaN   NaN  NaN  1737  0.848  1.010   \n",
              "\n",
              "   Delay  \n",
              "0    NaN  \n",
              "1    NaN  \n",
              "2    NaN  \n",
              "3    NaN  \n",
              "4    NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfcb28ab-5e11-408d-a2bc-74210788b3c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>M/F</th>\n",
              "      <th>Hand</th>\n",
              "      <th>Age</th>\n",
              "      <th>Educ</th>\n",
              "      <th>SES</th>\n",
              "      <th>MMSE</th>\n",
              "      <th>CDR</th>\n",
              "      <th>eTIV</th>\n",
              "      <th>nWBV</th>\n",
              "      <th>ASF</th>\n",
              "      <th>Delay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OAS1_0001_MR1</td>\n",
              "      <td>F</td>\n",
              "      <td>R</td>\n",
              "      <td>74</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1344</td>\n",
              "      <td>0.743</td>\n",
              "      <td>1.306</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OAS1_0002_MR1</td>\n",
              "      <td>F</td>\n",
              "      <td>R</td>\n",
              "      <td>55</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1147</td>\n",
              "      <td>0.810</td>\n",
              "      <td>1.531</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OAS1_0003_MR1</td>\n",
              "      <td>F</td>\n",
              "      <td>R</td>\n",
              "      <td>73</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1454</td>\n",
              "      <td>0.708</td>\n",
              "      <td>1.207</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OAS1_0004_MR1</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1588</td>\n",
              "      <td>0.803</td>\n",
              "      <td>1.105</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OAS1_0005_MR1</td>\n",
              "      <td>M</td>\n",
              "      <td>R</td>\n",
              "      <td>18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1737</td>\n",
              "      <td>0.848</td>\n",
              "      <td>1.010</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfcb28ab-5e11-408d-a2bc-74210788b3c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bfcb28ab-5e11-408d-a2bc-74210788b3c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bfcb28ab-5e11-408d-a2bc-74210788b3c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b0a89ebc-5ae3-418e-bfa8-4ba7676ebc3b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0a89ebc-5ae3-418e-bfa8-4ba7676ebc3b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b0a89ebc-5ae3-418e-bfa8-4ba7676ebc3b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(meta[[\\\"subject_id\\\",\\\"cdr\\\",\\\"timepoint\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"OAS1_0002_MR1\",\n          \"OAS1_0005_MR1\",\n          \"OAS1_0003_MR1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"M/F\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"M\",\n          \"F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"R\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 18,\n        \"max\": 74,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Educ\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1547005383792515,\n        \"min\": 2.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SES\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1547005383792515,\n        \"min\": 1.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1547005383792515,\n        \"min\": 27.0,\n        \"max\": 29.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          27.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CDR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2886751345948129,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eTIV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 226,\n        \"min\": 1147,\n        \"max\": 1737,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1147\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nWBV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056074058173098205,\n        \"min\": 0.708,\n        \"max\": 0.848,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20057093508282794,\n        \"min\": 1.01,\n        \"max\": 1.531,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.531\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Delay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected rename mapping (orig -> new): {'ID': 'subject_id', 'CDR': 'cdr', 'Age': 'age', 'Delay': 'timepoint'}\n",
            "After normalization — columns now: ['subject_id', 'M/F', 'Hand', 'age', 'Educ', 'SES', 'MMSE', 'cdr', 'eTIV', 'nWBV', 'ASF', 'timepoint']\n",
            "Unique subjects: 416\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  subject_id  cdr  timepoint\n",
              "0  OAS1_0001  0.0        NaN\n",
              "1  OAS1_0002  0.0        NaN\n",
              "2  OAS1_0003  0.5        NaN\n",
              "3  OAS1_0004  NaN        NaN\n",
              "4  OAS1_0005  NaN        NaN\n",
              "5  OAS1_0006  NaN        NaN\n",
              "6  OAS1_0007  NaN        NaN\n",
              "7  OAS1_0009  NaN        NaN\n",
              "8  OAS1_0010  0.0        NaN\n",
              "9  OAS1_0011  0.0        NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ca270fc-2a34-461e-a570-6c8fdede39f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject_id</th>\n",
              "      <th>cdr</th>\n",
              "      <th>timepoint</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OAS1_0001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OAS1_0002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OAS1_0003</td>\n",
              "      <td>0.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OAS1_0004</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OAS1_0005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OAS1_0006</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>OAS1_0007</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>OAS1_0009</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>OAS1_0010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>OAS1_0011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ca270fc-2a34-461e-a570-6c8fdede39f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ca270fc-2a34-461e-a570-6c8fdede39f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ca270fc-2a34-461e-a570-6c8fdede39f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d2371a37-d41d-4add-ba55-9c1c216d2c55\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2371a37-d41d-4add-ba55-9c1c216d2c55')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d2371a37-d41d-4add-ba55-9c1c216d2c55 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(meta[[\\\"subject_id\\\",\\\"cdr\\\",\\\"timepoint\\\"]]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"subject_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"OAS1_0010\",\n          \"OAS1_0002\",\n          \"OAS1_0006\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cdr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22360679774997902,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timepoint\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_mri(path, out_dir, target_shape=(96,96,96)):\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    img = nib.load(str(path))\n",
        "    data = img.get_fdata().astype(np.float32)\n",
        "    # simple normalization\n",
        "    mask = data > np.percentile(data, 5)\n",
        "    mean, std = data[mask].mean(), data[mask].std()\n",
        "    data = (data - mean) / (std + 1e-6)\n",
        "    data = resize(data, target_shape, order=1, preserve_range=True, anti_aliasing=True)\n",
        "    out_path = out_dir / f\"{path.stem}_preproc.nii.gz\"\n",
        "    nib.save(nib.Nifti1Image(data, affine=np.eye(4)), str(out_path))\n",
        "    return out_path\n",
        "\n",
        "preproc_files = []\n",
        "for f in tqdm(nii_files, desc=\"Preprocessing MRIs\"):\n",
        "    try:\n",
        "        out = preprocess_mri(f, PREPROC_DIR)\n",
        "        preproc_files.append(out)\n",
        "    except Exception as e:\n",
        "        print(\"Error preprocessing\", f, e)\n",
        "print(\"Preprocessed files:\", len(preproc_files))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbghYTCPdAl-",
        "outputId": "0d766f44-fe7a-428e-9b78-d8b3a728ca0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing MRIs: 100%|██████████| 304/304 [05:02<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed files: 304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mri_to_graph(nifti_path, subject_id, label, timepoint, patch_size=3, n_neighbors=6, sample_n=400):\n",
        "    data = nib.load(str(nifti_path)).get_fdata().astype(np.float32)\n",
        "    data = (data - data.mean()) / (data.std() + 1e-6)\n",
        "\n",
        "    coords_all = np.stack(np.meshgrid(np.arange(data.shape[0]),\n",
        "                                      np.arange(data.shape[1]),\n",
        "                                      np.arange(data.shape[2]),\n",
        "                                      indexing='ij'), axis=-1).reshape(-1,3)\n",
        "    mask = data.reshape(-1) > np.percentile(data.reshape(-1), 10)\n",
        "    coords = coords_all[mask]\n",
        "    if coords.shape[0] > sample_n:\n",
        "        idx = np.linspace(0, coords.shape[0]-1, sample_n).astype(int)\n",
        "        coords = coords[idx]\n",
        "\n",
        "    feats = []\n",
        "    for (x,y,z) in coords:\n",
        "        x0,x1 = max(0,x-patch_size), min(data.shape[0],x+patch_size+1)\n",
        "        y0,y1 = max(0,y-patch_size), min(data.shape[1],y+patch_size+1)\n",
        "        z0,z1 = max(0,z-patch_size), min(data.shape[2],z+patch_size+1)\n",
        "        patch = data[x0:x1,y0:y1,z0:z1]\n",
        "        feats.append([patch.mean(), patch.std(), patch.min(), patch.max()])\n",
        "    X = np.array(feats, dtype=np.float32)\n",
        "    if len(coords) > 1:\n",
        "        A = kneighbors_graph(coords, n_neighbors=min(n_neighbors,len(coords)-1), mode='connectivity', include_self=False)\n",
        "        edge_index = np.vstack(A.nonzero()).astype(np.int64)\n",
        "    else:\n",
        "        edge_index = np.zeros((2,0), dtype=np.int64)\n",
        "    g = Data(x=torch.tensor(X), edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
        "    g.y = torch.tensor([float(label)], dtype=torch.float32)\n",
        "    g.subject_id = str(subject_id)\n",
        "    g.timepoint = float(timepoint) if not pd.isna(timepoint) else 0.0\n",
        "    return g\n"
      ],
      "metadata": {
        "id": "KJbp0DBCdDAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphs = []\n",
        "skipped = []\n",
        "for f in tqdm(preproc_files, desc=\"Graph building\"):\n",
        "    name = f.stem.split(\"_\")[0]\n",
        "    row = meta[meta[\"subject_id\"].astype(str).str.contains(name, case=False, na=False)]\n",
        "    if len(row)==0:\n",
        "        skipped.append(name)\n",
        "        continue\n",
        "    sid = row.iloc[0][\"subject_id\"]\n",
        "    cdr = row.iloc[0][\"cdr\"]\n",
        "    tp  = row.iloc[0].get(\"timepoint\", 0.0)\n",
        "    try:\n",
        "        g = mri_to_graph(f, sid, cdr, tp)\n",
        "        graphs.append(g)\n",
        "    except Exception as e:\n",
        "        skipped.append((name,str(e)))\n",
        "        print(\"Failed\", name, e)\n",
        "\n",
        "print(\"Built graphs:\", len(graphs), \"Skipped:\", len(skipped))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4DhPggldFJW",
        "outputId": "772866c2-5c63-4e53-82a8-0e833c69dee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Graph building: 100%|██████████| 304/304 [00:34<00:00,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built graphs: 304 Skipped: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_PT = GRAPH_DIR / \"oasis1_1_graphs_labeled_auto_full.pt\"\n",
        "torch.save(graphs, OUT_PT)\n",
        "print(\"✅ Saved:\", OUT_PT)\n",
        "if graphs:\n",
        "    g0 = graphs[0]\n",
        "    print(\"Example graph:\", g0)\n",
        "    print(\"x shape:\", g0.x.shape, \"edges:\", g0.edge_index.shape[1], \"label:\", g0.y.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvVwV5DedKzE",
        "outputId": "3cb0d9c5-ee19-44da-c4b7-b2713d2a3822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved: /content/drive/MyDrive/oasis_project/data/graphs/oasis1_graphs_labeled_auto_full.pt\n",
            "Example graph: Data(x=[400, 4], edge_index=[2, 2400], y=[1], subject_id='OAS1_0001', timepoint=0.0)\n",
            "x shape: torch.Size([400, 4]) edges: 2400 label: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paste & run this in Colab\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "\n",
        "MASTER_PT = Path(\"/content/drive/MyDrive/oasis_project/data/graphs/oasis1_graphs_labeled_auto_full.pt\")\n",
        "assert MASTER_PT.exists(), f\"Master file not found: {MASTER_PT}\"\n",
        "\n",
        "# Safe load (allowlist PyG storage global) — recommended\n",
        "try:\n",
        "    import torch_geometric\n",
        "    with torch.serialization.safe_globals([torch_geometric.data.storage.GlobalStorage]):\n",
        "        graphs = torch.load(MASTER_PT, map_location=\"cpu\")\n",
        "except Exception as e:\n",
        "    # fallback (only if you trust file)\n",
        "    print(\"safe_globals load failed, trying weights_only=False fallback:\", e)\n",
        "    graphs = torch.load(MASTER_PT, map_location=\"cpu\", weights_only=False)\n",
        "\n",
        "print(\"Loaded graphs:\", len(graphs))\n",
        "\n",
        "# Gather basic info\n",
        "subject_ids = []\n",
        "timepoints = []\n",
        "labels = []\n",
        "for g in graphs:\n",
        "    sid = getattr(g, \"subject_id\", None)\n",
        "    # canonicalize short id if it contains MR suffix\n",
        "    if sid is not None:\n",
        "        sid = str(sid)\n",
        "        parts = sid.split(\"_\")\n",
        "        if len(parts) >= 2:\n",
        "            sid = \"_\".join(parts[:2])\n",
        "    subject_ids.append(sid)\n",
        "    tp = getattr(g, \"timepoint\", None)\n",
        "    timepoints.append(tp if tp is not None else np.nan)\n",
        "    try:\n",
        "        yv = float(g.y.view(-1).cpu().numpy()[0])\n",
        "    except Exception:\n",
        "        try:\n",
        "            yv = float(g.y)\n",
        "        except Exception:\n",
        "            yv = np.nan\n",
        "    labels.append(yv)\n",
        "\n",
        "n_graphs = len(graphs)\n",
        "unique_subjects = set([s for s in subject_ids if s is not None])\n",
        "print(\"Total graphs:\", n_graphs)\n",
        "print(\"Unique subject IDs:\", len(unique_subjects))\n",
        "\n",
        "# label distribution\n",
        "lab_counts = Counter([l for l in labels if not np.isnan(l)])\n",
        "print(\"Label counts (non-NaN):\")\n",
        "for k,v in sorted(lab_counts.items()):\n",
        "    print(\"  \", k, \":\", v)\n",
        "print(\"Labels with NaN (missing):\", sum(1 for l in labels if np.isnan(l)))\n",
        "\n",
        "# duplicates per (subject,timepoint)\n",
        "pair_counts = Counter()\n",
        "for sid, tp in zip(subject_ids, timepoints):\n",
        "    key = (sid, float(tp) if not (tp is None or (isinstance(tp,float) and np.isnan(tp))) else \"__na__\")\n",
        "    pair_counts[key] += 1\n",
        "\n",
        "dupes = [(k,c) for k,c in pair_counts.items() if c>1]\n",
        "print(\"Subjects/timepoint combinations with >1 graph (sample up to 20):\", len(dupes))\n",
        "for k,c in dupes[:20]:\n",
        "    print(\" \", k, \"->\", c)\n",
        "\n",
        "# show 5 example graphs (subject, shape, edges)\n",
        "print(\"\\nExample graphs (first 5):\")\n",
        "for i,g in enumerate(graphs[:5]):\n",
        "    sid = subject_ids[i]\n",
        "    tp  = timepoints[i]\n",
        "    xshape = getattr(g, \"x\").shape if hasattr(g, \"x\") else None\n",
        "    ecount = g.edge_index.shape[1] if hasattr(g, \"edge_index\") else None\n",
        "    yval = labels[i]\n",
        "    print(f\" {i:02d}) subject={sid} timepoint={tp} x.shape={xshape} edges={ecount} y={yval}\")\n",
        "\n",
        "# quick sanity checks:\n",
        "#  - any graphs with zero nodes?\n",
        "zero_nodes = [i for i,g in enumerate(graphs) if (not hasattr(g,\"x\") or getattr(g,\"x\") is None or getattr(g,\"x\").shape[0]==0)]\n",
        "print(\"Graphs with zero nodes:\", zero_nodes[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCz1jsUMMDxG",
        "outputId": "b756c776-c548-401f-e753-26d03e96a3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "safe_globals load failed, trying weights_only=False fallback: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL torch_geometric.data.data.DataEdgeAttr was not an allowed global by default. Please use `torch.serialization.add_safe_globals([torch_geometric.data.data.DataEdgeAttr])` or the `torch.serialization.safe_globals([torch_geometric.data.data.DataEdgeAttr])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "Loaded graphs: 304\n",
            "Total graphs: 304\n",
            "Unique subject IDs: 1\n",
            "Label counts (non-NaN):\n",
            "   0.0 : 304\n",
            "Labels with NaN (missing): 0\n",
            "Subjects/timepoint combinations with >1 graph (sample up to 20): 1\n",
            "  ('OAS1_0001', 0.0) -> 304\n",
            "\n",
            "Example graphs (first 5):\n",
            " 00) subject=OAS1_0001 timepoint=0.0 x.shape=torch.Size([400, 4]) edges=2400 y=0.0\n",
            " 01) subject=OAS1_0001 timepoint=0.0 x.shape=torch.Size([400, 4]) edges=2400 y=0.0\n",
            " 02) subject=OAS1_0001 timepoint=0.0 x.shape=torch.Size([400, 4]) edges=2400 y=0.0\n",
            " 03) subject=OAS1_0001 timepoint=0.0 x.shape=torch.Size([400, 4]) edges=2400 y=0.0\n",
            " 04) subject=OAS1_0001 timepoint=0.0 x.shape=torch.Size([400, 4]) edges=2400 y=0.0\n",
            "Graphs with zero nodes: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2VR708k8MEOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import tarfile\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/oasis_project\")\n",
        "RAW_ROOT = BASE / \"data\" / \"raw\" / \"oasis2\"\n",
        "PREPROC_DIR = BASE / \"data\" / \"preproc\" / \"oasis2\"\n",
        "GRAPH_DIR = BASE / \"data\" / \"graphs\"\n",
        "for p in [RAW_ROOT, PREPROC_DIR, GRAPH_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "CLIN_XLSX = Path(\"/content/drive/MyDrive/oasis_project/data/demographics/oasis2_demographics.xlsx\")\n",
        "ARCHIVE   = Path(\"/content/drive/MyDrive/OAS2_RAW_PART2.tar.gz\")\n",
        "\n",
        "print(\"Clinical exists:\", CLIN_XLSX.exists())\n",
        "print(\"Archive exists:\", ARCHIVE.exists())\n",
        "\n",
        "# extract only once\n",
        "out_subdir = RAW_ROOT / ARCHIVE.stem\n",
        "if not out_subdir.exists():\n",
        "    out_subdir.mkdir(parents=True, exist_ok=True)\n",
        "extracted_flag = out_subdir / \".extracted\"\n",
        "if not extracted_flag.exists():\n",
        "    print(\"Extracting\", ARCHIVE, \"->\", out_subdir)\n",
        "    with tarfile.open(ARCHIVE, \"r:*\") as tar:\n",
        "        tar.extractall(out_subdir)\n",
        "    extracted_flag.write_text(\"done\")\n",
        "else:\n",
        "    print(\"Already extracted at\", out_subdir)\n",
        "\n",
        "# list nifti files\n",
        "nii_files = sorted(list(out_subdir.rglob(\"*.nii*\")) + list(out_subdir.rglob(\"*.img\")))\n",
        "print(\"Found NIfTI files:\", len(nii_files))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30n4NnbJMkIY",
        "outputId": "fe3faa29-2868-4164-b2cb-04c0e18e459e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clinical exists: True\n",
            "Archive exists: True\n",
            "Extracting /content/drive/MyDrive/OAS2_RAW_PART2.tar.gz -> /content/drive/MyDrive/oasis_project/data/raw/oasis2/OAS2_RAW_PART2.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3907373730.py:25: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(out_subdir)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found NIfTI files: 596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "meta = pd.read_excel(CLIN_XLSX)\n",
        "print(\"Clinical columns:\", meta.columns.tolist())\n",
        "\n",
        "# heuristics to find ID, label, time columns\n",
        "def find_col(keylist):\n",
        "    for k in keylist:\n",
        "        for c in meta.columns:\n",
        "            if k.lower() in c.lower():\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "id_col = find_col([\"subject\",\"id\",\"subj\",\"ptid\"]) or meta.columns[0]\n",
        "label_col = find_col([\"cdr\",\"label\",\"dx\",\"diagnosis\"])\n",
        "time_col  = find_col([\"visit\",\"time\",\"date\",\"delay\",\"session\"])\n",
        "\n",
        "print(\"Using id_col:\", id_col, \"label_col:\", label_col, \"time_col:\", time_col)\n",
        "\n",
        "# canonicalize subject id to match filenames (e.g. OAS2_0001_MR1 -> OAS2_0001)\n",
        "def canonical_subject(s):\n",
        "    s = str(s)\n",
        "    parts = s.split(\"_\")\n",
        "    return \"_\".join(parts[:2]) if len(parts) >= 2 else s\n",
        "\n",
        "meta = meta.copy()\n",
        "meta[\"subject_id\"] = meta[id_col].astype(str).map(canonical_subject)\n",
        "if label_col:\n",
        "    meta[\"label\"] = pd.to_numeric(meta[label_col], errors=\"coerce\")\n",
        "else:\n",
        "    meta[\"label\"] = np.nan\n",
        "if time_col:\n",
        "    meta[\"timepoint\"] = pd.to_numeric(meta[time_col], errors=\"coerce\")\n",
        "else:\n",
        "    meta[\"timepoint\"] = np.nan\n",
        "\n",
        "print(\"Unique subjects in clinical:\", meta[\"subject_id\"].nunique())\n",
        "meta[[\"subject_id\",\"label\",\"timepoint\"]].head(6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "JbZd7zGTMkFw",
        "outputId": "00b1add1-363b-494a-f397-81f3535572e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clinical columns: ['Subject ID', 'MRI ID', 'Group', 'Visit', 'MR Delay', 'M/F', 'Hand', 'Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF']\n",
            "Using id_col: Subject ID label_col: CDR time_col: Visit\n",
            "Unique subjects in clinical: 150\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  subject_id  label  timepoint\n",
              "0  OAS2_0001    0.0          1\n",
              "1  OAS2_0001    0.0          2\n",
              "2  OAS2_0002    0.5          1\n",
              "3  OAS2_0002    0.5          2\n",
              "4  OAS2_0002    0.5          3\n",
              "5  OAS2_0004    0.0          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fad0fc39-1a67-44bf-a90e-917d86432732\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject_id</th>\n",
              "      <th>label</th>\n",
              "      <th>timepoint</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OAS2_0001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OAS2_0001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OAS2_0002</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OAS2_0002</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OAS2_0002</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OAS2_0004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fad0fc39-1a67-44bf-a90e-917d86432732')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fad0fc39-1a67-44bf-a90e-917d86432732 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fad0fc39-1a67-44bf-a90e-917d86432732');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-06a94a67-621c-4ca8-9e88-77a1e3e9d78d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06a94a67-621c-4ca8-9e88-77a1e3e9d78d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-06a94a67-621c-4ca8-9e88-77a1e3e9d78d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"meta[[\\\"subject_id\\\",\\\"label\\\",\\\"timepoint\\\"]]\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"subject_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"OAS2_0001\",\n          \"OAS2_0002\",\n          \"OAS2_0004\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27386127875258304,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timepoint\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def preprocess_mri(path, out_dir, target_shape=(96,96,96)):\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    img = nib.load(str(path))\n",
        "    data = img.get_fdata().astype(np.float32)\n",
        "    mask = data > np.percentile(data, 5)\n",
        "    if mask.sum() == 0:\n",
        "        mask = data != 0\n",
        "    mu = data[mask].mean() if mask.sum()>0 else data.mean()\n",
        "    sd = data[mask].std() if mask.sum()>0 else data.std()\n",
        "    data = (data - mu) / (sd + 1e-6)\n",
        "    data = resize(data, target_shape, order=1, preserve_range=True, anti_aliasing=True)\n",
        "    out_path = Path(out_dir) / f\"{Path(path).stem}_preproc.nii.gz\"\n",
        "    nib.save(nib.Nifti1Image(data.astype(np.float32), affine=np.eye(4)), str(out_path))\n",
        "    return out_path\n",
        "\n",
        "def mri_to_graph(nifti_path, subject_id, label, timepoint, patch_size=3, n_neighbors=6, sample_n=400):\n",
        "    data = nib.load(str(nifti_path)).get_fdata().astype(np.float32)\n",
        "    data = (data - data.mean()) / (data.std() + 1e-6)\n",
        "    coords_all = np.stack(np.meshgrid(np.arange(data.shape[0]),\n",
        "                                      np.arange(data.shape[1]),\n",
        "                                      np.arange(data.shape[2]),\n",
        "                                      indexing='ij'), axis=-1).reshape(-1,3)\n",
        "    mask = data.reshape(-1) > np.percentile(data.reshape(-1), 10)\n",
        "    coords = coords_all[mask]\n",
        "    if coords.shape[0] > sample_n:\n",
        "        idx = np.linspace(0, coords.shape[0]-1, sample_n).astype(int)\n",
        "        coords = coords[idx]\n",
        "    feats = []\n",
        "    valid_coords = []\n",
        "    for (x,y,z) in coords:\n",
        "        x,y,z = int(x), int(y), int(z)\n",
        "        x0,x1 = max(0,x-patch_size), min(data.shape[0], x+patch_size+1)\n",
        "        y0,y1 = max(0,y-patch_size), min(data.shape[1], y+patch_size+1)\n",
        "        z0,z1 = max(0,z-patch_size), min(data.shape[2], z+patch_size+1)\n",
        "        patch = data[x0:x1, y0:y1, z0:z1]\n",
        "        feats.append([patch.mean(), patch.std(), patch.min(), patch.max()])\n",
        "        valid_coords.append([x,y,z])\n",
        "    X = np.array(feats, dtype=np.float32)\n",
        "    if len(valid_coords) > 1:\n",
        "        A = kneighbors_graph(np.array(valid_coords), n_neighbors=min(n_neighbors, len(valid_coords)-1),\n",
        "                             mode='connectivity', include_self=False)\n",
        "        rows, cols = A.nonzero()\n",
        "        edge_index = np.vstack([rows, cols]).astype(np.int64)\n",
        "    else:\n",
        "        edge_index = np.zeros((2,0), dtype=np.int64)\n",
        "    g = Data(x=torch.tensor(X), edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
        "    g.y = torch.tensor([float(label) if not np.isnan(label) else np.nan], dtype=torch.float32)\n",
        "    g.subject_id = str(subject_id)\n",
        "    g.timepoint = float(timepoint) if (timepoint is not None and not np.isnan(timepoint)) else 0.0\n",
        "    # track origin\n",
        "    g.source_archive = str(Path(nifti_path).parts[1] if len(Path(nifti_path).parts)>1 else Path(nifti_path).parent.name)\n",
        "    return g\n"
      ],
      "metadata": {
        "id": "f-iEGIV2MkDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# build quick lookup by subject id (first occurrence)\n",
        "meta_index = meta.set_index(\"subject_id\")\n",
        "\n",
        "graphs_part = []\n",
        "skipped = []\n",
        "\n",
        "# try to match file -> subject by substring (subject id should appear in filename)\n",
        "for nii in tqdm(nii_files, desc=\"Process files\"):\n",
        "    stem = Path(nii).name\n",
        "    # find candidate subject id(s)\n",
        "    matched_sid = None\n",
        "    for sid in meta[\"subject_id\"].unique():\n",
        "        if sid in stem:\n",
        "            matched_sid = sid\n",
        "            break\n",
        "    if matched_sid is None:\n",
        "        # fallback: try regex of digits e.g. '0001' and match\n",
        "        m = re.search(r\"\\d{3,4}\", stem)\n",
        "        if m:\n",
        "            token = m.group(0)\n",
        "            cand = meta[meta[\"subject_id\"].str.contains(token, na=False)]\n",
        "            if len(cand)>0:\n",
        "                matched_sid = cand.iloc[0][\"subject_id\"]\n",
        "    if matched_sid is None:\n",
        "        skipped.append((nii, \"no_subject_match\"))\n",
        "        continue\n",
        "\n",
        "    # take first matching clinical row for label/time\n",
        "    row = meta_index.loc[matched_sid]\n",
        "    label = row[\"label\"] if \"label\" in row.index else np.nan\n",
        "    tp = row[\"timepoint\"] if \"timepoint\" in row.index else 0.0\n",
        "\n",
        "    try:\n",
        "        preproc = preprocess_mri(nii, PREPROC_DIR, target_shape=(96,96,96))\n",
        "        g = mri_to_graph(preproc, matched_sid, label, tp, patch_size=3, n_neighbors=6, sample_n=400)\n",
        "        graphs_part.append(g)\n",
        "    except Exception as e:\n",
        "        skipped.append((nii, str(e)))\n",
        "\n",
        "print(\"Built graphs in this part:\", len(graphs_part), \"Skipped:\", len(skipped))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zD85NkyNDS8",
        "outputId": "089a29ea-efb4-46f0-bd9d-09090eba858f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process files: 100%|██████████| 596/596 [00:00<00:00, 13180.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built graphs in this part: 0 Skipped: 596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import numpy as np\n",
        "\n",
        "PART_PT = GRAPH_DIR / \"oasis2_graphs_labeled_part2.pt\"\n",
        "MASTER_PT = GRAPH_DIR / \"oasis2_graphs_labeled_auto_full.pt\"\n",
        "GLOBAL_PT = GRAPH_DIR / \"all_graphs_master.pt\"\n",
        "\n",
        "# save the part file\n",
        "torch.save(graphs_part, PART_PT)\n",
        "print(\"Saved part graphs:\", PART_PT, \"count:\", len(graphs_part))\n",
        "\n",
        "# load existing master if exists (use safe_globals)\n",
        "existing = []\n",
        "try:\n",
        "    import torch_geometric\n",
        "    with torch.serialization.safe_globals([torch_geometric.data.storage.GlobalStorage]):\n",
        "        if MASTER_PT.exists():\n",
        "            existing = torch.load(MASTER_PT, map_location=\"cpu\")\n",
        "except Exception:\n",
        "    if MASTER_PT.exists():\n",
        "        existing = torch.load(MASTER_PT, map_location=\"cpu\", weights_only=False)\n",
        "\n",
        "print(\"Existing master count:\", len(existing))\n",
        "\n",
        "# merge with dedupe by (subject_id, timepoint, source_archive) preferring new graphs if label present\n",
        "merged = {}\n",
        "def key_for(g, idx):\n",
        "    sid = getattr(g, \"subject_id\", None) or f\"__idx__{idx}\"\n",
        "    tp = getattr(g, \"timepoint\", None) or 0.0\n",
        "    src = getattr(g, \"source_archive\", \"\")\n",
        "    return (str(sid), float(tp), str(src))\n",
        "\n",
        "# add existing\n",
        "for i,g in enumerate(existing):\n",
        "    merged[key_for(g,i)] = g\n",
        "\n",
        "# add new, overriding when appropriate (prefer labeled or prefer new)\n",
        "for i,g in enumerate(graphs_part):\n",
        "    k = key_for(g,i)\n",
        "    if k not in merged:\n",
        "        merged[k] = g\n",
        "    else:\n",
        "        prev = merged[k]\n",
        "        try:\n",
        "            prev_y = float(prev.y.view(-1).cpu().numpy()[0])\n",
        "        except Exception:\n",
        "            prev_y = np.nan\n",
        "        try:\n",
        "            new_y = float(g.y.view(-1).cpu().numpy()[0])\n",
        "        except Exception:\n",
        "            new_y = np.nan\n",
        "        if (not np.isnan(new_y) and np.isnan(prev_y)) or (not np.isnan(new_y) and not np.isnan(prev_y)):\n",
        "            # prefer new if it has label or equally labeled (choose new)\n",
        "            merged[k] = g\n",
        "\n",
        "merged_list = list(merged.values())\n",
        "print(\"Merged master count (after adding this part):\", len(merged_list))\n",
        "\n",
        "# atomic save\n",
        "tmp = tempfile.mktemp(suffix=\".pt\")\n",
        "torch.save(merged_list, tmp)\n",
        "Path(tmp).replace(MASTER_PT)\n",
        "print(\"Saved merged master to:\", MASTER_PT)\n",
        "\n",
        "# also append to global master (all_graphs_master.pt)\n",
        "global_existing = []\n",
        "if GLOBAL_PT.exists():\n",
        "    try:\n",
        "        with torch.serialization.safe_globals([torch_geometric.data.storage.GlobalStorage]):\n",
        "            global_existing = torch.load(GLOBAL_PT, map_location=\"cpu\")\n",
        "    except Exception:\n",
        "        global_existing = torch.load(GLOBAL_PT, map_location=\"cpu\", weights_only=False)\n",
        "# append all new graphs (no dedupe across datasets unless you want it)\n",
        "global_combined = list(global_existing) + graphs_part\n",
        "torch.save(global_combined, GLOBAL_PT)\n",
        "print(\"Appended to global master (count now):\", len(global_combined))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "6WGB_CAzNDOi",
        "outputId": "3f251302-26d0-4332-ac67-705fe5cadc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved part graphs: /content/drive/MyDrive/oasis_project/data/graphs/oasis2_graphs_labeled_part2.pt count: 0\n",
            "Existing master count: 209\n",
            "Merged master count (after adding this part): 209\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 18] Invalid cross-device link: '/tmp/tmpjrbncr1w.pt' -> '/content/drive/MyDrive/oasis_project/data/graphs/oasis2_graphs_labeled_auto_full.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3563294113.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmktemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMASTER_PT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved merged master to:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMASTER_PT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mPath\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mpointing\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \"\"\"\n\u001b[0;32m-> 1376\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 18] Invalid cross-device link: '/tmp/tmpjrbncr1w.pt' -> '/content/drive/MyDrive/oasis_project/data/graphs/oasis2_graphs_labeled_auto_full.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fixer: match by parent folder name, build graphs for PART2, and save safely ---\n",
        "from pathlib import Path\n",
        "import re, collections, math, shutil, tempfile\n",
        "import nibabel as nib, numpy as np, torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from skimage.transform import resize\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# --- CONFIG: adjust if yours differ ---\n",
        "GRAPH_DIR = Path(\"/content/drive/MyDrive/oasis_project/data/graphs\")\n",
        "RAW_ROOT  = Path(\"/content/drive/MyDrive/oasis_project/data/raw/oasis2\")\n",
        "PART_NAME = \"OAS2_RAW_PART2\"   # folder name inside RAW_ROOT created when archive extracted\n",
        "PART_OUT  = GRAPH_DIR / \"oasis2_graphs_labeled_part2.pt\"\n",
        "CLIN_XLSX = Path(\"/content/drive/MyDrive/oasis_project/data/demographics/oasis2_demographics.xlsx\")\n",
        "\n",
        "# locate extracted folder for part2\n",
        "candidates = list(RAW_ROOT.rglob(f\"*{PART_NAME}*\"))\n",
        "if len(candidates)==0:\n",
        "    raise FileNotFoundError(f\"Could not find extracted folder for {PART_NAME} under {RAW_ROOT}. Check extraction path.\")\n",
        "extracted_dir = candidates[0]\n",
        "print(\"Using extracted dir:\", extracted_dir)\n",
        "\n",
        "# load clinical meta and canonicalize subject ids (keep first two underscore parts)\n",
        "import pandas as pd\n",
        "meta = pd.read_excel(CLIN_XLSX)\n",
        "# detect id column\n",
        "id_col = next((c for c in meta.columns if any(tok in c.lower() for tok in (\"id\",\"subject\",\"subj\",\"ptid\"))), meta.columns[0])\n",
        "label_col = next((c for c in meta.columns if \"cdr\" in c.lower() or \"label\" in c.lower() or \"dx\" in c.lower()), None)\n",
        "time_col = next((c for c in meta.columns if \"visit\" in c.lower() or \"delay\" in c.lower() or \"date\" in c.lower()), None)\n",
        "\n",
        "def canonical_subject(s):\n",
        "    s = str(s)\n",
        "    parts = s.split('_')\n",
        "    return \"_\".join(parts[:2]) if len(parts)>=2 else s\n",
        "\n",
        "meta[\"subject_id\"] = meta[id_col].astype(str).map(canonical_subject)\n",
        "if label_col:\n",
        "    meta[\"label\"] = pd.to_numeric(meta[label_col], errors=\"coerce\")\n",
        "else:\n",
        "    meta[\"label\"] = np.nan\n",
        "if time_col:\n",
        "    meta[\"timepoint\"] = pd.to_numeric(meta[time_col], errors=\"coerce\")\n",
        "else:\n",
        "    meta[\"timepoint\"] = np.nan\n",
        "\n",
        "meta_index = meta.set_index(\"subject_id\", drop=False)\n",
        "print(\"Clinical subjects available:\", meta[\"subject_id\"].nunique())\n",
        "\n",
        "# helper: preprocess + graphify (same logic as before)\n",
        "def preprocess_mri(path, out_dir, target_shape=(96,96,96)):\n",
        "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    img = nib.load(str(path))\n",
        "    data = img.get_fdata().astype(np.float32)\n",
        "    mask = data > np.percentile(data, 5)\n",
        "    if mask.sum()==0:\n",
        "        mask = data!=0\n",
        "    mu = data[mask].mean() if mask.sum()>0 else data.mean()\n",
        "    sd = data[mask].std() if mask.sum()>0 else data.std()\n",
        "    data = (data - mu) / (sd + 1e-6)\n",
        "    data = resize(data, target_shape, order=1, preserve_range=True, anti_aliasing=True)\n",
        "    out_path = out_dir / f\"{Path(path).stem}_preproc.nii.gz\"\n",
        "    nib.save(nib.Nifti1Image(data.astype(np.float32), affine=np.eye(4)), str(out_path))\n",
        "    return out_path\n",
        "\n",
        "def mri_to_graph(nifti_path, subject_id, label, timepoint, patch_size=3, n_neighbors=6, sample_n=400):\n",
        "    data = nib.load(str(nifti_path)).get_fdata().astype(np.float32)\n",
        "    data = (data - data.mean()) / (data.std() + 1e-6)\n",
        "    coords_all = np.stack(np.meshgrid(np.arange(data.shape[0]),\n",
        "                                      np.arange(data.shape[1]),\n",
        "                                      np.arange(data.shape[2]),\n",
        "                                      indexing='ij'), axis=-1).reshape(-1,3)\n",
        "    mask = data.reshape(-1) > np.percentile(data.reshape(-1), 10)\n",
        "    coords = coords_all[mask]\n",
        "    if coords.shape[0] > sample_n:\n",
        "        idx = np.linspace(0, coords.shape[0]-1, sample_n).astype(int)\n",
        "        coords = coords[idx]\n",
        "    feats = []; valid_coords=[]\n",
        "    for (x,y,z) in coords:\n",
        "        x,y,z = int(x), int(y), int(z)\n",
        "        x0,x1 = max(0,x-patch_size), min(data.shape[0], x+patch_size+1)\n",
        "        y0,y1 = max(0,y-patch_size), min(data.shape[1], y+patch_size+1)\n",
        "        z0,z1 = max(0,z-patch_size), min(data.shape[2], z+patch_size+1)\n",
        "        patch = data[x0:x1, y0:y1, z0:z1]\n",
        "        feats.append([patch.mean(), patch.std(), patch.min(), patch.max()])\n",
        "        valid_coords.append([x,y,z])\n",
        "    X = np.array(feats, dtype=np.float32)\n",
        "    if len(valid_coords) > 1:\n",
        "        A = kneighbors_graph(np.array(valid_coords), n_neighbors=min(n_neighbors, len(valid_coords)-1),\n",
        "                             mode='connectivity', include_self=False)\n",
        "        rows, cols = A.nonzero()\n",
        "        edge_index = np.vstack([rows, cols]).astype(np.int64)\n",
        "    else:\n",
        "        edge_index = np.zeros((2,0), dtype=np.int64)\n",
        "    g = Data(x=torch.tensor(X), edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
        "    g.y = torch.tensor([float(label) if not np.isnan(label) else np.nan], dtype=torch.float32)\n",
        "    g.subject_id = str(subject_id)\n",
        "    g.timepoint = float(timepoint) if (not pd.isna(timepoint)) else 0.0\n",
        "    g.source_archive = PART_NAME\n",
        "    return g\n",
        "\n",
        "# scan all image files under extracted_dir\n",
        "all_imgs = sorted(list(extracted_dir.rglob(\"*.nii*\")) + list(extracted_dir.rglob(\"*.img\")) + list(extracted_dir.rglob(\"*.hdr\")))\n",
        "print(\"Total image-like files found:\", len(all_imgs))\n",
        "\n",
        "# match by searching parent directory names for pattern like 'OAS2_0100' or 'OAS2_0100_MR1'\n",
        "pattern = re.compile(r\"(OAS[12]_[0-9]{3,4})\", flags=re.IGNORECASE)\n",
        "\n",
        "matched_subject_files = {}   # sid -> first image path\n",
        "skipped = []\n",
        "\n",
        "for p in all_imgs:\n",
        "    # search among parents for subject folder token\n",
        "    sid_candidate = None\n",
        "    for part in reversed(p.parts):  # iterate path parts from leaf to root\n",
        "        m = pattern.search(part)\n",
        "        if m:\n",
        "            sid_candidate = m.group(1)\n",
        "            break\n",
        "    if sid_candidate is None:\n",
        "        # also try filename\n",
        "        m = pattern.search(p.name)\n",
        "        if m:\n",
        "            sid_candidate = m.group(1)\n",
        "    if sid_candidate is None:\n",
        "        skipped.append((p, \"no_subject_token_in_path\"))\n",
        "        continue\n",
        "    # canonicalize (keep first two underscore parts)\n",
        "    parts = sid_candidate.split(\"_\")\n",
        "    sid_can = \"_\".join(parts[:2]) if len(parts)>=2 else sid_candidate\n",
        "    # try match to clinical IDs (meta[\"subject_id\"]) - exact or case-insensitive\n",
        "    if sid_can in meta[\"subject_id\"].values:\n",
        "        if sid_can not in matched_subject_files:\n",
        "            matched_subject_files[sid_can] = p\n",
        "    else:\n",
        "        # try case-insensitive / partial numeric match (e.g., '0100' -> 'OAS2_0100')\n",
        "        digits = re.search(r\"\\d{3,4}\", sid_candidate)\n",
        "        if digits:\n",
        "            token = digits.group(0)\n",
        "            cand = meta[meta[\"subject_id\"].str.contains(token, na=False)]\n",
        "            if len(cand) > 0:\n",
        "                sid_match = cand.iloc[0][\"subject_id\"]\n",
        "                if sid_match not in matched_subject_files:\n",
        "                    matched_subject_files[sid_match] = p\n",
        "            else:\n",
        "                skipped.append((p, f\"no_clinical_match_for_{sid_candidate}\"))\n",
        "        else:\n",
        "            skipped.append((p, f\"candidate_{sid_candidate}_no_digits\"))\n",
        "\n",
        "print(\"Unique subjects matched to an image:\", len(matched_subject_files))\n",
        "print(\"Sample matches (up to 10):\")\n",
        "for k,v in list(matched_subject_files.items())[:10]:\n",
        "    print(\" \", k, \"->\", v.name)\n",
        "\n",
        "# build graphs for matched subjects (one image per subject)\n",
        "graphs_part = []\n",
        "skipped_build = []\n",
        "for sid, img_path in tqdm(matched_subject_files.items(), desc=\"Building graphs\"):\n",
        "    try:\n",
        "        row = meta_index.loc[sid]\n",
        "        label = row.get(\"label\", np.nan)\n",
        "        tp = row.get(\"timepoint\", 0.0)\n",
        "        preproc = preprocess_mri(img_path, PREPROC_DIR, target_shape=(96,96,96))\n",
        "        g = mri_to_graph(preproc, sid, label, tp, patch_size=3, n_neighbors=6, sample_n=400)\n",
        "        graphs_part.append(g)\n",
        "    except Exception as e:\n",
        "        skipped_build.append((sid, str(e)))\n",
        "\n",
        "print(\"Built graphs:\", len(graphs_part), \"skipped builds:\", len(skipped_build))\n",
        "print(\"Top skip reasons (first 20):\", skipped[:20] + skipped_build[:20])\n",
        "\n",
        "# Save the PART file atomically into same GRAPH_DIR (avoid cross-device replace)\n",
        "if len(graphs_part) > 0:\n",
        "    tmp_fd, tmp_path = tempfile.mkstemp(suffix=\".pt\", dir=str(GRAPH_DIR))\n",
        "    os.close(tmp_fd)\n",
        "    torch.save(graphs_part, tmp_path)\n",
        "    Path(tmp_path).replace(PART_OUT)\n",
        "    print(\"Saved part graphs to:\", PART_OUT)\n",
        "else:\n",
        "    print(\"No graphs built - part file not saved (graphs_part empty). Inspect skip reasons above.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGu8t8RoVGi1",
        "outputId": "16c2fd53-2fe8-4ee6-f282-6a32426157e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using extracted dir: /content/drive/MyDrive/oasis_project/data/raw/oasis2/OAS2_RAW_PART2.tar\n",
            "Clinical subjects available: 150\n",
            "Total image-like files found: 1192\n",
            "Unique subjects matched to an image: 68\n",
            "Sample matches (up to 10):\n",
            "  OAS2_0100 -> mpr-1.nifti.hdr\n",
            "  OAS2_0101 -> mpr-1.nifti.hdr\n",
            "  OAS2_0102 -> mpr-1.nifti.hdr\n",
            "  OAS2_0103 -> mpr-1.nifti.hdr\n",
            "  OAS2_0104 -> mpr-1.nifti.hdr\n",
            "  OAS2_0105 -> mpr-1.nifti.hdr\n",
            "  OAS2_0106 -> mpr-1.nifti.hdr\n",
            "  OAS2_0108 -> mpr-1.nifti.hdr\n",
            "  OAS2_0109 -> mpr-1.nifti.hdr\n",
            "  OAS2_0111 -> mpr-1.nifti.hdr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building graphs: 100%|██████████| 68/68 [01:12<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built graphs: 0 skipped builds: 68\n",
            "Top skip reasons (first 20): [('OAS2_0100', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0101', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0102', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0103', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0104', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0105', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0106', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0108', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0109', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0111', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0112', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0113', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0114', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0116', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0117', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0118', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0119', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0120', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0121', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().'), ('OAS2_0122', 'The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().')]\n",
            "No graphs built - part file not saved (graphs_part empty). Inspect skip reasons above.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuild graphs_part safely for PART2; fixes ambiguous Series error by selecting first clinical row\n",
        "from pathlib import Path\n",
        "import tempfile, os, traceback\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from skimage.transform import resize\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "GRAPH_DIR = Path(\"/content/drive/MyDrive/oasis_project/data/graphs\")\n",
        "PART_OUT  = GRAPH_DIR / \"oasis2_graphs_labeled_part2.pt\"\n",
        "PREPROC_DIR = Path(\"/content/drive/MyDrive/oasis_project/data/preproc/oasis2\")\n",
        "PREPROC_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# load clinical meta if not in memory\n",
        "import pandas as pd\n",
        "CLIN_XLSX = Path(\"/content/drive/MyDrive/oasis_project/data/demographics/oasis2_demographics.xlsx\")\n",
        "meta = pd.read_excel(CLIN_XLSX) if 'meta' not in globals() else meta.copy()\n",
        "# ensure canonical subject_id exists\n",
        "if \"subject_id\" not in meta.columns:\n",
        "    id_col = next((c for c in meta.columns if any(tok in c.lower() for tok in (\"id\",\"subject\",\"subj\",\"ptid\"))), meta.columns[0])\n",
        "    def canonical_subject(s):\n",
        "        s = str(s)\n",
        "        parts = s.split('_')\n",
        "        return \"_\".join(parts[:2]) if len(parts)>=2 else s\n",
        "    meta[\"subject_id\"] = meta[id_col].astype(str).map(canonical_subject)\n",
        "# optional: coerce label/timepoint names to 'label'/'timepoint' if present\n",
        "if 'label' not in meta.columns and any(\"cdr\" in c.lower() for c in meta.columns):\n",
        "    cdr_col = next(c for c in meta.columns if \"cdr\" in c.lower())\n",
        "    meta['label'] = pd.to_numeric(meta[cdr_col], errors='coerce')\n",
        "if 'timepoint' not in meta.columns:\n",
        "    # try 'delay' or date-like columns\n",
        "    tp_col = next((c for c in meta.columns if any(tok in c.lower() for tok in (\"delay\",\"visit\",\"time\",\"date\",\"session\"))), None)\n",
        "    if tp_col is not None:\n",
        "        meta['timepoint'] = pd.to_numeric(meta[tp_col], errors='coerce')\n",
        "    else:\n",
        "        meta['timepoint'] = np.nan\n",
        "\n",
        "meta_index = meta.set_index(\"subject_id\", drop=False)\n",
        "\n",
        "# matched_subject_files dictionary should exist from prior run.\n",
        "# If not present, attempt to recompute by scanning extracted dir for the PART folder pattern:\n",
        "if 'matched_subject_files' not in globals() or not matched_subject_files:\n",
        "    print(\"matched_subject_files not found — attempting to compute it again from extracted PART folder.\")\n",
        "    RAW_ROOT = Path(\"/content/drive/MyDrive/oasis_project/data/raw/oasis2\")\n",
        "    PART_NAME = \"OAS2_RAW_PART2\"\n",
        "    candidates = list(RAW_ROOT.rglob(f\"*{PART_NAME}*\"))\n",
        "    if len(candidates)==0:\n",
        "        raise FileNotFoundError(f\"Could not locate extracted folder for {PART_NAME} under {RAW_ROOT}\")\n",
        "    extracted_dir = candidates[0]\n",
        "    all_imgs = sorted(list(extracted_dir.rglob(\"*.nii*\")) + list(extracted_dir.rglob(\"*.img\")) + list(extracted_dir.rglob(\"*.hdr\")))\n",
        "    import re\n",
        "    pattern = re.compile(r\"(OAS2?_[0-9]{3,4})\", flags=re.IGNORECASE)\n",
        "    matched_subject_files = {}\n",
        "    for p in all_imgs:\n",
        "        sid_candidate = None\n",
        "        for part in reversed(p.parts):\n",
        "            m = pattern.search(part)\n",
        "            if m:\n",
        "                sid_candidate = m.group(1)\n",
        "                break\n",
        "        if sid_candidate:\n",
        "            sid_can = \"_\".join(sid_candidate.split(\"_\")[:2])\n",
        "            # match to clinical index by exact or by numeric token\n",
        "            if sid_can in meta[\"subject_id\"].values:\n",
        "                matched_subject_files.setdefault(sid_can, p)\n",
        "            else:\n",
        "                digits = re.search(r\"\\d{3,4}\", sid_candidate)\n",
        "                if digits:\n",
        "                    token = digits.group(0)\n",
        "                    cand = meta[meta[\"subject_id\"].str.contains(token, na=False)]\n",
        "                    if len(cand)>0:\n",
        "                        matched_subject_files.setdefault(cand.iloc[0][\"subject_id\"], p)\n",
        "    print(\"Recomputed matched_subject_files size:\", len(matched_subject_files))\n",
        "\n",
        "print(f\"Processing {len(matched_subject_files)} matched subjects into graphs...\")\n",
        "\n",
        "# helper functions (same as before)\n",
        "def preprocess_mri(path, out_dir, target_shape=(96,96,96)):\n",
        "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    img = nib.load(str(path))\n",
        "    data = img.get_fdata().astype(np.float32)\n",
        "    mask = data > np.percentile(data, 5)\n",
        "    if mask.sum()==0:\n",
        "        mask = data != 0\n",
        "    mu = data[mask].mean() if mask.sum()>0 else data.mean()\n",
        "    sd = data[mask].std() if mask.sum()>0 else data.std()\n",
        "    data = (data - mu) / (sd + 1e-6)\n",
        "    data = resize(data, target_shape, order=1, preserve_range=True, anti_aliasing=True)\n",
        "    out_path = out_dir / f\"{Path(path).stem}_preproc.nii.gz\"\n",
        "    nib.save(nib.Nifti1Image(data.astype(np.float32), affine=np.eye(4)), str(out_path))\n",
        "    return out_path\n",
        "\n",
        "def mri_to_graph(nifti_path, subject_id, label, timepoint, patch_size=3, n_neighbors=6, sample_n=400):\n",
        "    data = nib.load(str(nifti_path)).get_fdata().astype(np.float32)\n",
        "    data = (data - data.mean()) / (data.std() + 1e-6)\n",
        "    coords_all = np.stack(np.meshgrid(np.arange(data.shape[0]),\n",
        "                                      np.arange(data.shape[1]),\n",
        "                                      np.arange(data.shape[2]),\n",
        "                                      indexing='ij'), axis=-1).reshape(-1,3)\n",
        "    mask = data.reshape(-1) > np.percentile(data.reshape(-1), 10)\n",
        "    coords = coords_all[mask]\n",
        "    if coords.shape[0] > sample_n:\n",
        "        idx = np.linspace(0, coords.shape[0]-1, sample_n).astype(int)\n",
        "        coords = coords[idx]\n",
        "    feats = []; valid_coords=[]\n",
        "    for (x,y,z) in coords:\n",
        "        x,y,z = int(x), int(y), int(z)\n",
        "        x0,x1 = max(0,x-patch_size), min(data.shape[0], x+patch_size+1)\n",
        "        y0,y1 = max(0,y-patch_size), min(data.shape[1], y+patch_size+1)\n",
        "        z0,z1 = max(0,z-patch_size), min(data.shape[2], z+patch_size+1)\n",
        "        patch = data[x0:x1, y0:y1, z0:z1]\n",
        "        feats.append([patch.mean(), patch.std(), patch.min(), patch.max()])\n",
        "        valid_coords.append([x,y,z])\n",
        "    X = np.array(feats, dtype=np.float32)\n",
        "    if len(valid_coords) > 1:\n",
        "        A = kneighbors_graph(np.array(valid_coords), n_neighbors=min(n_neighbors, len(valid_coords)-1),\n",
        "                             mode='connectivity', include_self=False)\n",
        "        rows, cols = A.nonzero()\n",
        "        edge_index = np.vstack([rows, cols]).astype(np.int64)\n",
        "    else:\n",
        "        edge_index = np.zeros((2,0), dtype=np.int64)\n",
        "    g = Data(x=torch.tensor(X), edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
        "    g.y = torch.tensor([float(label) if not np.isnan(label) else np.nan], dtype=torch.float32)\n",
        "    g.subject_id = str(subject_id)\n",
        "    g.timepoint = float(timepoint) if (not pd.isna(timepoint)) else 0.0\n",
        "    g.source_archive = \"OAS2_RAW_PART2\"\n",
        "    return g\n",
        "\n",
        "# Build graphs_part with robust row selection\n",
        "graphs_part = []\n",
        "skipped_build = []\n",
        "for sid, img_path in tqdm(matched_subject_files.items(), desc=\"Building graphs (fixed)\"):\n",
        "    try:\n",
        "        # select first matching clinical row (avoid ambiguous Series issue)\n",
        "        rows = meta[meta[\"subject_id\"] == sid]\n",
        "        if len(rows) == 0:\n",
        "            skipped_build.append((sid, \"no_clinical_row\"))\n",
        "            continue\n",
        "        row = rows.iloc[0]   # pick first row if there are duplicates\n",
        "        label = row.get(\"label\", np.nan)\n",
        "        tp = row.get(\"timepoint\", np.nan)\n",
        "        preproc = preprocess_mri(img_path, PREPROC_DIR, target_shape=(96,96,96))\n",
        "        g = mri_to_graph(preproc, sid, label, tp, patch_size=3, n_neighbors=6, sample_n=400)\n",
        "        graphs_part.append(g)\n",
        "    except Exception as e:\n",
        "        skipped_build.append((sid, str(e)))\n",
        "        traceback.print_exc()\n",
        "\n",
        "print(\"Built graphs:\", len(graphs_part), \"skipped builds:\", len(skipped_build))\n",
        "if skipped_build:\n",
        "    print(\"Sample skipped build reasons (up to 20):\")\n",
        "    for s in skipped_build[:20]:\n",
        "        print(\" \", s)\n",
        "\n",
        "# Save PART file atomically inside GRAPH_DIR to avoid cross-device replace\n",
        "if len(graphs_part) > 0:\n",
        "    fd, tmp_path = tempfile.mkstemp(suffix=\".pt\", dir=str(GRAPH_DIR))\n",
        "    os.close(fd)\n",
        "    torch.save(graphs_part, tmp_path)\n",
        "    Path(tmp_path).replace(PART_OUT)\n",
        "    print(\"Saved PART file to:\", PART_OUT)\n",
        "else:\n",
        "    print(\"No graphs built; PART file not saved. Inspect skipped_build above.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upWsI3ukWhCg",
        "outputId": "ecd25707-2161-4dcf-c7d2-24058c53eb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 68 matched subjects into graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building graphs (fixed): 100%|██████████| 68/68 [01:13<00:00,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built graphs: 68 skipped builds: 0\n",
            "Saved PART file to: /content/drive/MyDrive/oasis_project/data/graphs/oasis2_graphs_labeled_part2.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge PART into MASTER safely, dedupe by (subject_id, timepoint), prefer labeled/new graphs.\n",
        "from pathlib import Path\n",
        "import os, tempfile, shutil\n",
        "import torch, numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "GRAPH_DIR = Path(\"/content/drive/MyDrive/oasis_project/data/graphs\")\n",
        "PART_PT = GRAPH_DIR / \"oasis2_graphs_labeled_part2.pt\"\n",
        "MASTER_PT = GRAPH_DIR / \"oasis2_graphs_labeled_auto_full.pt\"\n",
        "\n",
        "assert PART_PT.exists(), f\"Part file missing: {PART_PT}\"\n",
        "assert MASTER_PT.exists(), f\"Master file missing: {MASTER_PT}\"\n",
        "\n",
        "# Load with PyG safe context if possible\n",
        "def safe_load(p):\n",
        "    try:\n",
        "        import torch_geometric\n",
        "        with torch.serialization.safe_globals([torch_geometric.data.storage.GlobalStorage]):\n",
        "            return torch.load(p, map_location=\"cpu\")\n",
        "    except Exception:\n",
        "        return torch.load(p, map_location=\"cpu\", weights_only=False)\n",
        "\n",
        "master = safe_load(MASTER_PT)\n",
        "part   = safe_load(PART_PT)\n",
        "print(\"Loaded master count:\", len(master))\n",
        "print(\"Loaded part count:\", len(part))\n",
        "\n",
        "# Build keyed dict: key = (subject_id, timepoint)\n",
        "def get_key(g, idx):\n",
        "    sid = getattr(g, \"subject_id\", None)\n",
        "    if sid is None:\n",
        "        sid = f\"__idx__{idx}\"\n",
        "    tp = getattr(g, \"timepoint\", None)\n",
        "    try:\n",
        "        tp_f = float(tp) if tp is not None else 0.0\n",
        "    except Exception:\n",
        "        tp_f = 0.0\n",
        "    return (str(sid), tp_f)\n",
        "\n",
        "merged = {}\n",
        "source_of = {}  # track which source (master or part) provided the entry\n",
        "\n",
        "# add existing master first (lower priority)\n",
        "for i,g in enumerate(master):\n",
        "    merged[get_key(g,i)] = g\n",
        "    source_of[get_key(g,i)] = \"master\"\n",
        "\n",
        "# merge part: override according to policy (prefer labeled; else prefer part)\n",
        "added=0; replaced=0; kept=0\n",
        "for i,g in enumerate(part):\n",
        "    k = get_key(g, i)\n",
        "    try:\n",
        "        new_y = float(g.y.view(-1).cpu().numpy()[0])\n",
        "    except Exception:\n",
        "        try:\n",
        "            new_y = float(g.y)\n",
        "        except Exception:\n",
        "            new_y = np.nan\n",
        "    if k not in merged:\n",
        "        merged[k] = g\n",
        "        source_of[k] = \"part\"\n",
        "        added += 1\n",
        "    else:\n",
        "        prev = merged[k]\n",
        "        try:\n",
        "            prev_y = float(prev.y.view(-1).cpu().numpy()[0])\n",
        "        except Exception:\n",
        "            try:\n",
        "                prev_y = float(prev.y)\n",
        "            except Exception:\n",
        "                prev_y = np.nan\n",
        "        # decide: prefer graph with a label; if both labeled or both unlabeled, prefer the part (new)\n",
        "        prev_has = not np.isnan(prev_y)\n",
        "        new_has = not np.isnan(new_y)\n",
        "        if new_has and not prev_has:\n",
        "            merged[k] = g; source_of[k] = \"part\"; replaced += 1\n",
        "        elif new_has == prev_has:\n",
        "            # prefer newer (part)\n",
        "            merged[k] = g; source_of[k] = \"part\"; replaced += 1\n",
        "        else:\n",
        "            kept += 1\n",
        "\n",
        "merged_list = list(merged.values())\n",
        "print(f\"Merged master count (after): {len(merged_list)} (added {added}, replaced {replaced}, kept {kept})\")\n",
        "\n",
        "# Atomic save: write temp inside GRAPH_DIR to avoid cross-device link error\n",
        "tmp_fd, tmp_path = tempfile.mkstemp(suffix=\".pt\", dir=str(GRAPH_DIR))\n",
        "os.close(tmp_fd)\n",
        "torch.save(merged_list, tmp_path)\n",
        "os.replace(tmp_path, str(MASTER_PT))\n",
        "print(\"Master saved to:\", MASTER_PT)\n",
        "\n",
        "# Summary: show a few changes\n",
        "from collections import defaultdict\n",
        "count_by_source = Counter(source_of.values())\n",
        "print(\"Entries by source after merge (sample):\", dict(count_by_source))\n",
        "\n",
        "# Show subject IDs that were added from the part (up to 20)\n",
        "added_sids = [k[0] for k,v in source_of.items() if v==\"part\"]\n",
        "print(\"Sample subject IDs now coming from part (up to 20):\", added_sids[:20])\n",
        "\n",
        "# Quick sanity: label distribution in merged master\n",
        "labels=[]\n",
        "for g in merged_list:\n",
        "    try:\n",
        "        labels.append(float(g.y.view(-1).cpu().numpy()[0]))\n",
        "    except Exception:\n",
        "        try:\n",
        "            labels.append(float(g.y))\n",
        "        except Exception:\n",
        "            labels.append(np.nan)\n",
        "lbl_counts = Counter([l for l in labels if not np.isnan(l)])\n",
        "print(\"Label counts (non-NaN) in merged master (top items):\")\n",
        "for k,v in sorted(lbl_counts.items()):\n",
        "    print(\" \", k, \":\", v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcvf05kKXzpu",
        "outputId": "5e64b6f9-c295-4020-ac9a-6613ac4cad0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded master count: 209\n",
            "Loaded part count: 68\n",
            "Merged master count (after): 277 (added 68, replaced 0, kept 0)\n",
            "Master saved to: /content/drive/MyDrive/oasis_project/data/graphs/oasis2_graphs_labeled_auto_full.pt\n",
            "Entries by source after merge (sample): {'master': 209, 'part': 68}\n",
            "Sample subject IDs now coming from part (up to 20): ['OAS2_0100', 'OAS2_0101', 'OAS2_0102', 'OAS2_0103', 'OAS2_0104', 'OAS2_0105', 'OAS2_0106', 'OAS2_0108', 'OAS2_0109', 'OAS2_0111', 'OAS2_0112', 'OAS2_0113', 'OAS2_0114', 'OAS2_0116', 'OAS2_0117', 'OAS2_0118', 'OAS2_0119', 'OAS2_0120', 'OAS2_0121', 'OAS2_0122']\n",
            "Label counts (non-NaN) in merged master (top items):\n",
            "  0.0 : 144\n",
            "  0.5 : 102\n",
            "  1.0 : 28\n",
            "  2.0 : 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge helper: call this after you save oasis2_graphs_labeled_partX.pt for a new part\n",
        "from pathlib import Path\n",
        "import os, tempfile, shutil\n",
        "import torch, numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "GRAPH_DIR = Path(\"/content/drive/MyDrive/oasis_project/data/graphs\")\n",
        "MASTER_PT = GRAPH_DIR / \"oasis2_graphs_labeled_auto_full.pt\"\n",
        "GLOBAL_PT = GRAPH_DIR / \"all_graphs_master.pt\"\n",
        "\n",
        "def safe_load(p):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"File not found: {p}\")\n",
        "    try:\n",
        "        import torch_geometric\n",
        "        with torch.serialization.safe_globals([torch_geometric.data.storage.GlobalStorage]):\n",
        "            return torch.load(p, map_location=\"cpu\")\n",
        "    except Exception:\n",
        "        return torch.load(p, map_location=\"cpu\", weights_only=False)\n",
        "\n",
        "def merge_part_to_master(part_pt_path):\n",
        "    part_pt = Path(part_pt_path)\n",
        "    assert part_pt.exists(), f\"Part file not found: {part_pt}\"\n",
        "    print(\"Loading files...\")\n",
        "    master = safe_load(MASTER_PT) if MASTER_PT.exists() else []\n",
        "    part   = safe_load(part_pt)\n",
        "    print(f\"Master count: {len(master)}, Part count: {len(part)}\")\n",
        "\n",
        "    def key_for(g, idx):\n",
        "        sid = getattr(g, \"subject_id\", None) or f\"__idx__{idx}\"\n",
        "        tp = getattr(g, \"timepoint\", None)\n",
        "        try:\n",
        "            tpf = float(tp) if tp is not None else 0.0\n",
        "        except Exception:\n",
        "            tpf = 0.0\n",
        "        return (str(sid), tpf)\n",
        "\n",
        "    merged = {}\n",
        "    source = {}\n",
        "\n",
        "    # add existing\n",
        "    for i,g in enumerate(master):\n",
        "        merged[key_for(g,i)] = g\n",
        "        source[key_for(g,i)] = \"master\"\n",
        "\n",
        "    added = replaced = kept = 0\n",
        "    # merge part entries\n",
        "    for i,g in enumerate(part):\n",
        "        k = key_for(g,i)\n",
        "        try:\n",
        "            new_y = float(g.y.view(-1).cpu().numpy()[0])\n",
        "        except Exception:\n",
        "            try: new_y = float(g.y)\n",
        "            except Exception: new_y = np.nan\n",
        "        if k not in merged:\n",
        "            merged[k] = g; source[k] = \"part\"; added += 1\n",
        "        else:\n",
        "            prev = merged[k]\n",
        "            try:\n",
        "                prev_y = float(prev.y.view(-1).cpu().numpy()[0])\n",
        "            except Exception:\n",
        "                try: prev_y = float(prev.y)\n",
        "                except Exception: prev_y = np.nan\n",
        "            prev_has = not np.isnan(prev_y)\n",
        "            new_has = not np.isnan(new_y)\n",
        "            # prefer labeled; if same preference, prefer the part (new)\n",
        "            if (new_has and not prev_has) or (new_has == prev_has):\n",
        "                merged[k] = g; source[k] = \"part\"; replaced += 1\n",
        "            else:\n",
        "                kept += 1\n",
        "\n",
        "    merged_list = list(merged.values())\n",
        "    print(f\"Merged count: {len(merged_list)} (added {added}, replaced {replaced}, kept {kept})\")\n",
        "\n",
        "    # atomic save inside GRAPH_DIR to avoid cross-device error\n",
        "    tmp_fd, tmp_path = tempfile.mkstemp(suffix=\".pt\", dir=str(GRAPH_DIR))\n",
        "    os.close(tmp_fd)\n",
        "    torch.save(merged_list, tmp_path)\n",
        "    os.replace(tmp_path, str(MASTER_PT))\n",
        "    print(\"Master saved to:\", MASTER_PT)\n",
        "\n",
        "    # append to global master (no dedupe) and save\n",
        "    global_existing = safe_load(GLOBAL_PT) if GLOBAL_PT.exists() else []\n",
        "    global_combined = list(global_existing) + list(part)\n",
        "    tmp_fd2, tmp_path2 = tempfile.mkstemp(suffix=\".pt\", dir=str(GRAPH_DIR))\n",
        "    os.close(tmp_fd2)\n",
        "    torch.save(global_combined, tmp_path2)\n",
        "    os.replace(tmp_path2, str(GLOBAL_PT))\n",
        "    print(\"Global master updated:\", GLOBAL_PT)\n",
        "\n",
        "    # short summary of labels\n",
        "    labels = []\n",
        "    for g in merged_list:\n",
        "        try: labels.append(float(g.y.view(-1).cpu().numpy()[0]))\n",
        "        except Exception:\n",
        "            try: labels.append(float(g.y))\n",
        "            except Exception: labels.append(np.nan)\n",
        "    from collections import Counter\n",
        "    print(\"Label counts (non-NaN) in merged master:\", dict(Counter([l for l in labels if not np.isnan(l)])) )\n",
        "\n",
        "# Example usage:\n",
        "# merge_part_to_master(\"/content/drive/MyDrive/oasis_project/data/graphs/oasis2_graphs_labeled_part3.pt\")\n"
      ],
      "metadata": {
        "id": "qiyXM-GkPDFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U8-elOZRO8Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_6-sEw0O8L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnwSrjpYO8JW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}